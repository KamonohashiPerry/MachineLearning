{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNGl7bg6b1791Pawe+JMmch",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KamonohashiPerry/MachineLearning/blob/master/deep-learning-from-scratch-2/Chapter5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmnfzB2Khwqd",
        "colab_type": "text"
      },
      "source": [
        "# リカレントニューラルネットワーク（RNN）\n",
        "\n",
        "+ フィードフォワードのネットワーク\n",
        " + 流れが一方向のネットワーク\n",
        "  + 入力信号が次の層へ信号を伝達し、信号を受け取った層はその次の層へ伝達し、そしてまた次の層へといったように一方向だけの信号伝達を行う。\n",
        "   + 単純な構成で仕込みも理解しやすい。\n",
        "   + 時系列データをうまく扱うことができない。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlq5k59Mi5_p",
        "colab_type": "text"
      },
      "source": [
        "## 確率と言語モデル"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOPgEZ8kjF_4",
        "colab_type": "text"
      },
      "source": [
        "### word2vecを確率の視点から眺める\n",
        "\n",
        "+ これまでの表現（左右のウィンドウ）\n",
        "$$P(w_t | w_{t-1}, w_{t+1})$$\n",
        "\n",
        "+ 左のウィンドウだけ\n",
        "$$P(w_t | w_{t-2}, w_{t-1})$$\n",
        "\n",
        "+ 損失関数\n",
        "$$ L = - \\log P(w_t | w_{t-2}, w_{t-1}) $$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpyBgjEhkQVU",
        "colab_type": "text"
      },
      "source": [
        "### 言語モデル\n",
        "+ 単語の並びに対して確率を与える。\n",
        "\n",
        "以下は乗法定理から導くことができる。\n",
        "$$P(w_1, \\dots , w_m) = P(w_m | w_1, \\dots, w_{m-1})P(w_{m-1} | w_1, \\dots, w_{m-2}) \\dots P(w_3 | w_1, w_2)P(w_2 | w_1)P(w_1) \\\\\n",
        "= \\prod _{t=1}^{m}P(W_t | w_!, \\dots, w_{t-1})$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvwP7iI1nG9h",
        "colab_type": "text"
      },
      "source": [
        "### CBOWモデルを言語モデルに\n",
        "+ word2vecのCBOWモデルを無理やり言語モデルに適用するにはどうすればいいか？\n",
        "\n",
        "$$P(w_1, \\dots, w_m) = \\prod_{t=1}^m P(w_t | w_1, \\dots, w_{t-1}) \\approx \\prod_{t=1}^m P(w_t | w_{t-2}, w_{t-1}) $$\n",
        "\n",
        "たった2つ過去の単語しか見れないので、できることに限界がある。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y926C_L_pl1Z",
        "colab_type": "text"
      },
      "source": [
        "## RNNとは\n",
        "+ 何度も繰り返される、循環されるニューラルネットワーク"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmVJh2RQqE2x",
        "colab_type": "text"
      },
      "source": [
        "### 循環するニューラルネットワーク\n",
        "+ 循環するには閉じた経路が必要。\n",
        " + RNNレイヤはループする経路を持つ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxQsZOTorFSt",
        "colab_type": "text"
      },
      "source": [
        "### ループの展開\n",
        "+ 各時点のRNNレイヤは、そのレイヤへの入力と一つ目のRNNレイヤからの出力を受け取る。\n",
        "\n",
        "$$h_t = \\tanh (h_{t-1} W_h + x_t W_x + b)$$\n",
        "\n",
        "過去の状態を持つという観点で、記憶力を持つレイヤとも考えることができる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwBiIC23tpr2",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjmE3_6Ytp0H",
        "colab_type": "text"
      },
      "source": [
        "### Backpropagation Through Time(BPTT)\n",
        "+ ループを展開したあとのRNNは誤差逆伝播法を使うことができる。\n",
        " + 最初に順伝播を行い、続いて逆伝播を行うことで、目的とする勾配を求めることができる。\n",
        "\n",
        "+ 時間方向に展開したニューラルネットワークの誤差逆伝播法と呼ぶ。\n",
        "\n",
        "+ 長い時系列になると学習するのに時間がかかる。\n",
        " + 時間サイズが長くなると逆伝播時の勾配が不安定になる。\n",
        " + 当然、メモリもたくさん使うことになる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TkJ1UawxiaB",
        "colab_type": "text"
      },
      "source": [
        "### Truncated BPTT\n",
        "+ 大きな時系列データを扱う時に、ネットワークのつながりを適当な長さで断ち切るというもの。\n",
        "+ 逆伝播のつながりは切断するが、順伝播のつながりは切断しない。\n",
        "+ Truncated BPTTではデータをシーケンシャルに与えて学習を行う。これにより、順伝播のつながりを維持させながら、ブロック単位で誤差逆伝播法を適用できる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2YF-WCo0FP7",
        "colab_type": "text"
      },
      "source": [
        "### Truncated BPTTのミニバッチ学習\n",
        "+ バッチ数に応じて、開始位置に関して処理をズラす必要がある。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHJub5Ah0vwP",
        "colab_type": "text"
      },
      "source": [
        "## RNNの実装\n",
        "RNNの順伝播\n",
        "$$h_t = tanh(h_{t-1}W_h + x_t W_x + b)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EYgPqxHYiW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN:\n",
        "  def __init__(self, Wx, Wh, b):\n",
        "    self.params = [Wx, Wh, b] # 各パラメータ\n",
        "    self.grads = [np.zeros_like(Wx), np.zeros_like(Wh),\n",
        "                  np.zeros_like(b)] # 各パラメータに関する勾配\n",
        "    self.cache = None # 逆伝播の計算時に使用する中間データ\n",
        "\n",
        "  # 下からの入力、左からの入力を受け取る\n",
        "  def forward(self, x, h_prev):\n",
        "    Wx, Wh, b = self.params\n",
        "    t = np.dot(h_prev, Wh) + np.dot(x, Wx) + b\n",
        "    h_next = np.tanh(t)\n",
        "\n",
        "    self.cache = (x, h_prev, h_next)\n",
        "    return h_next\n",
        "\n",
        "  def backward(self, dh_next):\n",
        "    Wx, Wh, b = self.params\n",
        "    x, h_prev, h_next = self.cache\n",
        "\n",
        "    dt = dh_next * (1 - h_next ** 2)\n",
        "    db = np.sum(dt, axis=0)\n",
        "    dWh = np.dot(h_prev.T, dt)\n",
        "    dh_prev = np.dot(dt, Wh.T)\n",
        "    dWx = np.dot(x.T, dt)\n",
        "    dx = np.dot(dt, Wx.T)\n",
        "\n",
        "    self.grads[0][...] = dWx\n",
        "    self.grads[1][...] = dWh\n",
        "    self.grads[2][...] = db\n",
        "\n",
        "    return dx, dh_prev\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CF6YJifA7OWW",
        "colab_type": "text"
      },
      "source": [
        "### Time RNNレイヤの実装"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGQCHGwS3l1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TimeRNN:\n",
        "  def __init__(self, Wx, Wh, b, stateful=False):\n",
        "    self.params = [Wx, Wh, b]\n",
        "    self.grads = [np.zeros_like(Wx), np.zeros_like(Wh),\n",
        "                  np.zeros_like(b)]\n",
        "    self.layers = None\n",
        "\n",
        "    self.h, self.dh = None, None\n",
        "    self.stateful = stateful\n",
        "\n",
        "  # 隠れ状態を設定する\n",
        "  def set_state(self, h):\n",
        "    self.h = h\n",
        "\n",
        "  # 隠れ状態をリセットする\n",
        "  def reset_state(self):\n",
        "    self.h = None\n",
        "\n",
        "  # 順伝播(下側からxs（T個分の時系列データをひとつにまとめたもの）を受け取る)\n",
        "  def forward(self, xs):\n",
        "    Wx, Wh, b = self.params\n",
        "    N, T, D = xs.shape # Nはバッチサイズ、Dは入力ベクトルの次元数\n",
        "    D, H = Wx.shape\n",
        "\n",
        "    self.layers = []\n",
        "    # 出力用の変数を作成\n",
        "    hs = np.empty((N, T, H), dtype='f')\n",
        "\n",
        "    # 初期条件あるいはリセット\n",
        "    if not self.stateful or self.h is None:\n",
        "      self.h = np.zeros((N, H), dtype='f')\n",
        "\n",
        "    # 時系列の数だけ繰り返し\n",
        "    for t in range(T):\n",
        "      layer = RNN(*self.params)\n",
        "      self.h = layer.forward(xs[:, t, :], self.h)\n",
        "      hs[:, t, :] = self.h\n",
        "      self.layers.append(layer)\n",
        "\n",
        "    return hs\n",
        "\n",
        "  def backward(self, dhs):\n",
        "    Wx, Wh, b = self.params\n",
        "    N, T, H = dhs.shape\n",
        "    D, H = Wx.shape\n",
        "\n",
        "    # 勾配の出力用の変数を作成\n",
        "    dxs = np.empty((N, T, D), dtype='f')\n",
        "    dh = 0\n",
        "    grads = [0, 0, 0]\n",
        "    # 順伝播の逆の順番で時系列で繰り返し。\n",
        "    for t in reversed(range(T)):\n",
        "      layer = self.layers[t]\n",
        "      dx, dh = layer.backward(dhs[:, t, :] + dh) # 合算した勾配\n",
        "      dxs[:, t, :] += grad\n",
        "\n",
        "      for i, grad in enumerate(layer.grads):\n",
        "        grads[i] += grad\n",
        "\n",
        "    for i, grad in enumerate(grads):\n",
        "      self.grads[i][...] = grad\n",
        "\n",
        "    self.dh = dh\n",
        "\n",
        "    return dxs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLQN3MtRCmuX",
        "colab_type": "text"
      },
      "source": [
        "## 時系列データを扱うレイヤの実装\n",
        "RNN Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibrKtS7iCu64",
        "colab_type": "text"
      },
      "source": [
        "### RNNLMの全体図\n",
        "+ RNNLMはこれまで入力された単語を記憶し、それをもとに次に出現する単語を予測する。\n",
        "+ RNNレイヤは過去から現在へとデータを継続的に流すことによって、過去の情報をエンコードして記憶することを可能にしている。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLYXAL4yD86H",
        "colab_type": "text"
      },
      "source": [
        "### Timeレイヤの実装"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqvHUEyD3l5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TimeAffine:\n",
        "    def __init__(self, W, b):\n",
        "        self.params = [W, b]\n",
        "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
        "        self.x = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, T, D = x.shape\n",
        "        W, b = self.params\n",
        "\n",
        "        rx = x.reshape(N*T, -1)\n",
        "        out = np.dot(rx, W) + b\n",
        "        self.x = x\n",
        "        return out.reshape(N, T, -1)\n",
        "\n",
        "    def backward(self, dout):\n",
        "        x = self.x\n",
        "        N, T, D = x.shape\n",
        "        W, b = self.params\n",
        "\n",
        "        dout = dout.reshape(N*T, -1)\n",
        "        rx = x.reshape(N*T, -1)\n",
        "\n",
        "        db = np.sum(dout, axis=0)\n",
        "        dW = np.dot(rx.T, dout)\n",
        "        dx = np.dot(dout, W.T)\n",
        "        dx = dx.reshape(*x.shape)\n",
        "\n",
        "        self.grads[0][...] = dW\n",
        "        self.grads[1][...] = db\n",
        "\n",
        "        return dx\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAb7Jga83l8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TimeSoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.params, self.grads = [], []\n",
        "        self.cache = None\n",
        "        self.ignore_label = -1\n",
        "\n",
        "    def forward(self, xs, ts):\n",
        "        N, T, V = xs.shape\n",
        "\n",
        "        if ts.ndim == 3:  # 教師ラベルがone-hotベクトルの場合\n",
        "            ts = ts.argmax(axis=2)\n",
        "\n",
        "        mask = (ts != self.ignore_label)\n",
        "\n",
        "        # バッチ分と時系列分をまとめる（reshape）\n",
        "        xs = xs.reshape(N * T, V)\n",
        "        ts = ts.reshape(N * T)\n",
        "        mask = mask.reshape(N * T)\n",
        "\n",
        "        ys = softmax(xs)\n",
        "        ls = np.log(ys[np.arange(N * T), ts])\n",
        "        ls *= mask  # ignore_labelに該当するデータは損失を0にする\n",
        "        loss = -np.sum(ls)\n",
        "        loss /= mask.sum()\n",
        "\n",
        "        self.cache = (ts, ys, mask, (N, T, V))\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        ts, ys, mask, (N, T, V) = self.cache\n",
        "\n",
        "        dx = ys\n",
        "        dx[np.arange(N * T), ts] -= 1\n",
        "        dx *= dout\n",
        "        dx /= mask.sum()\n",
        "        dx *= mask[:, np.newaxis]  # ignore_labelに該当するデータは勾配を0にする\n",
        "\n",
        "        dx = dx.reshape((N, T, V))\n",
        "\n",
        "        return dx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCKaNGb5Gc_P",
        "colab_type": "text"
      },
      "source": [
        "## RNNLMの学習と評価"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC4Dps4bGiB4",
        "colab_type": "text"
      },
      "source": [
        "### RNNLMの実装"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd6GUZJg3AOz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e57ebdbf-5d75-47bc-8d13-837de15377fb"
      },
      "source": [
        "!git clone https://github.com/oreilly-japan/deep-learning-from-scratch-2.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deep-learning-from-scratch-2'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 378 (delta 0), reused 0 (delta 0), pack-reused 373\u001b[K\n",
            "Receiving objects: 100% (378/378), 7.91 MiB | 12.21 MiB/s, done.\n",
            "Resolving deltas: 100% (210/210), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfgN_uWdG63A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b043328a-4b45-47af-c8c9-1de015bea309"
      },
      "source": [
        "cd deep-learning-from-scratch-2"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deep-learning-from-scratch-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj6X7KLDG95Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "import numpy as np\n",
        "from common.time_layers import *\n",
        "\n",
        "class SimpleRnnlm:\n",
        "  def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
        "    V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "    rn = np.random.randn\n",
        "\n",
        "    # 重みの初期化\n",
        "    embed_W = (rn(V, D) / 100).astype('f')\n",
        "    rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f')\n",
        "    rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
        "    rnn_b = np.zeros(H).astype('f')\n",
        "    affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
        "    affine_b = np.zeros(V).astype('f')\n",
        "\n",
        "    # レイヤの生成\n",
        "    self.layers = [\n",
        "                   TimeEmbedding(embed_W),\n",
        "                   TimeRNN(rnn_Wx, rnn_Wh. rnn_b, stateful=True),\n",
        "                   TimeAffine(affine_W, affine_b)\n",
        "    ]\n",
        "    self.loss_layer = TimeSoftmaxWithLoss()\n",
        "    self.rnn_layerr = self.layers[1]\n",
        "\n",
        "    # すべての重みと勾配をリストにまとめる\n",
        "    self.params, self.grads = [], []\n",
        "    for layer in self.layers:\n",
        "      self.params += layer.params\n",
        "      self.grads += layer.grads\n",
        "\n",
        "  def forward(self, xs, ts):\n",
        "    for layer in self.layerrs:\n",
        "      xs = layer.forward(xs)\n",
        "    loss = self.loss_layer.forward(xs, ts)\n",
        "    return loss\n",
        "\n",
        "  def backward(self, dout=1):\n",
        "    dout = self.loss_layer.backward(dout)\n",
        "    for layer in reversed(self.layers):\n",
        "      dout = layer.backward(dout)\n",
        "    return dout\n",
        "\n",
        "  def reset_state(self):\n",
        "    self.rnn_layer.reset_state()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr7cvvtXKLWz",
        "colab_type": "text"
      },
      "source": [
        "### 言語モデルの評価\n",
        "+ 言語モデルの予測性能の良さ\n",
        " + パープレキシティ\n",
        "   + 小さいほど良い\n",
        "\n",
        "$$L = - \\frac{1}{N} \\sum_n \\sum_k t_{nk} \\log y_{nk} \\\\\n",
        "perplexity = e^L$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYXja_zPHCSL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5971b35f-3ce3-40ba-96ab-910f1db710f3"
      },
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from common.optimizer import SGD\n",
        "from dataset import ptb\n",
        "from ch05.simple_rnnlm import SimpleRnnlm\n",
        "\n",
        "\n",
        "# ハイパーパラメータの設定\n",
        "batch_size = 10\n",
        "wordvec_size = 100\n",
        "hidden_size = 100\n",
        "time_size = 5  # Truncated BPTTの展開する時間サイズ\n",
        "lr = 0.1\n",
        "max_epoch = 100\n",
        "\n",
        "# 学習データの読み込み（データセットを小さくする）\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "corpus_size = 1000\n",
        "corpus = corpus[:corpus_size]\n",
        "vocab_size = int(max(corpus) + 1)\n",
        "\n",
        "xs = corpus[:-1]  # 入力\n",
        "ts = corpus[1:]  # 出力（教師ラベル）\n",
        "data_size = len(xs)\n",
        "print('corpus size: %d, vocabulary size: %d' % (corpus_size, vocab_size))\n",
        "\n",
        "# 学習時に使用する変数\n",
        "max_iters = data_size // (batch_size * time_size)\n",
        "time_idx = 0\n",
        "total_loss = 0\n",
        "loss_count = 0\n",
        "ppl_list = []\n",
        "\n",
        "# モデルの生成\n",
        "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
        "optimizer = SGD(lr)\n",
        "\n",
        "# ミニバッチの各サンプルの読み込み開始位置を計算\n",
        "jump = (corpus_size - 1) // batch_size\n",
        "offsets = [i * jump for i in range(batch_size)]\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "    for iter in range(max_iters):\n",
        "        # ミニバッチの取得\n",
        "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
        "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
        "        for t in range(time_size):\n",
        "            for i, offset in enumerate(offsets):\n",
        "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
        "                batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
        "            time_idx += 1\n",
        "\n",
        "        # 勾配を求め、パラメータを更新\n",
        "        loss = model.forward(batch_x, batch_t)\n",
        "        model.backward()\n",
        "        optimizer.update(model.params, model.grads)\n",
        "        total_loss += loss\n",
        "        loss_count += 1\n",
        "\n",
        "    # エポックごとにパープレキシティの評価\n",
        "    ppl = np.exp(total_loss / loss_count)\n",
        "    print('| epoch %d | perplexity %.2f'\n",
        "          % (epoch+1, ppl))\n",
        "    ppl_list.append(float(ppl))\n",
        "    total_loss, loss_count = 0, 0\n",
        "\n",
        "# グラフの描画\n",
        "x = np.arange(len(ppl_list))\n",
        "plt.plot(x, ppl_list, label='train')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('perplexity')\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading ptb.train.txt ... \n",
            "Done\n",
            "corpus size: 1000, vocabulary size: 418\n",
            "| epoch 1 | perplexity 400.45\n",
            "| epoch 2 | perplexity 279.04\n",
            "| epoch 3 | perplexity 227.18\n",
            "| epoch 4 | perplexity 216.92\n",
            "| epoch 5 | perplexity 206.84\n",
            "| epoch 6 | perplexity 203.97\n",
            "| epoch 7 | perplexity 199.48\n",
            "| epoch 8 | perplexity 197.11\n",
            "| epoch 9 | perplexity 192.63\n",
            "| epoch 10 | perplexity 193.11\n",
            "| epoch 11 | perplexity 189.70\n",
            "| epoch 12 | perplexity 193.42\n",
            "| epoch 13 | perplexity 190.91\n",
            "| epoch 14 | perplexity 191.50\n",
            "| epoch 15 | perplexity 190.71\n",
            "| epoch 16 | perplexity 187.80\n",
            "| epoch 17 | perplexity 185.72\n",
            "| epoch 18 | perplexity 182.44\n",
            "| epoch 19 | perplexity 183.60\n",
            "| epoch 20 | perplexity 185.13\n",
            "| epoch 21 | perplexity 182.51\n",
            "| epoch 22 | perplexity 179.65\n",
            "| epoch 23 | perplexity 176.62\n",
            "| epoch 24 | perplexity 177.85\n",
            "| epoch 25 | perplexity 174.69\n",
            "| epoch 26 | perplexity 174.86\n",
            "| epoch 27 | perplexity 170.00\n",
            "| epoch 28 | perplexity 167.48\n",
            "| epoch 29 | perplexity 164.40\n",
            "| epoch 30 | perplexity 159.20\n",
            "| epoch 31 | perplexity 161.29\n",
            "| epoch 32 | perplexity 154.62\n",
            "| epoch 33 | perplexity 153.88\n",
            "| epoch 34 | perplexity 147.98\n",
            "| epoch 35 | perplexity 147.48\n",
            "| epoch 36 | perplexity 141.80\n",
            "| epoch 37 | perplexity 137.40\n",
            "| epoch 38 | perplexity 133.74\n",
            "| epoch 39 | perplexity 128.57\n",
            "| epoch 40 | perplexity 125.57\n",
            "| epoch 41 | perplexity 124.84\n",
            "| epoch 42 | perplexity 118.42\n",
            "| epoch 43 | perplexity 111.52\n",
            "| epoch 44 | perplexity 107.49\n",
            "| epoch 45 | perplexity 103.87\n",
            "| epoch 46 | perplexity 102.82\n",
            "| epoch 47 | perplexity 97.52\n",
            "| epoch 48 | perplexity 90.64\n",
            "| epoch 49 | perplexity 87.87\n",
            "| epoch 50 | perplexity 84.81\n",
            "| epoch 51 | perplexity 81.92\n",
            "| epoch 52 | perplexity 77.06\n",
            "| epoch 53 | perplexity 72.07\n",
            "| epoch 54 | perplexity 69.76\n",
            "| epoch 55 | perplexity 67.12\n",
            "| epoch 56 | perplexity 63.42\n",
            "| epoch 57 | perplexity 59.37\n",
            "| epoch 58 | perplexity 55.23\n",
            "| epoch 59 | perplexity 53.07\n",
            "| epoch 60 | perplexity 50.51\n",
            "| epoch 61 | perplexity 49.39\n",
            "| epoch 62 | perplexity 46.27\n",
            "| epoch 63 | perplexity 41.19\n",
            "| epoch 64 | perplexity 39.67\n",
            "| epoch 65 | perplexity 38.36\n",
            "| epoch 66 | perplexity 36.14\n",
            "| epoch 67 | perplexity 34.38\n",
            "| epoch 68 | perplexity 31.30\n",
            "| epoch 69 | perplexity 30.98\n",
            "| epoch 70 | perplexity 29.03\n",
            "| epoch 71 | perplexity 27.26\n",
            "| epoch 72 | perplexity 24.60\n",
            "| epoch 73 | perplexity 23.04\n",
            "| epoch 74 | perplexity 21.98\n",
            "| epoch 75 | perplexity 21.51\n",
            "| epoch 76 | perplexity 19.69\n",
            "| epoch 77 | perplexity 19.01\n",
            "| epoch 78 | perplexity 17.51\n",
            "| epoch 79 | perplexity 16.61\n",
            "| epoch 80 | perplexity 15.73\n",
            "| epoch 81 | perplexity 14.91\n",
            "| epoch 82 | perplexity 13.90\n",
            "| epoch 83 | perplexity 13.27\n",
            "| epoch 84 | perplexity 12.61\n",
            "| epoch 85 | perplexity 11.79\n",
            "| epoch 86 | perplexity 11.14\n",
            "| epoch 87 | perplexity 10.73\n",
            "| epoch 88 | perplexity 10.16\n",
            "| epoch 89 | perplexity 9.77\n",
            "| epoch 90 | perplexity 8.93\n",
            "| epoch 91 | perplexity 8.89\n",
            "| epoch 92 | perplexity 8.28\n",
            "| epoch 93 | perplexity 7.96\n",
            "| epoch 94 | perplexity 7.43\n",
            "| epoch 95 | perplexity 7.38\n",
            "| epoch 96 | perplexity 6.83\n",
            "| epoch 97 | perplexity 6.77\n",
            "| epoch 98 | perplexity 6.38\n",
            "| epoch 99 | perplexity 5.85\n",
            "| epoch 100 | perplexity 5.80\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd3hc1bnv8e+rUS9Ws9wkuTcMATdMDTiYHsCQAAcIhADn+JAQCIHcE5J7zj2k3Qs5BAKB0BMMIZSQEAwECJhiwNjGxja4gnGV3GSr2LK69N4/ZkvITZaxRiNpfp/n0ePZa/bMvPsZ0E97rb3XMndHREQEIC7aBYiISNehUBARkRYKBRERaaFQEBGRFgoFERFpER/tAg5F7969ffDgwdEuQ0SkW1mwYME2d8/b13PdOhQGDx7M/Pnzo12GiEi3Ymbr9vecuo9ERKSFQkFERFooFEREpIVCQUREWigURESkRcRDwcxCZrbQzF4KtoeY2VwzW2Vmz5hZYtCeFGyvCp4fHOnaRERkd51xpvADYHmr7duBu9x9OFAGXBO0XwOUBe13BfuJiEgnimgomFkB8HXgkWDbgFOA54JdpgPnB4+nBtsEz08J9u9wKzfv5I7XVlK6qy4Sby8i0m1F+kzht8B/AE3Bdi5Q7u4NwXYRkB88zgc2AATPVwT778bMppnZfDObX1JS8qWKWrOtknvfWsWWHTVf6vUiIj1VxELBzM4Btrr7go58X3d/yN0nuvvEvLx93qV9QGlJ4Ru5d9U2HGBPEZHYEslpLk4AzjOzs4FkoBdwN5BlZvHB2UABUBzsXwwUAkVmFg9kAtsjUVhqYviwKxUKIiK7idiZgrv/xN0L3H0wcAnwprt/C3gLuDDY7UrgheDxjGCb4Pk3PUJrhaa3nCk0RuLtRUS6rWjcp/Bj4CYzW0V4zODRoP1RIDdovwm4JVIFpCWFAHUfiYjsqVNmSXX3t4G3g8ergUn72KcGuKgz6mk+U1D3kYjI7mLyjmYNNIuI7FtMhkJCKI7E+Dgq6xQKIiKtxWQoQLgLSWcKIiK7i9lQSEsK6eojEZE9xG4oJMZroFlEZA8xGwrqPhIR2VvMhkKaQkFEZC8xGwrpSeo+EhHZU8yGggaaRUT2FsOhoO4jEZE9xWwopCfFs6uugQjNuSci0i3FbCikJcXT5FBdry4kEZFmMR0KoEnxRERai91QSGyePltnCiIizWI3FDRTqojIXmI2FNIVCiIie4lYKJhZspnNM7PFZrbUzH4WtD9mZmvMbFHwMzZoNzO7x8xWmdnHZjY+UrVBqzMFTZ8tItIikiuv1QKnuHulmSUA75nZK8Fz/8vdn9tj/7OAEcHPMcD9wb8RkR4syVmpMQURkRYRO1PwsMpgMyH4aeumgKnA48Hr5gBZZtY/UvVpTEFEZG8RHVMws5CZLQK2Aq+7+9zgqV8FXUR3mVlS0JYPbGj18qKgLSIUCiIie4toKLh7o7uPBQqASWZ2BPATYDRwNJAD/Phg3tPMppnZfDObX1JS8qVrS0vUfQoiInvqlKuP3L0ceAs40903BV1EtcAfgUnBbsVAYauXFQRte77XQ+4+0d0n5uXlfemaQnFGSkJIZwoiIq1E8uqjPDPLCh6nAKcBK5rHCczMgPOBJcFLZgDfDq5COhaocPdNkaoPwl1IGmgWEflCJK8+6g9MN7MQ4fB51t1fMrM3zSwPMGARcG2w/z+As4FVQBVwVQRrA8JXIOlMQUTkCxELBXf/GBi3j/ZT9rO/A9dFqp590fTZIiK7i9k7mqG5+0ihICLSLKZDoXlNBRERCYvpUAh3H2mgWUSkWUyHQnpSSN1HIiKtxHQopCVqoFlEpLWYDoXUpHiq6hppatI6zSIiEOOh0DxTqgabRUTCYjoUvpgUT4PNIiIQ46HQvPqaBptFRMJiOhSaZ0rVYLOISFhsh4LWVBAR2U1Mh0J6yzrNGlMQEYEYD4W05quPdKYgIgLEeChooFlEZHcxHQoaUxAR2V1Mh0JqYggzhYKISLNILseZbGbzzGyxmS01s58F7UPMbK6ZrTKzZ8wsMWhPCrZXBc8PjlRtrWokLVFLcoqINIvkmUItcIq7HwWMBc4M1l6+HbjL3YcDZcA1wf7XAGVB+13BfhGXpiU5RURaRCwUPKwy2EwIfhw4BXguaJ8OnB88nhpsEzw/xcwsUvU1S0uKp1JzH4mIABEeUzCzkJktArYCrwOfA+Xu3vxbuAjIDx7nAxsAgucrgNxI1gfB6ms6UxARASIcCu7e6O5jgQJgEjD6UN/TzKaZ2Xwzm19SUnLINWpNBRGRL3TK1UfuXg68BRwHZJlZfPBUAVAcPC4GCgGC5zOB7ft4r4fcfaK7T8zLyzvk2tKSNNAsItIsklcf5ZlZVvA4BTgNWE44HC4MdrsSeCF4PCPYJnj+TXeP+Oo3GmgWEflC/IF3+dL6A9PNLEQ4fJ5195fMbBnwtJn9ElgIPBrs/yjwhJmtAkqBSyJYW4s0jSmIiLSIWCi4+8fAuH20ryY8vrBnew1wUaTq2Z/0pHhNcyEiEojpO5ohPNBc29BEQ2NTtEsREYk6hULLTKkabBYRiflQaJkpVTewiYgoFDRTqojIF2I+FLSmgojIF2I+FLLTEgEorayLciUiItEX86EwICsZgI0V1VGuREQk+mI+FHqnJZEYiqO4TKEgIhLzoRAXZwzISqa4XKEgIhLzoQAwICuFjQoFERGFAjSHQk20yxARiTqFApCflcKWnTXUNWiqCxGJbQoFwqHgDlt26GxBRGKbQoFw9xGgwWYRiXkKBb64V0GXpYpIrFMo8MWZgq5AEpFYF8nlOAvN7C0zW2ZmS83sB0H7rWZWbGaLgp+zW73mJ2a2ysxWmtkZkaptT8kJIXqnJ+quZhGJeZFcjrMBuNndPzKzDGCBmb0ePHeXu9/RemczG0N4Cc7DgQHAG2Y20t07ZaGDAVkpFOuyVBGJcRE7U3D3Te7+UfB4J7AcyG/jJVOBp9291t3XAKvYx7KdkTIgM4XisqrO+jgRkS6pU8YUzGww4fWa5wZN3zezj83sD2aWHbTlAxtavayItkOkQ+Vnh29gc/fO+kgRkS4n4qFgZunAX4Eb3X0HcD8wDBgLbAJ+c5DvN83M5pvZ/JKSkg6rc0BWCtX1jZRX1XfYe4qIdDftCgUz+5uZfd3MDipEzCyBcCA86e5/A3D3Le7e6O5NwMN80UVUDBS2enlB0LYbd3/I3Se6+8S8vLyDKadN+c2XpeoKJBGJYe39Jf974DLgMzO7zcxGHegFZmbAo8Byd7+zVXv/VrtdACwJHs8ALjGzJDMbAowA5rWzvkOmG9hERNp59ZG7v0H4aqBM4NLg8QbCf+n/yd331edyAnAF8ImZLQrafgpcamZjAQfWAv8efMZSM3sWWEb4yqXrOuvKIwhPdQG6V0FEYlu7L0k1s1zgcsK/6BcCTwInAlcCk/fc393fA2wfb/WP/X2Gu/8K+FV7a+pIOWmJJMXHKRREJKa1KxTM7HlgFPAEcK67bwqeesbM5kequM5kZuRnpaj7SERiWnvPFB52993+wjezpOCegokRqCsq8rN1A5uIxLb2DjT/ch9tH3RkIV3BgEytwCYisa3NMwUz60f4BrIUMxvHF2MEvYDUCNfW6QZkpVCys5bahkaS4kPRLkdEpNMdqPvoDOA7hO8ZuLNV+07CVxL1KM1TaG8qr2Fw77QoVyMi0vnaDAV3nw5MN7NvuvtfO6mmqMnPDl+Wur60SqEgIjHpQN1Hl7v7n4DBZnbTns+3vimtJzi8fyYZSfE8/O5qvjqiN+H770REYseBBpqb/1xOBzL28dOjZKYm8MPTRvLuZ9t4benmaJcjItLpDtR99GDw78/2fM7MEiNVVDR9+7hBPDt/A794aTknj+xDSqIGnEUkdrR3Qry3g+mvm7ePBj6MUE1RFR+K4+dTj6C4vJr73loV7XJERDpVe+9T+H/Aq2b2PTP7FfAgcFXkyoquSUNyuGBcPg/NWs2abbuiXY6ISKdpVyi4+2vAtcDdwNXA2c2rqvVUPzlrNEnxcfz3jKVaeEdEYkZ7u4/+C/gdcBJwK/C2mX09gnVFXZ9eydx0+khmfVrCK0s06CwisaG93Ue5wCR3/yAYfD4DuDFyZXUNVxw7iDH9e/HzF5dRWdsQ7XJERCKuvd1HNwI0L67j7uvc/bRIFtYVxIfi+OUFR7B5Rw33zPws2uWIiERce7uPzgUWAa8G22PNbEYkC+sqxg/M5tJJhTz63hre+bRE4wsi0qO1t/voVsJrKZcDuPsiYGhbLzCzQjN7y8yWmdlSM/tB0J5jZq+b2WfBv9lBu5nZPWa2ysw+NrPxX/qoOth/nDGafr2SufIP8/jm/bP559LNNDUpHESk52lvKNS7e8UebU0HeE0DcLO7jwGOBa4zszHALcBMdx8BzAy2Ac4ivC7zCGAacH87a4u47LREZt58Mr+Yejhbd9Yy7YkFfOuRuWyu0NoLItKztDcUlprZZUDIzEaY2e+A2W29wN03NV+26u47geWEp+GeCkwPdpsOnB88ngo87mFzgCwz639whxM5yQkhrjhuMG//aDL/94KvsGhDOWfdPYuZy7dEuzQRkQ7T3lC4HjgcqAWeAnZwEFcfBXdDjwPmAn1bLee5GegbPM4HNrR6WVHQ1qXEh+K47JiBvHj9ifTLTOGa6fO57smPePezEnUpiUi3167lON29Cvjfwc9BMbN04K/Aje6+o/XMo+7uZnZQv0nNbBrh7iUGDhx4sOV0mOF90nn+e8dz98zP+PPc9bz8ySbys1K4dvIwLj9moGZYFZFuydq6msbMXgT2u4O7n9fmm5slAC8BrzVPs21mK4HJ7r4p6B56291HmdmDweOn9txvf+8/ceJEnz9/flsldIqa+kZeX7aFJz5Yx7y1pZx6WB9+feFR5KT1yDkDRaSbM7MF7j5xX88d6EzhjkP4UAMeBZbvse7CDOBK4Lbg3xdatX/fzJ4GjgEq2gqEriQ5IcS5Rw3gnCP788f313LbKys46+5ZXHHsIHbWNlC+q55+mclcfeIQMlMSgHCQPDRrNYs3lHPuUQM46yv9tASoiERdm2cKu+0Ynip7NOEzh5XuXneA/U8E3gU+4YsrlX5KeFzhWWAgsA642N1LgxC5FzgTqAKucvc2TwO6ypnCnpYUV3DD0wtZXbKLxFAcWakJbN1ZS3ZqAjeeOpLCnBR+9uIy1m2vIi8jiZKdteSkJTJldB8qaxvYurOWXbUN9MtMpiA7haG905k6dgC56UnRPjQR6QHaOlNoVygE8xw9AHwOGDAE+Hd3f6UjCz1YXTUUAJqanOr6RlITQ5gZS4or+NXLy/lg9XYAhual8fPzjuD4Ybm8//k2/jRnHR+uLSMnLZG89CTSk+PZVFHNhtJqKqrrSU6I45KjBzLtpKEMyEqJ8tGJSHfWEaGwAjjH3VcF28OAl919dIdWepC6cijsi7vz9qclbN1Rw/nj8tvdXbRq604eeGc1f19YDMCJI3pzzpEDOP3wvvRKTohkySLSA3VEKHzo7ke32jZgXuu2aOhuoXCoisqqeGLOOl5avIni8moSQ3FcMqmQ608ZQV7G7l1LW3bUMGf1dhasK2NwbhoXTixQgIgI0DGhcD8wiPBYgAMXAeuBNwDc/W8dVu1BiLVQaObuLNxQzrMfbuAvC4pIio/jO8cPJi0pnqUbK1i6cQfrtlcBkJIQaunG+sb4fK46YQjD8tKjfAQiEk0dEQp/bONpd/erv2xxhyJWQ6G11SWV/Oafn/LyJ+ELtQblpjKmfy8mDMrm2KG5HNa/F8s37eCx2WuZsXgj9Y1NnD6mL9eePIxxA7OjXL2IRMMhhYKZhYAb3P2uSBR3KBQKX9hYXk16cnybXUTbK2uZPnst0z9YR0V1PccNzeWGKSM4blhuJ1YqItHWEWcK89x9UodXdogUCl/OrtoGnpq3ngdnraZkZy2ThuRwzJAclm7cwSfFFSSG4rjua8O5aGIBCaH2zoQiIt1FR4TCXUAC8AzQspJ9tNdpVigcmpr6Rp6et5773/mcrTtrGZ6XzlfyM1mzfRcL15czMCeVfzm6kDgz6hqayE1P5JKjC4lXUIh0ax0RCm/to9nd/ZRDLe5QKBQ6RkNjE/WNTkpi+BJZd+ftlSXc8c+VLN24Y7d9jx+Wy+8uHacb6US6sUMOha5KoRBZ7s6OmgYSQ3Ekxsfx/MJifvr8J/ROS+SBKyZwZEFWtEsUkS+hrVBo73Kcfc3sUTN7JdgeY2bXdGSR0vWYGZkpCaQkhgjFGRdOKOCv1x6PmXHB72fz3T8tYPaqbVqiVKQHaW/n8GPAa8CAYPtTDmI9Bek5vlKQyYvXn8g1Jw7hg9XbueyRuZx65zv8dUERDY0HWoxPRLq69oZCb3d/lmBiO3dvABojVpV0aTlpifz07MOY85Mp3HnxUSTFh7j5L4s57a5Z/O2jIi02JNKNtTcUdplZLsHaCmZ2LLDnms0SY5ITQnxjfAEv33AiD10xgZSEEDc9u5jrn15ITb3+ZhDpjtq18hpwE+H1Doaa2ftAHnBhxKqSbsXMOP3wfpw2pi8PzlrN7a+uoLismoe/PZGkhDj+uXQLsz4t4eoThzC2UIPTIl1Ze0NhGfA84XUOdgJ/JzyuINLCzLj25GEMzk3jxmcWcsZvZ1FZ00BdYxOhOOOdT0v4y7XHMbJvRrRLFZH9aO99Cs8CO4Ang6bLgCx3vyiCtR2QLkntuj4pquDXr61gRJ8MzjmqP3npSXzz/tmYwXPXHk9hTmq0SxSJWR1x89oydx9zoLbOplDoXlZu3slFD8wmJy2R/3PuGAqyU8nPSiEtqb0nrCLSEQ75PgXgo2BwufkNjwHa/G1sZn8ws61mtqRV261mVmxmi4Kfs1s99xMzW2VmK83sjHbWJd3IqH4Z/PGqo9m6s5arH5vP6XfN4vD/fo2fPv8JjbpiSaRLaO+faBOA2Wa2PtgeCKw0s08IT3dx5D5e8xjhNZcf36P9Lne/o3WDmY0BLgEOJ3wvxBtmNtLddQlLDzNhUA6zbzmFz0sqKSqrZu6aUv48dz2VNQ385uKjNAGfSJS1NxTOPNg3dvdZZja4nbtPBZ5291pgjZmtAiYBHxzs50rXl5WayIRBOUwYBFPH5lOYncrtr66gtqGRey4d1+5lSkWk47UrFNx9XQd+5vfN7NuEu59udvcyIB+Y02qfoqBtL2Y2DZgGMHDgwA4sS6Llu5OHkZIQx60vLmP0f71KVkoCOWmJfP0r/bnx1JHExVm0SxSJGZ09wnc/8AvCN8H9AvgNcFCrtrn7Q8BDEB5o7ugCJTq+c8IQhuSls2BdGaW7alm3vYp73lxFUXk1v/7mkZquW6STdGoouPuW5sdm9jDwUrBZDBS22rUgaJMYcvLIPE4emQeEZ2j93ZuruPP1T9lR3cC9l40jOUHdSiKR1ql/fplZ/1abFwDNVybNAC4xsyQzGwKMAOZ1Zm3StZgZN0wZwS+mHs7MFVu49OE5bCitinZZIj1exELBzJ4iPFA8ysyKgqm2f21mn5jZx8DXgB8CuPtS4FnCd06/ClynK48E4IrjBvP7y8azakslZ9/9Li8s0gmkSCRpkR3pFjaUVnHjM4tYsK6M844awH+ecxh9MpKjXZZIt9QRN6+JRFVhTirPTDuWG08dwStLNjHljnd49L011GsNB5EOpVCQbiM+FMeNp47ktRtPYtygbH7x0jKm3vs+RWUaaxDpKAoF6XaG5qUz/aqjeeDy8Wwoq+L8+97no/Vl0S5LpEdQKEi3ZGaceUR/nv/e8aQmxnPJQ3P420dFWi9a5BApFKRbG94ng79fdwJjC7O46dnFnHfv+7y2dLOWBBX5knT1kfQI9Y1NPL+wmPveWsW67VUMyk1lRJ8MCrJTGNk3g4snFuiuaJFAW1cfaSJ76RESQnFcPLGQb4zLZ8bijbz88SY2lFYxZ/V2KmsbWLCujP+58EjNoyRyAAoF6VHiQ3F8Y3wB3xhf0NJ29xufcdcbn5KSGMcvph6BmYJBZH8UCtLj3TBlOFV1DTw4azWpifH85KzRCgaR/VAoSI9nZtxy1miq6xt5aNZqslMT+e7kYdEuS6RLUihITDAzbj33cMqq6rn91RX0y0zignEFB36hSIxRKEjMiIsz7rjoSLbtrOV//eVjeqcn8dURedEuS6RL0TV6ElOS4kM8+O0JDO+TzrVPLOD1ZVsO/CKRGKJQkJjTKzmBx66axMDcNP7t8fnc8NRCSnfVRbsskS5BoSAxqV9mMi9cdwI3nTaSV5Zs4rQ73+G5BUW6E1pinkJBYlZifBw3TBnBS9d/lYG5qfzoL4u58IHZLCmuiHZpIlETsWkuzOwPwDnAVnc/ImjLAZ4BBgNrgYvdvczCF43fDZwNVAHfcfePDvQZmuZCOkpTk/PXj4q4/dUVbN9Vx4g+6Yzsm8Govhl8c0IBA7JSol2iSIeJ1iI7jwFn7tF2CzDT3UcAM4NtgLMIr8s8ApgG3B/BukT2EhdnXDSxkDd/NJmbTh3JwJxUFheV85vXP+W8e99j0YbyaJco0ikiOiGemQ0GXmp1prASmOzum8ysP/C2u48ysweDx0/tuV9b768zBYm0VVsrueqxeZTsrOW3/zKOM4/oF+2SRA5ZV1qOs2+rX/Sbgb7B43xgQ6v9ioK2vZjZNDObb2bzS0pKIlepCDC8TzrPf+8EDuvfi+8+uYA/zVkX7ZJEIipqA80ePkU56NMUd3/I3Se6+8S8PN14JJHXOz2Jp/7tWL42qg//9cISXl3S5gmsSLfW2aGwJeg2Ivh3a9BeDBS22q8gaBPpEpITQtx32XjGFWZxw9OL+HBtabRLEomIzg6FGcCVweMrgRdatX/bwo4FKg40niDS2VISQzx65dEUZKdwzWMfsnSjLl2VnidioWBmTwEfAKPMrMjMrgFuA04zs8+AU4NtgH8Aq4FVwMPA9yJVl8ihyE5LZPpVk0hKCHHO797j3x6fz7w1pVobWnoMLccp8iWU7Kzl8Q/W8sScdZRX1TN+YBY/OHUkJ43orbUapMtr6+ojhYLIIaiua+S5BRt44J3VFJdXM25gFjdMGcHkkXkKB+myFAoiEVbX0MRfFmzgvjdXsbGiJnwJ6+RhnH1EP+JDmk1GuhaFgkgnqWto4u+Linngnc9ZXbKLUX0zuP/y8QzNS492aSItutLNayI9WmJ8HBdPLOSNH57MfZeNp6Sylqn3vq91G6TbUCiIREBcnPH1I/vz4vUnMrh3eN2GO1//VFNzS5enUBCJoPysFP5y7XFcOKGAe2Z+xrQnFrCzpj7aZYnsl0JBJMKSE0L8z4VHcuu5Y3hr5Va+8fvZrN22K9plieyTQkGkE5gZ3zlhCE9cPYmSylrOuvtdbn52MXNWb1eXknQpuvpIpJNtKK3i3jdX8fInm6isbWBQbipXHDuIiyYWkpmSEO3yJAboklSRLqiqroHXlm7mz3PX8+HaMlITQ3xzfAHXTxlOn4zkaJcnPZhCQaSLW1JcwfTZa/n7omKS40PcdPpIrjh2kG58k4jQfQoiXdwR+Zn8z0VH8dqNJzF2YBY/e3EZ5977Ph8XaRlQ6VwKBZEuZGheOo9fPYn7vzWe0l21nH/f+9z2ygpq6hujXZrECIWCSBdjZpz1lf7884cnc9GEQh5453O+fs+7LFxfFu3SJAYoFES6qMyUBG6/8Egev3oS1XWNfPP+2dz+6gpqG3TWIJGjUBDp4k4amcerPzyJiyYUcv/bn3Pe797nxcUbqa5TOEjHi8rVR2a2FtgJNAIN7j7RzHKAZ4DBwFrgYndv83xZVx9JrHlr5Vb+8/klFJdXk5oY4ozD+3HRxAKOG5qr9Ruk3brcJalBKEx0922t2n4NlLr7bWZ2C5Dt7j9u630UChKLGpuceWtKmbG4mJc/3sSOmgaG90nnimMHceqYvgzITFZASJu6SyisBCa7+yYz6w+87e6j2nofhYLEupr6Rl5cvJE/zVnH4qIKIDwWMbpfBqeN6cu3jhlESmIoylVKV9MVQ2ENUAY48KC7P2Rm5e6eFTxvQFnz9h6vnQZMAxg4cOCEdevWdWLlIl3X0o0VfLS+nOWbdvBJUQWfFFeQl5HE9yYP49JJA0lOUDhIWFcMhXx3LzazPsDrwPXAjNYhYGZl7p7d1vvoTEFk/+au3s6dr3/K3DWljOqbwSNXTqQwJzXaZUkX0OXuaHb34uDfrcDzwCRgS9BtRPDv1mjUJtJTHDM0l2f+/Tj++J2j2byjhvPufY85q7dHuyzp4jo9FMwszcwymh8DpwNLgBnAlcFuVwIvdHZtIj3R10b34e/XnUB2WiKXPzKXO/+5ko/Wl1Hf2BTt0qQL6vTuIzMbSvjsACAe+LO7/8rMcoFngYHAOsKXpJa29V7qPhJpv4rqem5+djFvLA+vF52aGGLcwCzGFmYxtjCbCYOyyUlLjHKV0hm63JhCR1EoiBy8bZW1zFtTypzV21mwrowVm3fS2OSE4oyvjujNBePyOX1MP1211IMpFERkv6rrGlmysYK3VmzlhUUbKS6vJjkhjuOH9WbyqDxOGd2HgmwNUPckCgURaZemJufDtaW8smQzb63cyrrtVZjBuUcO4IYpwxneJyPaJUoHUCiIyJeyZtsunvlwA49/sJbq+kZOPawvg3JSSUuKJyctkROG92Z4n/RolykHSaEgIodke2UtD7+7hhcWFVNRXU9Vq8n4hualccbh/Zgyug9jC7O0Wlw3oFAQkQ7V2ORs3lHDzOVbeG3pZuasLqWxyclMSeCkkXlcPLGAE4f31hxMXZRCQUQiqqKqnndXlfD2yhLeXLGV0l11jOiTzndOGMzZR/QnW5e6dikKBRHpNLUNjby0eBN/nL2GJcU7ABjdL4PjhuUytjCLkX0zGJqXRlK8LnmNFoWCiHQ6d+fjogre/ayED1ZvZ/7aMmobwndRh+KMvPQkstMSyUlLYGTfDKaM7sukITkkxmtMItIUCiISdXUNTazZtouVW3by6eadbNlRQ1lVPdt31bJ04w7qGppIT4rnK/mZ9M9Kpn9mMkN7pzNpSA4F2dsKyJgAAAlRSURBVCkan+hAbYVCfGcXIyKxKTE+jlH9MhjVLwOO2v256rpGZn++jZkrtrJy807mri5l844aGpvCf7QOyExm3MBshualMaR3GoN7pzEkN01jFRGgUBCRqEtJDDHlsL5MOaxvS1tjk/PZ1nBAzF2znU+KK3hlySaaWnVuZKYkMDg3lcKcVAblpjIoJ41hfdIZ0TedXskJUTiS7k/dRyLSbdQ1NLG+tIq123axdnvws62KDWVVFJdV09AqMfpkJNE/M5m+vcI//TKT6dcr3C1VkJ3KgKzkmL2nQt1HItIjJMbHMbxP+j7vom5obKK4vJpVWyv5dEslq0sq2byjhnXbq5i7ppSK6vrd9g/FGQOykumfmUK/IDRy0hLJTEkgKyWBnLRE8jKSyMtIIj0pPmbGNBQKItIjxIfiGJSbxqDctN26oZpV1zWyZUcNGyuqKSqtZn1pFetLq9hcUcOiDeVsXlpDXcO+15hICBm9khPolZJAXnoSA3NTGZSTSm56EnEGZpCcEKJPRjJ9eiXROy2J9OR4QnHdL0gUCiISE1ISQwwOBqkZtvfz7k51fSPlVfWUV9VTuquOksoaSnbWUlZVz47qeiqq69myo4ZZn5awdWftAT8zOSGOXskJ5KYn0Ts9fBYSH2fEmREfMnLSwu256YnEx8URZ0YozshIjg9CKDzHVGeeqSgUREQAMyM1MZ7UxHgGZKUccP/qukYqqutxnCaHqtoGtu6sZevOGrZX1rGrtpFddQ1UVNWzfVcd2yprKSqrpsmdxianrqGJsqo66hsPPK6bFB9HbloiSQkhzCDOjEuOLuRfvzq0Iw59N10uFMzsTOBuIAQ84u63RbkkEZG9pCSG9lqIaETfg5ta3N3ZUdNA2a46GpqaaGyC+sYmdtU2sKOmgfKqOsqq6thWWcf2yjrqG5tocscdeqcndeThtOhSoWBmIeA+4DSgCPjQzGa4+7LoViYi0vHMjMyUBDJTus7ls13teqxJwCp3X+3udcDTwNQo1yQiEjO6WijkAxtabRcFbS3MbJqZzTez+SUlJZ1anIhIT9fVQuGA3P0hd5/o7hPz8vKiXY6ISI/S1UKhGChstV0QtImISCfoaqHwITDCzIaYWSJwCTAjyjWJiMSMLnX1kbs3mNn3gdcIX5L6B3dfGuWyRERiRpcKBQB3/wfwj2jXISISi7pa95GIiERRt54628xKgHVf8uW9gW0dWE53EYvHHYvHDLF53LF4zHDwxz3I3fd5+Wa3DoVDYWbz9zefeE8Wi8cdi8cMsXncsXjM0LHHre4jERFpoVAQEZEWsRwKD0W7gCiJxeOOxWOG2DzuWDxm6MDjjtkxBRER2VssnymIiMgeFAoiItIiJkPBzM40s5VmtsrMbol2PZFgZoVm9paZLTOzpWb2g6A9x8xeN7PPgn+zo11rJJhZyMwWmtlLwfYQM5sbfOfPBHNr9RhmlmVmz5nZCjNbbmbHxcJ3bWY/DP77XmJmT5lZck/8rs3sD2a21cyWtGrb5/drYfcEx/+xmY0/mM+KuVBotbrbWcAY4FIzGxPdqiKiAbjZ3ccAxwLXBcd5CzDT3UcAM4PtnugHwPJW27cDd7n7cKAMuCYqVUXO3cCr7j4aOIrwsffo79rM8oEbgInufgTh+dIuoWd+148BZ+7Rtr/v9yxgRPAzDbj/YD4o5kKBGFndzd03uftHweOdhH9J5BM+1unBbtOB86NTYeSYWQHwdeCRYNuAU4Dngl161HGbWSZwEvAogLvXuXs5MfBdE56/LcXM4oFUYBM98Lt291lA6R7N+/t+pwKPe9gcIMvM+rf3s2IxFA64ultPY2aDgXHAXKCvu28KntoM9I1SWZH0W+A/gKZgOxcod/eGYLunfedDgBLgj0GX2SNmlkYP/67dvRi4A1hPOAwqgAX07O+6tf19v4f0Oy4WQyGmmFk68FfgRnff0fo5D1+P3KOuSTazc4Ct7r4g2rV0onhgPHC/u48DdrFHV1EP/a6zCf9VPAQYAKSxdxdLTOjI7zcWQyFmVnczswTCgfCku/8taN7SfCoZ/Ls1WvVFyAnAeWa2lnDX4CmE+9uzgi4G6HnfeRFQ5O5zg+3nCIdET/+uTwXWuHuJu9cDfyP8/ffk77q1/X2/h/Q7LhZDISZWdwv60R8Flrv7na2emgFcGTy+Enihs2uLJHf/ibsXuPtgwt/tm+7+LeAt4MJgtx513O6+GdhgZqOCpinAMnr4d0242+hYM0sN/ntvPu4e+13vYX/f7wzg28FVSMcCFa26mQ4oJu9oNrOzCfc7N6/u9qsol9ThzOxE4F3gE77oW/8p4XGFZ4GBhKcdv9jd9xzA6hHMbDLwI3c/x8yGEj5zyAEWApe7e2006+tIZjaW8MB6IrAauIrwH309+rs2s58B/0L4aruFwL8S7j/vUd+1mT0FTCY8RfYW4L+Bv7OP7zcIyHsJd6VVAVe5+/x2f1YshoKIiOxbLHYfiYjIfigURESkhUJBRERaKBRERKSFQkFERFooFEQ6kZlNbp65VaQrUiiIiEgLhYLIPpjZ5WY2z8wWmdmDwfoMlWZ2VzB//0wzywv2HWtmc4K5659vNa/9cDN7w8wWm9lHZjYsePv0VmsfPBncbISZ3Wbh9S8+NrM7onToEuMUCiJ7MLPDCN8le4K7jwUagW8RnnBtvrsfDrxD+K5SgMeBH7v7kYTvIG9ufxK4z92PAo4nPJMnhGesvZHweh5DgRPMLBe4ADg8eJ9fRvYoRfZNoSCytynABOBDM1sUbA8lPF3IM8E+fwJODNYyyHL3d4L26cBJZpYB5Lv78wDuXuPuVcE+89y9yN2bgEXAYMLTPtcAj5rZNwhPTyDS6RQKInszYLq7jw1+Rrn7rfvY78vOEdN6Hp5GID6Y/38S4RlOzwFe/ZLvLXJIFAoie5sJXGhmfaBlLdxBhP9/aZ598zLgPXevAMrM7KtB+xXAO8Fqd0Vmdn7wHklmlrq/DwzWvch0938APyS8pKZIp4s/8C4iscXdl5nZfwL/NLM4oB64jvDiNZOC57YSHneA8LTFDwS/9JtnKIVwQDxoZj8P3uOiNj42A3jBzJIJn6nc1MGHJdIumiVVpJ3MrNLd06Ndh0gkqftIRERa6ExBRERa6ExBRERaKBRERKSFQkFERFooFEREpIVCQUREWvx/s2eTwwfkmPYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlLdxKE-XhBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RnnlmTrainer:\n",
        "  def __init__(self, model, optimizer):\n",
        "    self.model = model\n",
        "    self.optimizer = optimizer\n",
        "    self.time_idx = None\n",
        "    self.ppl_list = None # パープレキシティ\n",
        "    self.eval_interval = None\n",
        "    self.current_epoch = 0\n",
        "\n",
        "  # バッチ処理をズラすための関数\n",
        "  def get_batch(self, x, t, batch_size, time_size):\n",
        "    batch_x = np.empty((batch_size, time_size), dtype='i') # 入力\n",
        "    batch_t = np.empty((batch_size, time_size), dtype='i') # 出力\n",
        "\n",
        "    data_size = len(x)\n",
        "    # インデックスを飛ばすため\n",
        "    jump = data_size // batch_size\n",
        "    offsets = [i * jump for i in range(batch_size)] # バッチの各サンプルの読み込み開始位置\n",
        "\n",
        "    for time in range(time_size):\n",
        "      for i, offset in enumerate(offsets):\n",
        "        batch_x[i, time] = x[(offset + self.time_idx) % data_size]\n",
        "        batch_t[i, time] = t[(offset + self.time_idx) % data_size]\n",
        "\n",
        "      self.time_idx += 1\n",
        "    return batch_x, batch_t\n",
        "\n",
        "  def fit(self, xs, ts, max_epoch=10, batch_size=20, time_size=35,\n",
        "          max_grad=None, eval_interval=20):\n",
        "    data_size = len(xs)\n",
        "    max_iters = data_size // (batch_size * time_size)\n",
        "    self.time_idx = 0\n",
        "    self.ppl_list = []\n",
        "    self.eval_interval = eval_interval\n",
        "    model, optimizer = self.model, self.optimizer\n",
        "    total_loss = 0\n",
        "    loss_count = 0\n",
        "\n",
        "    start_time = time.time()\n",
        "    for epoch in range(max_epoch):\n",
        "      for iters in range(max_iters):\n",
        "        batch_x, batch_t = self.get_batch(xs, ts, batch_size, time_size)\n",
        "\n",
        "        # 勾配を求め、パラメータを更新\n",
        "        loss = model.forward(batch_x, batch_t)\n",
        "        model.backward()\n",
        "        params, grads = remove_duplicate(model.params, model.grads) # 共有された重みを1つに集約\n",
        "        if max_grad is not None:\n",
        "          clip_grads(grads, max_grad)\n",
        "        optimizer.update(params, grads)\n",
        "        total_loss += loss\n",
        "        loss_count += 1\n",
        "\n",
        "        # パープレキシティの評価\n",
        "        if (eval_interval is not None) and (iter % eval_interval) == 0:\n",
        "          ppl = np.exp(total_loss / loss_count)\n",
        "          elapsed_time = time.time() - start_time\n",
        "          print('| epoch %d | iter %d / %d | time %d[s] | perplexity %.2f'\n",
        "                % (self.current_epoch + 1, iters + 1, max_iters, elapsed_time, ppl))\n",
        "          self.ppl_list.append(float(ppl))\n",
        "          total_loss, loss_count = 0.0\n",
        "\n",
        "      self.current_epoch += 1\n",
        "\n",
        "  def plot(self, ylim=None):\n",
        "    x = numpy.arange(len(self.ppl_list))\n",
        "    if ylim is not None:\n",
        "      plt.ylim(*ylim)\n",
        "    plt.plot(x, self.ppl_list, label='train')\n",
        "    plt.xlabel('iterations (x' + str(self.eval_interval) + ')' )\n",
        "    plt.ylabel('perplexity')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORA8xupLL3SH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f7482e50-dbcc-4b95-d259-fd758f779a00"
      },
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "from common.optimizer import SGD\n",
        "from common.trainer import RnnlmTrainer\n",
        "from dataset import ptb\n",
        "from ch05.simple_rnnlm import SimpleRnnlm\n",
        "\n",
        "\n",
        "# ハイパーパラメータの設定\n",
        "batch_size = 10\n",
        "wordvec_size = 100\n",
        "hidden_size = 100  # RNNの隠れ状態ベクトルの要素数\n",
        "time_size = 5  # RNNを展開するサイズ\n",
        "lr = 0.1\n",
        "max_epoch = 100\n",
        "\n",
        "# 学習データの読み込み\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "corpus_size = 1000  # テスト用にデータセットを小さくする\n",
        "corpus = corpus[:corpus_size]\n",
        "vocab_size = int(max(corpus) + 1)\n",
        "xs = corpus[:-1]  # 入力\n",
        "ts = corpus[1:]  # 出力（教師ラベル）\n",
        "\n",
        "# モデルの生成\n",
        "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
        "optimizer = SGD(lr)\n",
        "trainer = RnnlmTrainer(model, optimizer)\n",
        "\n",
        "trainer.fit(xs, ts, max_epoch, batch_size, time_size)\n",
        "trainer.plot()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| epoch 1 |  iter 1 / 19 | time 0[s] | perplexity 418.15\n",
            "| epoch 2 |  iter 1 / 19 | time 0[s] | perplexity 404.58\n",
            "| epoch 3 |  iter 1 / 19 | time 0[s] | perplexity 306.41\n",
            "| epoch 4 |  iter 1 / 19 | time 0[s] | perplexity 229.08\n",
            "| epoch 5 |  iter 1 / 19 | time 0[s] | perplexity 213.15\n",
            "| epoch 6 |  iter 1 / 19 | time 0[s] | perplexity 209.82\n",
            "| epoch 7 |  iter 1 / 19 | time 0[s] | perplexity 201.53\n",
            "| epoch 8 |  iter 1 / 19 | time 0[s] | perplexity 201.23\n",
            "| epoch 9 |  iter 1 / 19 | time 0[s] | perplexity 194.96\n",
            "| epoch 10 |  iter 1 / 19 | time 0[s] | perplexity 189.51\n",
            "| epoch 11 |  iter 1 / 19 | time 0[s] | perplexity 192.12\n",
            "| epoch 12 |  iter 1 / 19 | time 0[s] | perplexity 188.55\n",
            "| epoch 13 |  iter 1 / 19 | time 0[s] | perplexity 191.23\n",
            "| epoch 14 |  iter 1 / 19 | time 0[s] | perplexity 186.55\n",
            "| epoch 15 |  iter 1 / 19 | time 1[s] | perplexity 184.70\n",
            "| epoch 16 |  iter 1 / 19 | time 1[s] | perplexity 188.47\n",
            "| epoch 17 |  iter 1 / 19 | time 1[s] | perplexity 187.44\n",
            "| epoch 18 |  iter 1 / 19 | time 1[s] | perplexity 184.13\n",
            "| epoch 19 |  iter 1 / 19 | time 1[s] | perplexity 179.90\n",
            "| epoch 20 |  iter 1 / 19 | time 1[s] | perplexity 181.98\n",
            "| epoch 21 |  iter 1 / 19 | time 1[s] | perplexity 178.97\n",
            "| epoch 22 |  iter 1 / 19 | time 1[s] | perplexity 178.14\n",
            "| epoch 23 |  iter 1 / 19 | time 1[s] | perplexity 177.58\n",
            "| epoch 24 |  iter 1 / 19 | time 1[s] | perplexity 175.52\n",
            "| epoch 25 |  iter 1 / 19 | time 1[s] | perplexity 170.48\n",
            "| epoch 26 |  iter 1 / 19 | time 1[s] | perplexity 169.85\n",
            "| epoch 27 |  iter 1 / 19 | time 1[s] | perplexity 171.19\n",
            "| epoch 28 |  iter 1 / 19 | time 1[s] | perplexity 170.83\n",
            "| epoch 29 |  iter 1 / 19 | time 2[s] | perplexity 165.63\n",
            "| epoch 30 |  iter 1 / 19 | time 2[s] | perplexity 163.30\n",
            "| epoch 31 |  iter 1 / 19 | time 2[s] | perplexity 160.79\n",
            "| epoch 32 |  iter 1 / 19 | time 2[s] | perplexity 155.89\n",
            "| epoch 33 |  iter 1 / 19 | time 2[s] | perplexity 153.56\n",
            "| epoch 34 |  iter 1 / 19 | time 2[s] | perplexity 154.12\n",
            "| epoch 35 |  iter 1 / 19 | time 2[s] | perplexity 145.48\n",
            "| epoch 36 |  iter 1 / 19 | time 2[s] | perplexity 143.28\n",
            "| epoch 37 |  iter 1 / 19 | time 2[s] | perplexity 147.04\n",
            "| epoch 38 |  iter 1 / 19 | time 2[s] | perplexity 136.63\n",
            "| epoch 39 |  iter 1 / 19 | time 2[s] | perplexity 135.17\n",
            "| epoch 40 |  iter 1 / 19 | time 2[s] | perplexity 128.59\n",
            "| epoch 41 |  iter 1 / 19 | time 2[s] | perplexity 125.06\n",
            "| epoch 42 |  iter 1 / 19 | time 2[s] | perplexity 121.64\n",
            "| epoch 43 |  iter 1 / 19 | time 3[s] | perplexity 117.98\n",
            "| epoch 44 |  iter 1 / 19 | time 3[s] | perplexity 114.01\n",
            "| epoch 45 |  iter 1 / 19 | time 3[s] | perplexity 106.10\n",
            "| epoch 46 |  iter 1 / 19 | time 3[s] | perplexity 103.84\n",
            "| epoch 47 |  iter 1 / 19 | time 3[s] | perplexity 103.02\n",
            "| epoch 48 |  iter 1 / 19 | time 3[s] | perplexity 98.33\n",
            "| epoch 49 |  iter 1 / 19 | time 3[s] | perplexity 93.01\n",
            "| epoch 50 |  iter 1 / 19 | time 3[s] | perplexity 87.90\n",
            "| epoch 51 |  iter 1 / 19 | time 3[s] | perplexity 85.36\n",
            "| epoch 52 |  iter 1 / 19 | time 3[s] | perplexity 79.89\n",
            "| epoch 53 |  iter 1 / 19 | time 3[s] | perplexity 80.21\n",
            "| epoch 54 |  iter 1 / 19 | time 3[s] | perplexity 74.32\n",
            "| epoch 55 |  iter 1 / 19 | time 3[s] | perplexity 68.84\n",
            "| epoch 56 |  iter 1 / 19 | time 4[s] | perplexity 65.80\n",
            "| epoch 57 |  iter 1 / 19 | time 4[s] | perplexity 63.89\n",
            "| epoch 58 |  iter 1 / 19 | time 4[s] | perplexity 59.89\n",
            "| epoch 59 |  iter 1 / 19 | time 4[s] | perplexity 57.25\n",
            "| epoch 60 |  iter 1 / 19 | time 4[s] | perplexity 52.35\n",
            "| epoch 61 |  iter 1 / 19 | time 4[s] | perplexity 48.16\n",
            "| epoch 62 |  iter 1 / 19 | time 4[s] | perplexity 46.61\n",
            "| epoch 63 |  iter 1 / 19 | time 4[s] | perplexity 45.96\n",
            "| epoch 64 |  iter 1 / 19 | time 4[s] | perplexity 43.17\n",
            "| epoch 65 |  iter 1 / 19 | time 4[s] | perplexity 38.81\n",
            "| epoch 66 |  iter 1 / 19 | time 4[s] | perplexity 36.25\n",
            "| epoch 67 |  iter 1 / 19 | time 4[s] | perplexity 34.85\n",
            "| epoch 68 |  iter 1 / 19 | time 4[s] | perplexity 33.97\n",
            "| epoch 69 |  iter 1 / 19 | time 4[s] | perplexity 32.03\n",
            "| epoch 70 |  iter 1 / 19 | time 5[s] | perplexity 29.92\n",
            "| epoch 71 |  iter 1 / 19 | time 5[s] | perplexity 28.00\n",
            "| epoch 72 |  iter 1 / 19 | time 5[s] | perplexity 26.37\n",
            "| epoch 73 |  iter 1 / 19 | time 5[s] | perplexity 25.37\n",
            "| epoch 74 |  iter 1 / 19 | time 5[s] | perplexity 24.06\n",
            "| epoch 75 |  iter 1 / 19 | time 5[s] | perplexity 22.62\n",
            "| epoch 76 |  iter 1 / 19 | time 5[s] | perplexity 21.62\n",
            "| epoch 77 |  iter 1 / 19 | time 5[s] | perplexity 20.27\n",
            "| epoch 78 |  iter 1 / 19 | time 5[s] | perplexity 18.83\n",
            "| epoch 79 |  iter 1 / 19 | time 5[s] | perplexity 17.85\n",
            "| epoch 80 |  iter 1 / 19 | time 5[s] | perplexity 16.59\n",
            "| epoch 81 |  iter 1 / 19 | time 5[s] | perplexity 15.51\n",
            "| epoch 82 |  iter 1 / 19 | time 6[s] | perplexity 15.05\n",
            "| epoch 83 |  iter 1 / 19 | time 6[s] | perplexity 14.39\n",
            "| epoch 84 |  iter 1 / 19 | time 6[s] | perplexity 13.68\n",
            "| epoch 85 |  iter 1 / 19 | time 6[s] | perplexity 12.69\n",
            "| epoch 86 |  iter 1 / 19 | time 6[s] | perplexity 12.05\n",
            "| epoch 87 |  iter 1 / 19 | time 6[s] | perplexity 11.62\n",
            "| epoch 88 |  iter 1 / 19 | time 6[s] | perplexity 10.57\n",
            "| epoch 89 |  iter 1 / 19 | time 6[s] | perplexity 11.06\n",
            "| epoch 90 |  iter 1 / 19 | time 6[s] | perplexity 9.49\n",
            "| epoch 91 |  iter 1 / 19 | time 6[s] | perplexity 8.97\n",
            "| epoch 92 |  iter 1 / 19 | time 6[s] | perplexity 8.70\n",
            "| epoch 93 |  iter 1 / 19 | time 6[s] | perplexity 8.48\n",
            "| epoch 94 |  iter 1 / 19 | time 6[s] | perplexity 7.79\n",
            "| epoch 95 |  iter 1 / 19 | time 7[s] | perplexity 7.71\n",
            "| epoch 96 |  iter 1 / 19 | time 7[s] | perplexity 7.02\n",
            "| epoch 97 |  iter 1 / 19 | time 7[s] | perplexity 6.83\n",
            "| epoch 98 |  iter 1 / 19 | time 7[s] | perplexity 6.59\n",
            "| epoch 99 |  iter 1 / 19 | time 7[s] | perplexity 6.15\n",
            "| epoch 100 |  iter 1 / 19 | time 7[s] | perplexity 5.90\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxcdb3/8dcny2SZLE3SdKFbWroBha7UIpWlIpuyyCYCisK9iAqCcq8i3p/b9XrxKiKgcEFRERDKla0g+45gS1foRqF0X5M0afY9n98fcxrSkrYpzWQmM+/n45FH5pw5M/M5nDLvfL/nnO/X3B0RERGAlFgXICIi8UOhICIiHRQKIiLSQaEgIiIdFAoiItIhLdYFHIz+/ft7SUlJrMsQEelTFi5cWO7uxV0916dDoaSkhAULFsS6DBGRPsXM1u/tOXUfiYhIB4WCiIh0UCiIiEgHhYKIiHRQKIiISAeFgoiIdFAoiIhIh6QMhaWbqvjFM++iYcNFRHaXlKGwaEMld7zyAfPWVsS6FBGRuJKUoXDBtGEUhUPc/soHsS5FRCSuJGUoZIVSuWzmSF57r4xlm6tiXY6ISNxIylAAuGTGCHIy0rhDrQURkQ5JGwr5WelcMmMETy3bypqy2liXIyISF5I2FAAunzmSUGoKd766JtaliIjEhaiHgpmlmtliM3syWB5pZvPMbLWZzTazULA+I1heHTxfEu3ainMzuGDaMB5ZvImq+pZof5yISNzrjZbCNcDKTsu/AG5299FAJXB5sP5yoDJYf3OwXdRNH1lIS5uzvaaxNz5ORCSuRTUUzGwo8FngD8GyAbOAvwWb3AOcHTw+K1gmeP7TwfZRlZ+VDkBVg1oKIiLRbin8Bvgu0B4sFwE73b01WN4EDAkeDwE2AgTPVwXb78bMrjCzBWa2oKys7KAL7AgFdR+JiEQvFMzsc0Cpuy/syfd197vcfZq7Tysu7nKK0QOyKxSqGxUKIiLRnKP5WOBMMzsdyATygFuAfmaWFrQGhgKbg+03A8OATWaWBuQDO6JYHwB56j4SEekQtZaCu3/f3Ye6ewlwIfCSu18MvAycF2x2KfB48HhOsEzw/EveCyPW5WVGclGhICISm/sUvgd8x8xWEzlncHew/m6gKFj/HeD63igmLTWFnIw0hYKICNHtPurg7q8ArwSP1wDTu9imETi/N+rZU35WOtUNrfvfUEQkwSX1Hc275GaqpSAiAgoFYFdLQaEgIqJQIAgFXZIqIqJQgMhlqeo+EhFRKACRloJCQUREoQBEQqG+uY2Wtvb9bywiksAUCnQa6kKtBRFJcgoFIC9LdzWLiIBCAdDw2SIiuygUUCiIiOyiUKDz8Nka6kJEkptCAcjLVEtBRAQUCsCHcyro6iMRSXYKBSAzPZWMtBSFgogkPYVCQENdiIgoFDpoqAsREYVCB4WCiIhCoYOGzxYRUSh0yNPsayIiCoVd8rPSqapXKIhIclMoBPKz0qlpaqW93WNdiohIzCgUAnlZ6bhDTZOGuhCR5KVQCOiuZhERhUIHjZQqIqJQ6KDZ10REFAodNFKqiIhCoUN+tkJBREShEPhwoh2FgogkL4VCIBxKJTXF1FIQkaSmUAiYmYa6EJGkp1DoJDJSqm5eE5HkpVDoJD8rXZekikhSUyh0otnXRCTZKRQ6yVNLQUSSnEKhE82+JiLJTqHQya7Z19w1fLaIJCeFQid5mem0tDkNLW2xLkVEJCYUCp1opFQRSXYKhU4UCiKS7KIWCmaWaWZvmdnbZrbczH4SrB9pZvPMbLWZzTazULA+I1heHTxfEq3a9qYgGBSvsk6hICLJKZothSZglrtPBCYBp5rZDOAXwM3uPhqoBC4Ptr8cqAzW3xxs16uKcjIA2FHX1NsfLSISF6IWCh5RGyymBz8OzAL+Fqy/Bzg7eHxWsEzw/KfNzKJVX1cKwyEAKuqae/NjRUTiRlTPKZhZqpktAUqB54EPgJ3uvmuAoU3AkODxEGAjQPB8FVDUxXteYWYLzGxBWVlZj9a7q/toR61CQUSSU1RDwd3b3H0SMBSYDozvgfe8y92nufu04uLig66xs7TUFPplp6ulICJJq1euPnL3ncDLwDFAPzNLC54aCmwOHm8GhgEEz+cDO3qjvs4KwyGdUxCRpBXNq4+Kzaxf8DgL+Aywkkg4nBdsdinwePB4TrBM8PxLHoNbi/uHM9R9JCJJK23/m3xsg4F7zCyVSPg85O5PmtkK4EEz+xmwGLg72P5u4F4zWw1UABdGsba9KgyH+KCsdv8biogkoKiFgru/A0zuYv0aIucX9lzfCJwfrXq6qzAnxPx1aimISHLSHc17KAqHqKxvpq1dg+KJSPJRKOyhKByi3WFnvVoLIpJ8FAp7KAzuatZlqSKSjBQKeygK7mreoVAQkSSkUNiDhroQkWSmUNiDWgoikswUCnso2BUKtbqrWUSSj0JhD+mpKeRnafwjEUlOCoUuFIVD6j4SkaSkUOhCYThEhcY/EpEkpFDoQmE4pO4jEUlKCoUuFOVkaPhsEUlKCoUuRMY/aqFd4x+JSJJRKHShMByird2pamiJdSkiIr2qW6FgZo+Y2WfNLClCpChHN7CJSHLq7pf87cBFwPtmdqOZjYtiTTFXFI4Miqcb2EQk2XQrFNz9BXe/GJgCrANeMLM3zeyrZpYezQJjQeMfiUiy6nZ3kJkVAV8B/oXINJq3EAmJ56NSWQyp+0hEklW3puM0s0eBccC9wBnuvjV4araZLYhWcbFSkK2Wgogkp+7O0fx7d3+q8wozy3D3JnefFoW6YiqUlkJuZppCQUSSTne7j37Wxbp/9mQh8aZ/TgblOtEsIklmny0FMxsEDAGyzGwyYMFTeUB2lGuLKQ11ISLJaH/dR6cQObk8FPh1p/U1wA1RqikuFIZDbKyoj3UZIiK9ap+h4O73APeY2bnu/nAv1RQXisIhlmzcGesyRER61f66jy5x9/uAEjP7zp7Pu/uvu3hZQijKCVFZ10x7u5OSYvt/gYhIAthf91E4+J0T7ULiTWE4g9Z2p7qxhX7BJaoiIoluf91Hdwa/f7Lnc2aW0N+UReEPb2BTKIhIsujugHivmFlJp+WjgflRqiku7BrqorRal6WKSPLo7s1r/w08Y2a3ErlE9TTgq1GrKg5MGJJPKDWFZ5dv45hDi2JdjohIr+jugHjPAlcSGe/oMuB0d18UzcJirTAc4pQJg3hk0SYaW9piXY6ISK/obvfR/wNuA44Dfgy8YmafjWJdceGi6cOpbmzlyXe27n9jEZEE0N1hLoqA6e7+z+Dk8ynAtdErKz7MGFXIqOIwf523PtaliIj0iu52H10LsGtyHXdf7+6fiWZh8cDMuGj6cBZt2Mm726pjXY6ISNR1t/voDGAJ8EywPMnM5kSzsHhx7pShhNJS+Ou8DbEuRUQk6rrbffRjYDqwE8DdlwCjolRTXCkIhzh9wiAeXbSZ+ubWWJcjIhJV3Q2FFnev2mNde08XE68umTGCmqZWzv7dGzyzbCvuHuuSRESioruhsNzMLgJSzWyMmd0GvBnFuuLKtJJC/veSKbS2O1fet4gzf/sGH5TVxrosEZEe191QuBo4AmgCHgCqSYKrjzo7dcJgnrv2OP7nvKPYvLOBf71nATWNLbEuS0SkR3X36qN6d/+Bux/t7tOCx43RLi7epKWmcMG0Ydx+8RTWV9TzvYffUVeSiCSUfYaCmT1hZnP29rOf1w4zs5fNbIWZLTeza4L1hWb2vJm9H/wuCNabmd1qZqvN7B0zm9Jzu9mzZowq4runjOOppdu4+x9rY12OiEiP2d/YR786iPduBa5z90VmlgssNLPniczk9qK732hm1wPXA98jMp7SmODnE8Adwe+4dMVxo1i4vpIbn36XVdtqyM1MJycjlTMmHsKYgbmxLk9E5GOx7nZ/BENljwccWOXuBzSBsZk9Dvw2+DnB3bea2WDgFXcfZ2Z3Bo8fCLZftWu7vb3ntGnTfMGCBQdSRo+qbmzhm/cv4r3tNdQ1tVHX3EpuRhr3Xv4JJg7rF7O6RET2xcwWuvu0rp7r1iipwThH/wt8ABgw0sy+5u5Pd/P1JcBkYB4wsNMX/TZgYPB4CLCx08s2Bet2CwUzuwK4AmD48OHd+fioyctM597LP2zMbKyo56I/zOWSP8zjz5dNZ+qIghhWJyJy4Lp79dFNwInufoK7Hw+cCNzcnReaWQ7wMHCtu+82VoRHmikHdKbW3e8KTnZPKy4uPpCXRt2wwmxmX3EMRTkhvnz3POau2RHrkkREDkh3Q6HG3Vd3Wl4D1OzvRWaWTiQQ7nf3R4LV24NuI4LfpcH6zcCwTi8fGqzrUw7pl8Xsrx3DoPxMvnz3Wzy6eNNuzze3ttPSljT3/YlIH9PdSXYWmNlTwENE/rI/H5hvZucAdPrC72BmBtwNrHT3X3d6ag5wKXBj8PvxTuuvMrMHiZxgrtrX+YR4NjAvk4e//kmuvG8h3579NmvL6znjqMH89a0NPLxwE6kpxrUnjeWiTwwnPTWFspomZs/fQE1TK988cTR5memx3gURSVLdOtFsZn/ax9Pu7pd18ZqZwOvAUj4cEuMGIucVHgKGA+uBC9y9IgiR3wKnAvXAV919n2eRY32ieX+aW9v5waNL+b+FkdZCeqpxyhGDKK9tYu6aCkb1D3P4IXk8u3wbLW1OisGQgixu++IUJnVxorq6sYU3V5czKD+LQ4vD5Co8RORj2NeJ5v2GgpmlAt9y926dQ+hN8R4KAO7O/fM2UNfUyrlTh9I/JwN356V3S/n5UysprW7i3KlDuWTGCKoamvnWA0vYXt3IVbNGc87koQwvyqa93Xl40SZ+8cwqyms/nDN6SL8sLv3kCL40o4SsUGoM91JE+pKDCoXgDd5y9+k9XtlB6guhsC/ujjukpFjHuqr6Fm54dCl/XxrpORtVHCYrPZXlW6qZMrwf3/7MWOqb2/igrJY3V+/gH6vLKc7N4KoTR3d0R4mI7EtPhMLNQDowG6jbtT7W8zT39VDYl7XldbyyqpSXV5WxZWcDXz/+UD4/echuAQIwb80ObnruPd5aV8ERh+Txy/MmcvgheQC0tTurttUwoiibcEZ3Tx+JSKLriVB4uYvV7u6zDra4g5HIoXAg3J1nl2/jPx5bzs76Zi7/1EhqG1t5dvl2ymub6JedzqXHlHDpJ0soDIdiXa6IxNhBh0K8UijsrrKumZ8+uYJHF28mO5TKieMGcNzY/ry4spTnVmwnKz2VycP7Mawgm+FF2QzMy6QoJ0T/cAajisNqTYgkiZ5oKQwEfg4c4u6nmdnhwDHufnfPlnpgFApd27CjngF5GWSmf3jy+f3tNfz5zXWs2FrNxoqG3U5YA4TSUjhuTDGnThjEyUcM1GWxIgmsJ0LhaeBPwA/cfaKZpQGL3f3Ini31wCgUPr765lbKapoor22mrKaJuWt28OzybWytamRgXga3XzxVw3SIJKieCIX57n60mS1298nBuiXuPqmHaz0gCoWe5e7MX1fJv/3f22ytauCHZxzBJZ8YTuQWkg+1tTs1jS1kh9IIpelqJ5G+5qAHxAPqzKyIYJwiM5sB7Dlns/RxZsb0kYU8cdVMrp29mP/32DLmLNlMSVGYgXmZtLS18/amnSzdVEVdcxsAGWkpjCjK5qbzJ3Hk0PwY74GIHKzuthSmALcRmZJzOVAMnOfu70S3vH1TSyF62tudO179gGeWbaO0ppHy2mZSzThscC5HDe3HiKJsGlvaqGlq5cm3t1Je28T/nHcUZ00aEuvSRWQ/eqL7KBO4CjiFyEB4/wRui/WUnAqF3tPW7rS7d3lzXHltE9+4fxFvra3g8pkj+foJh9I/JyMGVYpId/REKDwEVAP3B6suAvq5+/k9VuXHoFCIHy1t7fz0iRXcO3c9qSnG8WOLOWfKEE46bOBuV0GJSOz1RCiscPfD97eutykU4s9722t4ZNFmHl+yma1VjfTLTuecyUO5cPowxmqaUpG4sK9Q6O6lI4uCk8u73vATgL6N5SPGDszl+tPG84/vzeLey6dz7Oj+3Dt3HSff/Br/+eQKzSUhEue6e/XRVOBNM9sQLA8HVpnZUiLDXRwVleqkz0pNMT41pphPjSlmR20Tv3nhfe7+x1qWbNzJby+azOD8rFiXKCJd6G730Yh9Pe/u63usogOg7qO+5Ym3t3D9w++QkZ7K5TNHctakQxhakB3rskSSjsY+krixurSW/3hsKXPXVABwdEkB2aE0dtQ1Ud3QytWzRnP+tGH7eRcRORg9cfOaSI8YPSCHB684ho0V9Ty2eDPPLN9GY0s7xTkZtLXDDx5dxmGD85gwRDfCicSCWgoSNyrrmjn91tfJSEvhiatnarpRkSjpiauPRKKuIBzi1i9OZmNlAzc8uow9/2Bxd55ZtpWF6ytiVKFI4lP3kcSVo0sK+fZJY/jVc++RlZ7C+dOGMXV4Acu3VPPjJ5azcH0l+VnpvHjd8bprWiQKFAoSd75+wmi2VDXy8MJNPLRgE8W5GZTXNlGYHeLfTxnHb154j/9+6l1uumBirEsVSTgKBYk7qSnGzz9/JDecfhgvrNjOs8u3Mbwwm2+cOJr8rHTqm1v53csfcN7UoRxzaFGsyxVJKDrRLH1OQ3MbJ//mVUKpKTx9zXGa00HkAOlEsySUrFAqPz1zAh+U1fGjOct4e+NODZ8h0kPUfSR90onjB3D+1KE88NZGHnhrI5npKZw2YTD/fc6RGpVV5CAoFKTP+uX5E7nu5HEs2lDJmx+Uc9/cDVQ3tHDHJVPVpSTyMen/HOnTBuVncvqRg/nZ2Ufys7Mn8OK7pVz9wCJ1J4l8TAoFSRiXzBjBj844nGeXb+cb9y+itDqmEwOK9EkKBUkoXz12JD/83OG8sqqU43/5Cr9+/j3qmlpjXZZIn6FQkIRz2cyRvPCd45k1fgC3vvg+x//yFf7yz3U0t6pLSWR/FAqSkEYUhfndxVN45BufZFRxmB8+vpyTfv0qjy/ZTHt73703RyTaFAqS0KYML2D2FTP401ePJpyRxjUPLuGcO95k0YbKWJcmEpcUCpLwzIwTxw3g71fP5FfnT2TLzgbOuf1NrnlwMdt1MlpkNwoFSRopKcZ5U4fy8r+dwNWzRvP0sm2cdNOr3PPmOtrUpSQCKBQkCYUz0rju5HE8d+1xTBrejx/NWc45t7+hS1hFUChIEivpH+Yvl03nlgsn8d72Wq68byFNrW2xLkskphQKktTMjLMmDeFX509k0Yad/PCx5R+Z8U0kmSgURIDPHjWYq2eNZvaCjdw7d32syxGJGQ2IJxL49kljWbm1mp88sYKVW2s4a9IhTC8pJCXFYl2aSK+JWiiY2R+BzwGl7j4hWFcIzAZKgHXABe5eaWYG3AKcDtQDX3H3RdGqTaQrKSnGzV+YxI/nrODxJZt54K0NDMrLZMKQPIYWZDOsMJszJg5mQG5mrEsViZqozbxmZscBtcBfOoXC/wAV7n6jmV0PFLj798zsdOBqIqHwCeAWd//E/j5DM69JtNQ3t/LCylKeXbaND8pq2VTZQG1TK0XhEDddMJETxg2IdYkiH9u+Zl6L6nScZlYCPNkpFFYBJ7j7VjMbDLzi7uPM7M7g8QN7brev91coSG9xd1Ztr+HaB5fw7rYa/vVTI/n3U8Zr3gbpk+JpOs6Bnb7otwEDg8dDgI2dttsUrPsIM7vCzBaY2YKysrLoVSrSiZkxflAej33zWL40YwS/f30tF/1+LuW1TbEuTaRHxezPHI80UQ64meLud7n7NHefVlxcHIXKRPYuMz2V/zx7Ard9cTJLN1dx1m/fYOXW6liXJdJjejsUtgfdRgS/S4P1m4FhnbYbGqwTiUtnTDyE/7vyGFrb2zn3jjd5Ztm2WJck0iN6OxTmAJcGjy8FHu+0/ssWMQOo2t/5BJFYO2poP+ZcNZMxA3O58r6F3PTcKg3LLX1e1ELBzB4A/gmMM7NNZnY5cCPwGTN7HzgpWAZ4ClgDrAZ+D3wjWnWJ9KSBeZnMvmIG508dym0vrebye+ZTVd8S67JEPraoXn0Ubbr6SOKFu3PfvA38ZM5yMtNTOXPSIXzx6OEcOTQ/1qWJfMS+rj7SHc0iPcDM+NKMEUwe1o8/vrGWhxdu4q/zNnDc2GJuu3Ay+dnpsS5RpFvUUhCJgqqGFmbP38Avn13F8MJs/vSV6Qwvyo51WSJADG9eizaFgsS7uWt28LV7F5KaYnz3lHGYQW1TGyVF2Xz6sIH7fwORKFAoiMTQmrJaLvvzfNbtqN9t/bdmjebbnxlLZOgvkd6jcwoiMTSqOIdnrj2ODRX1hDPSyEpP5canV3LrS6upqG/mJ2dOIFUjsUqcUCiI9ILM9FTGDsztWP7FuUdREA5x56trqKxr4aYLJpKZnhrDCkUiFAoiMWBmfP+0w+gfzuC/nlrJtupG7vrSVIpyMmJdmiQ5DfEoEkP/etwobr94Css2V/H5299kdWltrEuSJKdQEImx048czINXzKC+uZWzfvsPbnz6XcpqNPqqxIZCQSQOTB5ewGPfPJYTxw/grtc+4NhfvMQNjy7lzdXltLS1x7o8SSK6JFUkzqwtr+POVz/gkcWbaW5tJzcjjRPGD+CaT49h9ICcWJcnCUD3KYj0QfXNrfzj/XJeereUvy/dSlNLO18/4VC+fsKhulJJDopCQaSPK6tp4md/X8HjS7Ywsn+YK48fxZkTh5AVUjjIgVMoiCSI194r47/+vpJV22vIy0zj3KlDuerE0bqUVQ6I7mgWSRDHjS3mU2P6M39dJffNXc99c9fz9NJt/O7iyUwdURjr8iQB6OojkT7GzJg+spBbvziZR79xLKG0FL5w51zu/sda+nLLX+KDQkGkD5swJJ8nrp7JrPED+M8nV3Dpn+azeWdDrMuSPkyhINLH5Welc+eXpvLTs45gwboKTv71q9z7z3W0ab5o+Rh0olkkgWysqOeGR5fy+vvl5GWmcXRJIdNHFjJmYA4DcjMZmJdJ/5yQhutOcjrRLJIkhhVm85fLpvPs8u28+l4p89ZW8OK7pbttM6p/mK8cW8K5U4YSztBXgOxOLQWRBFde28SGinpKq5vYsrOBx9/ewtsbd5KbmcblM0fyjRNGE0pTT3IyUUtBJIn1z8mgf6f7GC6bOZJFGyr5/Wtr+M0L7/P8iu3cdMFExg/Ki2GVEi/054FIEpoyvIA7LpnKXV+ayvbqRs687Q1+9ewqtlbpyqVkp+4jkSRXUdfMDx9fxpPvbCXFYNb4AZw9eQjTRhQyKD8z1uVJFGiYCxHZrw076nlw/gYeWrCJ8trIfA6D8zOZMCSfkqJshheFGTMgh6kjCkhPVSdDX6ZQEJFua2lrZ/mWahZvqGTxhp2s3FrNhop6mloj8zrkZqRx/LhiPnP4QE4cP4C8zPQYVywHSqEgIgelvd0prWninU07eXFlKS++W0p5bROh1BQ+NaY/p04YxKzxAzQwXx+hq49E5KCkpBiD8jMZlD+Ik48YRHu7s3hjJU8t3cbTS7fy4rulmMHU4QXMOmwAM0f354hD8klN0U1yfY1aCiJyUNydpZureGFlKS+u3M7yLdUA5GamMb2kkMMG53HogDCHFucwdmCuJgiKA+o+EpFeU1rdyD/X7GDumh28tbaCdTvqO8ZhSksxxg7MZeKwfCYN68eU4QUcWpxDiloUvUqhICIx09zazoaKOt7fXsuyLVW8synyU9XQAkBeZhrjB+dxaHEOhxaHOXxwHkcOzSdXJ7CjRucURCRmQmkpjB6Qy+gBuZx25GAg0uW0pryOhesjVzi9v72Gp5dtZWd9JCjM4NDiHCYN68fUEQVMGV7AmAFqUfQGtRREJG7sqG1i2ZZq3t64kyUbd7J4QyWVQVBkpKUwsn+YUcVhxgzIZcKQfCYMyWNQXqZGfT1AaimISJ9QlJPB8WOLOX5sMRBpUazbUc+i9ZW8u62aNWV1rNhSzTPLtrFruoiicIgxAyMnsUf2D1MYDpGflU5hOMTAvEyKwiHSdLNdtykURCRumRkj+4cZ2T+82/r65lZWbq1m6aYqVm6t4b3SGh5ZtJnaptaPvEeKRQYFHJyfyaD8TA7pl8XI/pGroUYVhxmQm6lLZztRKIhIn5MdSmPqiEKmjijsWOfuVNQ1s7OhhZ31LVTUNbO9upHS6ka2VjWyrbqRNWV1vP5+OfXNbR2v2xUaA/IyKMgOkZeVTr+sdIYXZjNmYA6HFucAUFnfQmV9M4fkZyX0+Q2FgogkBDOjKCdjv3dVuzvbq5tYU1bLmvK6IDiaKK1pZGdDC5t3NnSEyt4UZKdzdEkh4wblUpAdoignRF5mOlmhVLJDqWSlp5KRlkpmegq5wfq+QqEgIknFbNfd2Zl8cnT/vW5XVd/C6rIaVpfWkpqSQkF2OvlZ6awtr2Pe2greWlvBCyu3052psPOz0hmUl0lhOERaqpGaYmSkpTAoL5OB+ZkU52SQmZ5KKC2FjLQUMtMjwZIdSiU/K528rPReu+lPVx+JiHxM7e1OVUMLO+qaqWlsoaG5jfrmNhpa2mhqbaexpY2qhha2B11YlXXNtLnT3u40tLSxraqR6saPngfpSkZaCuGMtEgrJD2Fa08ay5kTD/lYdfeZq4/M7FTgFiAV+IO73xjjkkRE9iolxSgIhygIhz72e9Q3t1Je00xTayRImlrbaWqJBEtdcxvVDS1UBT8NQeA0tLRRkB2dm/viJhTMLBX4HfAZYBMw38zmuPuK2FYmIhI92aE0hhfFzVdxXE3HOR1Y7e5r3L0ZeBA4K8Y1iYgklXgKhSHAxk7Lm4J1uzGzK8xsgZktKCsr67XiRESSQTyFQre4+13uPs3dpxUXF8e6HBGRhBJPobAZGNZpeWiwTkREekk8hcJ8YIyZjTSzEHAhMCfGNYmIJJW4OeXt7q1mdhXwLJFLUv/o7stjXJaISFKJm1AAcPengKdiXYeISLKKp+4jERGJsT49zIWZlQHrP+bL+wPlPVhOX5GM+52M+wzJud/JuM9w4Ps9wt27vHyzT4fCwTCzBXsb+yORJeN+J+M+Q3LudzLuM/Tsfqv7SEREOigURESkQzKHwl2xLjhge8EAAAcsSURBVCBGknG/k3GfITn3Oxn3GXpwv5P2nIKIiHxUMrcURERkDwoFERHpkJShYGanmtkqM1ttZtfHup5oMLNhZvayma0ws+Vmdk2wvtDMnjez94PfBbGutaeZWaqZLTazJ4PlkWY2Lzjes4OxtRKKmfUzs7+Z2btmttLMjkmSY/3t4N/3MjN7wMwyE+14m9kfzazUzJZ1WtflsbWIW4N9f8fMphzo5yVdKHSa4e004HDgi2Z2eGyriopW4Dp3PxyYAXwz2M/rgRfdfQzwYrCcaK4BVnZa/gVws7uPBiqBy2NSVXTdAjzj7uOBiUT2P6GPtZkNAb4FTHP3CUTGTLuQxDvefwZO3WPd3o7tacCY4OcK4I4D/bCkCwWSZIY3d9/q7ouCxzVEviSGENnXe4LN7gHOjk2F0WFmQ4HPAn8Ilg2YBfwt2CQR9zkfOA64G8Ddm919Jwl+rANpQJaZpQHZwFYS7Hi7+2tAxR6r93ZszwL+4hFzgX5mNvhAPi8ZQ6FbM7wlEjMrASYD84CB7r41eGobMDBGZUXLb4DvAu3BchGw091bg+VEPN4jgTLgT0G32R/MLEyCH2t33wz8CthAJAyqgIUk/vGGvR/bg/5+S8ZQSCpmlgM8DFzr7tWdn/PI9cgJc02ymX0OKHX3hbGupZelAVOAO9x9MlDHHl1FiXasAYJ+9LOIhOIhQJiPdrMkvJ4+tskYCkkzw5uZpRMJhPvd/ZFg9fZdzcngd2ms6ouCY4EzzWwdkW7BWUT62vsF3QuQmMd7E7DJ3ecFy38jEhKJfKwBTgLWunuZu7cAjxD5N5Doxxv2fmwP+vstGUMhKWZ4C/rS7wZWuvuvOz01B7g0eHwp8Hhv1xYt7v59dx/q7iVEjutL7n4x8DJwXrBZQu0zgLtvAzaa2bhg1aeBFSTwsQ5sAGaYWXbw733Xfif08Q7s7djOAb4cXIU0A6jq1M3ULUl5R7OZnU6k73nXDG//FeOSepyZzQReB5byYf/6DUTOKzwEDCcy7PgF7r7nSaw+z8xOAP7N3T9nZqOItBwKgcXAJe7eFMv6epqZTSJycj0ErAG+SuSPvoQ+1mb2E+ALRK62Wwz8C5E+9IQ53mb2AHACkeGxtwM/Ah6ji2MbhONviXSj1QNfdfcFB/R5yRgKIiLStWTsPhIRkb1QKIiISAeFgoiIdFAoiIhIB4WCiIh0UChIn2dmbwa/S8zsoh5+7xu6+qxoMbOzzeyH+9nml8FoqO+Y2aNm1q/Tc98PRshcZWanBOtCZvZapxu6RPZKoSB9nrt/MnhYAhxQKHTji3K3UOj0WdHyXeD2/WzzPDDB3Y8C3gO+DxCMgnshcASR69RvN7PUYODHF4lczy+yTwoF6fPMrDZ4eCPwKTNbEoyznxr8VT0/+Kv6a8H2J5jZ62Y2h8gdsJjZY2a2MBib/4pg3Y1ERuBcYmb3d/6s4I7RXwbj+C81sy90eu9X7MO5De4PbijCzG60yPwW75jZr7rYj7FAk7uXB8uPm9mXg8df21WDuz/XacC3uUSGMoDIOEAPunuTu68FVhMZFRgiNztd3AP/uSXBqTkpieR6gruYAYIv9yp3P9rMMoA3zOy5YNspRP7aXhssXxbcEZoFzDezh939ejO7yt0ndfFZ5wCTiMxd0D94zWvBc5OJ/LW+BXgDONbMVgKfB8a7u3fu8unkWGBRp+UrgprXAtcRmRdjT5cBs4PHQ4iExC6dR8hcBhzdxetFdqOWgiSyk4mMA7OEyPAeRUQmHwF4q1MgAHzLzN4m8qU6rNN2ezMTeMDd29x9O/AqH37pvuXum9y9HVhCpFurCmgE7jazc4gMQbCnwUSGwAYgeN8fEhnL57o9h6gwsx8QGd7h/v3Uiru3Ac1mlru/bSW5qaUgicyAq9392d1WRsZFqttj+STgGHevN7NXgMyD+NzO4+y0AWnu3mpm04kM2nYecBWRUVw7awDy91h3JLCDyNDQnffhK8DngE/7h2PV7G+EzAwiwSSyV2opSCKpATr/Jfws8PVgCHHMbGww+cye8oHKIBDGs3s3Tcuu1+/hdeALwXmLYiIzn721t8KCeS3y3f0p4NtEup32tBIY3ek104lMrzgZ+DczGxmsP5XICekz3b1zi2MOcKGZZQTbjtlVk5kVAeXBENMie6WWgiSSd4C2oBvoz0TmUigBFgUne8voemrGZ4Arg37/VezeL38X8I6ZLQqG4d7lUeAY4G0iE5x81923BaHSlVzgcTPLJNKC+U4X27wG3BTUGgJ+T2SUyy1mdh3wRzObRWQUzAzg+eAc9lx3v9Ldl5vZQ0ROnrcC3wy6jQBOBP6+l9pEOmiUVJE4Yma3AE+4+ws9/L6PANe7+3s9+b6SeNR9JBJffk5kAvoeY5HJpB5TIEh3qKUgIiId1FIQEZEOCgUREemgUBARkQ4KBRER6aBQEBGRDv8frfK9gef+74EAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fePKPi9nVQcL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}