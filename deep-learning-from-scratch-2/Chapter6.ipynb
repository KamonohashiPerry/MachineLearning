{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPfiQuqSJaln8OOUNt9UzKg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KamonohashiPerry/MachineLearning/blob/master/deep-learning-from-scratch-2/Chapter6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM-kCCbYFzmU",
        "colab_type": "text"
      },
      "source": [
        "# ゲート付きRNN\n",
        "+ 単純なRNNでは時系列データの長期の依存関係をうまく学習することはできない。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SJ8QOaGGjup",
        "colab_type": "text"
      },
      "source": [
        "## RNNの問題点\n",
        "+ BPTTにおいて勾配消失もしくは勾配爆発問題が起こることに原因がある。\n",
        " + ようは、長い時点をさかのぼっての、誤差逆伝播法がうまくいかないということ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpHISicxHfPS",
        "colab_type": "text"
      },
      "source": [
        "### RNNの復習\n",
        "+ RNNレイヤは時系列データである\\\\(x_t\\\\)を入力すると\\\\( h_t\\\\)を出力する。この\\\\( h_t\\\\)はRNNレイヤの隠れ状態とも呼ばれ、過去からの情報が記憶される。\n",
        "+ RNNレイヤの順伝播で行う計算は、「行列の積と和、そして活性化関数であるtanh関数による変換」から構成される。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLsCth1dqGq2",
        "colab_type": "text"
      },
      "source": [
        "### 勾配消失もしくは勾配爆発\n",
        "+ RNNレイヤが過去方向に「意味のある勾配」を伝達することによって、時間方向の依存関係を学習することができる。\n",
        " + この勾配が途中で弱まったら、ほとんど何も情報をもたなくなったら、重みのパラメータは更新されなくなる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEcszfPErMWn",
        "colab_type": "text"
      },
      "source": [
        "### 勾配消失もしくは勾配爆発の原因\n",
        "+ 逆伝播において勾配がtanhノードを通るたびに、その値はどんどん小さくなっていく。\n",
        " + tanh関数をT回通過すれば、勾配はT回も繰り返し弱められることになる。\n",
        "   + ReLUを使えば勾配消失を抑えることができる。\n",
        "    + 入力xが0異常であれば、逆伝播では上流の勾配をそのまま下流に流すことになり、勾配の劣化が起こらないから。 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irLczolOFbTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "N = 2 # バッチサイズ\n",
        "H = 3 # 隠れ状態ベクトルの次元数\n",
        "T = 20 # 時系列データの長さ\n",
        "\n",
        "dh = np.ones((N, H)) # 初期化\n",
        "np.random.seed(3) # 再現性のため乱数のシードを固定\n",
        "Wh = np.random.randn(H, H)\n",
        "\n",
        "norm_list = []\n",
        "for t in range(T):\n",
        "  dh = np.dot(dh, Wh.T) # 更新\n",
        "  norm = np.sqrt(np.sum(dh**2)) / N\n",
        "  norm_list.append(norm)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y39Uznaw9dzn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "5aeb4919-7980-4f03-da9d-012ce3e9713b"
      },
      "source": [
        "norm_list"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.4684068094579303,\n",
              " 3.335704974161037,\n",
              " 4.783279375373183,\n",
              " 6.2795873320876145,\n",
              " 8.080776465019055,\n",
              " 10.25116303229294,\n",
              " 12.9360635066099,\n",
              " 16.276861327786712,\n",
              " 20.454829618345983,\n",
              " 25.688972842084684,\n",
              " 32.25315718048336,\n",
              " 40.48895641683869,\n",
              " 50.824407307019094,\n",
              " 63.79612654485427,\n",
              " 80.07737014308985,\n",
              " 100.51298922051251,\n",
              " 126.16331847536827,\n",
              " 158.3592064825883,\n",
              " 198.77107967611957,\n",
              " 249.495615421267]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zhILJuZ9Lrv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "84feeb8e-320c-410a-9ff8-7326c8a4a82f"
      },
      "source": [
        "# グラフの描画\n",
        "plt.plot(np.arange(len(norm_list)), norm_list)\n",
        "plt.xticks([0, 4, 9, 14, 19], [1, 5, 10, 15, 20])\n",
        "plt.xlabel('time step')\n",
        "plt.ylabel('norm')\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZhA44a-9mws",
        "colab_type": "text"
      },
      "source": [
        "勾配の大きさは時間とともに指数関数的に増加していく。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkyKL7n79abE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dh = np.ones((N, H)) # 初期化\n",
        "np.random.seed(3) # 再現性のため乱数のシードを固定\n",
        "Wh = np.random.randn(H, H) * 0.5\n",
        "\n",
        "norm_list = []\n",
        "for t in range(T):\n",
        "  dh = np.dot(dh, Wh.T) # 更新\n",
        "  norm = np.sqrt(np.sum(dh**2)) / N\n",
        "  norm_list.append(norm)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxQfFLSK90us",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "8733865c-f55b-4087-d95d-3c004db5cb1b"
      },
      "source": [
        "# グラフの描画\n",
        "plt.plot(np.arange(len(norm_list)), norm_list)\n",
        "plt.xticks([0, 4, 9, 14, 19], [1, 5, 10, 15, 20])\n",
        "plt.xlabel('time step')\n",
        "plt.ylabel('norm')\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdrWifqR95s-",
        "colab_type": "text"
      },
      "source": [
        "今度は勾配が指数的に減少している。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxstlRN-DGS",
        "colab_type": "text"
      },
      "source": [
        "行列\\\\( Wh\\\\)をT回繰り返して乗算しているので、指数的な変化が起きてしまう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIgfw2u5-29C",
        "colab_type": "text"
      },
      "source": [
        "### 勾配爆発への対策\n",
        "+ 勾配クリッピング\n",
        " + 勾配のL2ノルムが閾値を超えた場合に勾配を修正する。\n",
        "\n",
        "$$ if \\ \\| \\hat g \\| \\ \\geq threshold \\\\\n",
        "\\hat g = \\frac{threshold}{\\| \\hat g \\|}\\hat g $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiME8Y8092k_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "dW1 = np.random.rand(3, 3) * 10\n",
        "dW2 = np.random.rand(3, 3) * 10\n",
        "grads = [dW1, dW2]\n",
        "max_norm = 5.0\n",
        "\n",
        "def clip_grads(grads, max_norm):\n",
        "  total_norm = 0\n",
        "  for grad in grads:\n",
        "    total_norm += np.sum(grad ** 2)\n",
        "  total_norm = np.sqrt(total_norm)\n",
        "\n",
        "  rate = max_norm / (total_norm + 1e-6)\n",
        "  if rate < 1:\n",
        "    for grad in grads:\n",
        "      grad *= rate\n",
        "\n",
        "clip_grads(grads, max_norm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqNejyJ6CJMj",
        "colab_type": "text"
      },
      "source": [
        "## 勾配消失とLSTM\n",
        "+ RNNの学習の際に問題となる、勾配消失問題を解消したい。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5jo1MlwCwL4",
        "colab_type": "text"
      },
      "source": [
        "### LSTMのインタフェース\n",
        "+ LSTMにはRNNにはない、記憶セルというものがある。\n",
        "+ LSTMの出力を受け取る側から見ると、LSTMの出力は隠れ状態ベクトルのhだけになり、記憶セルcの情報は外部には見えない。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFSVrdKBEDoe",
        "colab_type": "text"
      },
      "source": [
        "### LSTMレイヤの組み立て\n",
        "+ 現在の記憶セル\\\\( c_t\\\\)は3つの入力（\\\\( c_{t-1}, h_{t-1}, x_{t}\\\\)）から何らかの計算によって求めることができる。\n",
        "+ 更新された\\\\( c_t\\\\)を使って、隠れ状態の\\\\( h_t\\\\)が計算される。\n",
        "+ LSTMで使用するゲートは、開く・閉じるの二択ではなく、どれだけゲートを開くか、そしてそれによって、どのくらいの量の水を次へ流すかということをコントロールする。それに関してもデータから自動的に学ばせる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjinpiR0JPKL",
        "colab_type": "text"
      },
      "source": [
        "### outputゲート\n",
        "+ \\\\(  \\tanh (c_t) \\\\)の各要素に対して、それらが次時刻の隠れ状態としてどれだけ重要かということを調整し、\\\\( h_t \\\\)をコントロールする。\n",
        "+ outputゲートの開き具合は\\\\( x_t\\\\)と前の状態\\\\( h_{t-1}\\\\)から求める。\n",
        "\n",
        "$$ o = \\sigma ( x_t W^{(o)}_x + h_{t-1}W_h^{(o)} + b^{(o)}) $$\n",
        "\n",
        "出力はアダマール積で計算\n",
        "$$ h_t = o \\odot \\tanh (c_t) $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN8bnvRZSKwL",
        "colab_type": "text"
      },
      "source": [
        "### forgetゲート\n",
        "+ 記憶セルに対して、何を忘れるかを明示的に指示すること。\n",
        "+ \\\\( c_{t-1}\\\\)の記憶から、不要な記憶を忘れるためのゲートを追加する。\n",
        "\n",
        "$$ f = \\sigma (x_t W_x^{(f)} + h_{t-1}W_{h}^{(f)} + b^{(f)} ) $$\n",
        "\n",
        "\n",
        "出力はアダマール積で計算\n",
        "$$c_t = f \\odot c_{t-1}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYtLJt1wTQMT",
        "colab_type": "text"
      },
      "source": [
        "### 新しい記憶セル\n",
        "+ 新しく覚えるべき情報を記憶セルに追加する。\n",
        " + tanhノードを新たに追加する。\n",
        "\n",
        "\n",
        "$$g = \\tanh (x_t W_x^{(g)} + h_{t-1}W_h^{(g)} + b^{(g)})$$\n",
        "\n",
        "新しい情報を記憶セルに追加することが目的のため、活性化関数にsigmoidではなく、tanh関数を使う。0-1でなくてもいいということ。\n",
        "\n",
        "gが\\\\( c_{t-1}\\\\)に加算されることで、新しい記憶が生まれる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-P3fAMMU4Ui",
        "colab_type": "text"
      },
      "source": [
        "### inputゲート\n",
        "+ gの各要素が新たに追加する情報として、どれだけの価値があるかを判断する。追加する情報の取捨選択を行う。\n",
        "\n",
        "$$ i = \\sigma ( x_t W_x^{(i)} + h_{t-1} W_h^{(i)} + b^{(i)} ) $$\n",
        "\n",
        "出力はアダマール積で計算\n",
        "$$ g \\odot i $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5M9f5v8V8Am",
        "colab_type": "text"
      },
      "source": [
        "### LSTMの勾配の流れ\n",
        "+ LSTMの逆伝播では、行列の積の計算ではなく、要素ごとの積が計算される。\n",
        " + 毎時刻、異なるゲート値によって要素ごとの積の計算が行われる。その結果、勾配消失が起きない。\n",
        " + 忘れるべきと判断した記憶セルの要素に対しては、その勾配の要素は小さくなる。\n",
        " + 忘れてはいけないと導いた要素に対しては、その勾配の要素は劣化することなく過去方向へ伝わる。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4VUC9fuihxl",
        "colab_type": "text"
      },
      "source": [
        "## LSTMの実装\n",
        "\n",
        "$$ f = \\sigma ( x_t W_x^{(f)} + h_{t-1}W_h^{(f)} + b^{(f)} ) \\\\\n",
        "g = \\tanh(x_tW_x^{(g)} + h_{t-1}W_h^{(g)} +b^{(g)}) \\\\\n",
        "i = \\sigma(x_tW_x^{(i)} + h_{t-1}W_h^{(i)} + b^{(i)}) \\\\\n",
        "o = \\sigma(x_tW_x^{(o)} + h_{t-1}W_h^{(o)} + b^{(o)}) \\\\\n",
        "\\\\\n",
        "c_t = f \\odot c_{t-1}+ g \\odot i \\\\\n",
        "h_t = o \\odot \\tanh(c_t) $$\n",
        "\n",
        "\n",
        "+ ここに出てくる4つの重みに関してまとめて処理する。\n",
        "+ 行列ライブラリは大きな行列としてまとめて計算したほうが多くの場合、計算が高速化される。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl1pV62qByen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM:\n",
        "  def __init__(self, Wx, Wh, b):\n",
        "    self.params = [Wx, Wh, b] # パラメータ\n",
        "    self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)] # 勾配\n",
        "    self.cache = None # 順伝播での中間結果を保持\n",
        "\n",
        "  def forward(self, x, h_prev, c_prev):\n",
        "    Wx, Wh, b = self.params\n",
        "    N, H = h_prev.shape\n",
        "\n",
        "    # アフィン変換：平行移動を伴う線型写像\n",
        "    A = np.dot(x, Wx) + np.dot(h_prev, Wh) + b\n",
        "\n",
        "    # 4つ分の重みをまとめて保持するので、スライスする必要がある。\n",
        "    # slice\n",
        "    f = A[:, :H]\n",
        "    g = A[:, H:2*H]\n",
        "    i = A[:, 2*H:3*H]\n",
        "    o = A[:, 3*H:]\n",
        "\n",
        "    # シグモイドやらハイパボリックタンジェントをかます\n",
        "    f = sigmoid(f)\n",
        "    g = np.tanh(g)\n",
        "    i = sigmoid(i)\n",
        "    o = sigmoid(o)\n",
        "\n",
        "    # 上の式にある通り\n",
        "    c_next = f*c_prev + g*i\n",
        "    h_next = o*np.tanh(c_next)\n",
        "\n",
        "    self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
        "    return h_next, c_next\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP-IANsEwwsy",
        "colab_type": "text"
      },
      "source": [
        "### TimeLSTMの実装\n",
        "+ T個分の時系列データをまとめて処理するレイヤ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHs0Cp1Iq38_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TimeLSTM:\n",
        "  def __init__(self, Wx, Wh, b, stateful=False):\n",
        "    self.params = [Wx, Wh, b]\n",
        "    self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
        "    self.layers = None\n",
        "\n",
        "    self.h, self.c = None, None\n",
        "    self.dh = None\n",
        "    self.stateful = stateful # 状態を維持するかどうかを指定\n",
        "\n",
        "  def forward(self, xs):\n",
        "    Wx, Wh, b = self.params\n",
        "    N, T, D = xs.shape\n",
        "    H = Wh.shape[0]\n",
        "\n",
        "    self.layers = []\n",
        "    # 初期化\n",
        "    hs = np.empty((N, T, H), dtype='f')\n",
        "\n",
        "    # 隠れ状態hと記憶セルcの初期化\n",
        "    if not self.stateful or self.h is None:\n",
        "      self.h = np.zeros_like((N, H), dtype='f')\n",
        "    if not self.stateful or self.c is None:\n",
        "      self.c = np.zeros_like((N, H), dtype='f')\n",
        "\n",
        "    # 時点の数だけ繰り返す\n",
        "    for t in range(T):\n",
        "      layer = LSTM(*self.params)\n",
        "      self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
        "      hs[:, t, :] = self.h\n",
        "\n",
        "      self.layers.append(layer)\n",
        "\n",
        "    return hs\n",
        "  \n",
        "  def backward(self, dhs):\n",
        "    Wx, Wh, b = self.params\n",
        "    N, T, H = dhs.shape\n",
        "    D = Wx.shape[0]\n",
        "\n",
        "    dxs = np.empty((N, T, D), dtype='f')\n",
        "    dh, dc = 0, 0\n",
        "\n",
        "    grads = [0, 0, 0]\n",
        "    # 逆の時点から繰り返す\n",
        "    for t in reversed(range(T)):\n",
        "      layer = self.layers[t]\n",
        "      dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
        "      dxs[:, t, :] = dx\n",
        "      for i, grad in enumerate(layer.grads):\n",
        "        grads[i] += grad\n",
        "\n",
        "    for i, grad in enumerate(grads):\n",
        "      self.grads[i][...] = grads\n",
        "\n",
        "    self.dh = dh\n",
        "    return dxs\n",
        "\n",
        "  def set_state(self, h, c=None):\n",
        "    self.h, self.c = h, c\n",
        "\n",
        "  def reset_state(self):\n",
        "    self.h, self.c = None, None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6er8dQ9l7cEx",
        "colab_type": "text"
      },
      "source": [
        "## LSTMを使った言語モデル"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaZVLL3j5IEg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "48afb579-9448-4e61-b19f-430cf3f09290"
      },
      "source": [
        "!git clone https://github.com/oreilly-japan/deep-learning-from-scratch-2.git"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deep-learning-from-scratch-2'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 378 (delta 0), reused 0 (delta 0), pack-reused 373\u001b[K\n",
            "Receiving objects: 100% (378/378), 7.91 MiB | 11.21 MiB/s, done.\n",
            "Resolving deltas: 100% (210/210), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqLqTVK0dRpT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb3d7c7a-0bf8-4e21-c5da-c634c4ec4227"
      },
      "source": [
        "cd deep-learning-from-scratch-2"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deep-learning-from-scratch-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-h9F91PdUXt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "051122d1-edf5-46a1-fbed-e059872e5694"
      },
      "source": [
        "ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mch01\u001b[0m/  \u001b[01;34mch03\u001b[0m/  \u001b[01;34mch05\u001b[0m/  \u001b[01;34mch07\u001b[0m/  \u001b[01;34mcommon\u001b[0m/   LICENSE.md\n",
            "\u001b[01;34mch02\u001b[0m/  \u001b[01;34mch04\u001b[0m/  \u001b[01;34mch06\u001b[0m/  \u001b[01;34mch08\u001b[0m/  \u001b[01;34mdataset\u001b[0m/  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1cWNfONdWw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "from common.time_layers import *\n",
        "import pickle\n",
        "\n",
        "class Rnnlm:\n",
        "  def __init__(self, vocab_size=10000, wordvec_size=100,\n",
        "               hidden_size=100):\n",
        "    V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "    rn = np.random.randn\n",
        "\n",
        "    # 重みの初期化\n",
        "    embed_W = (rn(V, D) / 100).astype('f')\n",
        "    lstm_Wx = (rn(D, 4*H) / np.sqrt(D)).astype('f')\n",
        "    lstm_Wh = (rn(H, 4*H) / np.sqrt(H)).astype('f')\n",
        "    lstm_b = np.zeros(4*H).astype('f')\n",
        "    affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
        "    affine_b = np.zeros(V).astype('f')\n",
        "\n",
        "    # レイヤの生成\n",
        "    self.layers = [\n",
        "                   TimeEmbedding(embed_W),\n",
        "                   TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n",
        "                   TimeAffine(affine_W, affine_b)\n",
        "    ]\n",
        "    self.loss_layer = TimeSoftmaxWithLoss()\n",
        "    self.lstm_layer = self.layers[1]\n",
        "\n",
        "    # すべての重みと勾配をリストにまとめる\n",
        "    self.params, self.grads = [], []\n",
        "    for layer in self.layers:\n",
        "      self.params += layer.params\n",
        "      self.grads += layer.grads\n",
        "\n",
        "  def predict(self, xs):\n",
        "    for layer in self.layers:\n",
        "      xs = layer.forward(xs)\n",
        "    return xs\n",
        "\n",
        "  def forward(self, xs, ts):\n",
        "    score = self.predict(xs)\n",
        "    loss = self.loss_layer.forward(score, ts)\n",
        "    return loss\n",
        "\n",
        "  def backward(self, dout=1):\n",
        "    dout = self.loss_layer.backward(dout)\n",
        "    for layer in reversed(self.layers):\n",
        "      dout = layer.backward(dout)\n",
        "    return dout\n",
        "\n",
        "  def reset_state(self):\n",
        "    self.lstm_layer.reset_state()\n",
        "\n",
        "  # パラメータの書き込み\n",
        "  def save_params(self, file_name='Rnnlm.pkl'):\n",
        "    with open(file_name, 'wb') as f:\n",
        "      pickle.dump(self.params, f)\n",
        "\n",
        "  # パラメータの読み込み\n",
        "  def load_params(self, file_name='Rnnlm.pkl'):\n",
        "    with open(file_name, 'rb') as f:\n",
        "      self.params = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzNc7B7sspnX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b9d9e3e6-1ae9-44dd-a8c4-f27fb4e2c37b"
      },
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "from common.optimizer import SGD\n",
        "from common.trainer import RnnlmTrainer\n",
        "from common.util import eval_perplexity\n",
        "from dataset import ptb\n",
        "from ch06.rnnlm import Rnnlm\n",
        "\n",
        "# ハイパーパラメータの設定\n",
        "batch_size = 20\n",
        "wordvec_size = 100\n",
        "hidden_size = 100 # RNNの隠れ状態ベクトルの要素数\n",
        "time_size = 35 # RNNを展開するサイズ\n",
        "lr = 20.0\n",
        "max_epoch = 4\n",
        "max_grad = 0.25\n",
        "\n",
        "# 学習データの読み込み\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "corpus_test, _, _ = ptb.load_data('test')\n",
        "vocab_size = len(word_to_id)\n",
        "xs = corpus[:-1]\n",
        "ts = corpus[1:]\n",
        "\n",
        "# モデルの生成\n",
        "model = Rnnlm(vocab_size, wordvec_size, hidden_size)\n",
        "optimizer = SGD(lr)\n",
        "trainer = RnnlmTrainer(model, optimizer)\n",
        "\n",
        "# STEP1:勾配クリッピングを適用して学習\n",
        "# モデルの勾配を求め、モデルのパラメータを更新する\n",
        "# max_gradで勾配の爆発を防ぐ\n",
        "# eval_intervalでパープレキシティを計算するイタレーションの単位を決める\n",
        "trainer.fit(xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval=20)\n",
        "# パープレキシティに関して可視化\n",
        "trainer.plot(ylim=(0, 500))\n",
        "\n",
        "# STEP2:テストデータで評価\n",
        "# モデルの状態をリセットしてからテストデータでのパープレキシティを評価する\n",
        "model.reset_state()\n",
        "ppl_test = eval_perplexity(model, corpus_test)\n",
        "print('test perplexity: ', ppl_test)\n",
        "\n",
        "# STEP3:パラメータの保存\n",
        "model.save_params()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading ptb.train.txt ... \n",
            "Done\n",
            "Downloading ptb.test.txt ... \n",
            "Done\n",
            "| epoch 1 |  iter 1 / 1327 | time 0[s] | perplexity 9999.69\n",
            "| epoch 1 |  iter 21 / 1327 | time 7[s] | perplexity 2965.95\n",
            "| epoch 1 |  iter 41 / 1327 | time 13[s] | perplexity 1247.29\n",
            "| epoch 1 |  iter 61 / 1327 | time 20[s] | perplexity 969.02\n",
            "| epoch 1 |  iter 81 / 1327 | time 27[s] | perplexity 783.35\n",
            "| epoch 1 |  iter 101 / 1327 | time 34[s] | perplexity 653.61\n",
            "| epoch 1 |  iter 121 / 1327 | time 41[s] | perplexity 641.88\n",
            "| epoch 1 |  iter 141 / 1327 | time 47[s] | perplexity 600.89\n",
            "| epoch 1 |  iter 161 / 1327 | time 54[s] | perplexity 579.60\n",
            "| epoch 1 |  iter 181 / 1327 | time 61[s] | perplexity 579.73\n",
            "| epoch 1 |  iter 201 / 1327 | time 68[s] | perplexity 502.86\n",
            "| epoch 1 |  iter 221 / 1327 | time 75[s] | perplexity 502.25\n",
            "| epoch 1 |  iter 241 / 1327 | time 82[s] | perplexity 456.13\n",
            "| epoch 1 |  iter 261 / 1327 | time 88[s] | perplexity 470.11\n",
            "| epoch 1 |  iter 281 / 1327 | time 95[s] | perplexity 461.30\n",
            "| epoch 1 |  iter 301 / 1327 | time 102[s] | perplexity 392.89\n",
            "| epoch 1 |  iter 321 / 1327 | time 109[s] | perplexity 353.23\n",
            "| epoch 1 |  iter 341 / 1327 | time 115[s] | perplexity 406.85\n",
            "| epoch 1 |  iter 361 / 1327 | time 122[s] | perplexity 408.12\n",
            "| epoch 1 |  iter 381 / 1327 | time 129[s] | perplexity 341.20\n",
            "| epoch 1 |  iter 401 / 1327 | time 136[s] | perplexity 354.57\n",
            "| epoch 1 |  iter 421 / 1327 | time 142[s] | perplexity 346.78\n",
            "| epoch 1 |  iter 441 / 1327 | time 149[s] | perplexity 334.04\n",
            "| epoch 1 |  iter 461 / 1327 | time 156[s] | perplexity 329.74\n",
            "| epoch 1 |  iter 481 / 1327 | time 163[s] | perplexity 312.58\n",
            "| epoch 1 |  iter 501 / 1327 | time 170[s] | perplexity 318.75\n",
            "| epoch 1 |  iter 521 / 1327 | time 176[s] | perplexity 307.64\n",
            "| epoch 1 |  iter 541 / 1327 | time 183[s] | perplexity 316.11\n",
            "| epoch 1 |  iter 561 / 1327 | time 190[s] | perplexity 290.63\n",
            "| epoch 1 |  iter 581 / 1327 | time 197[s] | perplexity 261.26\n",
            "| epoch 1 |  iter 601 / 1327 | time 203[s] | perplexity 337.97\n",
            "| epoch 1 |  iter 621 / 1327 | time 210[s] | perplexity 316.26\n",
            "| epoch 1 |  iter 641 / 1327 | time 217[s] | perplexity 285.25\n",
            "| epoch 1 |  iter 661 / 1327 | time 224[s] | perplexity 269.89\n",
            "| epoch 1 |  iter 681 / 1327 | time 230[s] | perplexity 230.71\n",
            "| epoch 1 |  iter 701 / 1327 | time 237[s] | perplexity 251.52\n",
            "| epoch 1 |  iter 721 / 1327 | time 244[s] | perplexity 260.55\n",
            "| epoch 1 |  iter 741 / 1327 | time 251[s] | perplexity 226.57\n",
            "| epoch 1 |  iter 761 / 1327 | time 257[s] | perplexity 236.64\n",
            "| epoch 1 |  iter 781 / 1327 | time 264[s] | perplexity 221.09\n",
            "| epoch 1 |  iter 801 / 1327 | time 271[s] | perplexity 242.54\n",
            "| epoch 1 |  iter 821 / 1327 | time 278[s] | perplexity 225.87\n",
            "| epoch 1 |  iter 841 / 1327 | time 284[s] | perplexity 230.38\n",
            "| epoch 1 |  iter 861 / 1327 | time 291[s] | perplexity 221.34\n",
            "| epoch 1 |  iter 881 / 1327 | time 298[s] | perplexity 208.32\n",
            "| epoch 1 |  iter 901 / 1327 | time 305[s] | perplexity 254.01\n",
            "| epoch 1 |  iter 921 / 1327 | time 312[s] | perplexity 228.83\n",
            "| epoch 1 |  iter 941 / 1327 | time 318[s] | perplexity 233.14\n",
            "| epoch 1 |  iter 961 / 1327 | time 325[s] | perplexity 246.95\n",
            "| epoch 1 |  iter 981 / 1327 | time 332[s] | perplexity 230.45\n",
            "| epoch 1 |  iter 1001 / 1327 | time 338[s] | perplexity 193.83\n",
            "| epoch 1 |  iter 1021 / 1327 | time 345[s] | perplexity 227.11\n",
            "| epoch 1 |  iter 1041 / 1327 | time 352[s] | perplexity 207.71\n",
            "| epoch 1 |  iter 1061 / 1327 | time 359[s] | perplexity 197.78\n",
            "| epoch 1 |  iter 1081 / 1327 | time 366[s] | perplexity 168.72\n",
            "| epoch 1 |  iter 1101 / 1327 | time 372[s] | perplexity 190.25\n",
            "| epoch 1 |  iter 1121 / 1327 | time 379[s] | perplexity 231.29\n",
            "| epoch 1 |  iter 1141 / 1327 | time 386[s] | perplexity 207.01\n",
            "| epoch 1 |  iter 1161 / 1327 | time 393[s] | perplexity 197.89\n",
            "| epoch 1 |  iter 1181 / 1327 | time 399[s] | perplexity 190.10\n",
            "| epoch 1 |  iter 1201 / 1327 | time 406[s] | perplexity 162.75\n",
            "| epoch 1 |  iter 1221 / 1327 | time 413[s] | perplexity 159.61\n",
            "| epoch 1 |  iter 1241 / 1327 | time 420[s] | perplexity 187.34\n",
            "| epoch 1 |  iter 1261 / 1327 | time 427[s] | perplexity 172.18\n",
            "| epoch 1 |  iter 1281 / 1327 | time 433[s] | perplexity 177.31\n",
            "| epoch 1 |  iter 1301 / 1327 | time 440[s] | perplexity 221.74\n",
            "| epoch 1 |  iter 1321 / 1327 | time 447[s] | perplexity 210.67\n",
            "| epoch 2 |  iter 1 / 1327 | time 449[s] | perplexity 221.61\n",
            "| epoch 2 |  iter 21 / 1327 | time 456[s] | perplexity 203.92\n",
            "| epoch 2 |  iter 41 / 1327 | time 463[s] | perplexity 190.31\n",
            "| epoch 2 |  iter 61 / 1327 | time 469[s] | perplexity 174.52\n",
            "| epoch 2 |  iter 81 / 1327 | time 476[s] | perplexity 160.39\n",
            "| epoch 2 |  iter 101 / 1327 | time 483[s] | perplexity 152.21\n",
            "| epoch 2 |  iter 121 / 1327 | time 490[s] | perplexity 160.57\n",
            "| epoch 2 |  iter 141 / 1327 | time 496[s] | perplexity 176.48\n",
            "| epoch 2 |  iter 161 / 1327 | time 503[s] | perplexity 192.49\n",
            "| epoch 2 |  iter 181 / 1327 | time 510[s] | perplexity 201.71\n",
            "| epoch 2 |  iter 201 / 1327 | time 517[s] | perplexity 183.98\n",
            "| epoch 2 |  iter 221 / 1327 | time 523[s] | perplexity 182.75\n",
            "| epoch 2 |  iter 241 / 1327 | time 530[s] | perplexity 175.95\n",
            "| epoch 2 |  iter 261 / 1327 | time 537[s] | perplexity 185.77\n",
            "| epoch 2 |  iter 281 / 1327 | time 543[s] | perplexity 185.44\n",
            "| epoch 2 |  iter 301 / 1327 | time 550[s] | perplexity 166.49\n",
            "| epoch 2 |  iter 321 / 1327 | time 557[s] | perplexity 137.85\n",
            "| epoch 2 |  iter 341 / 1327 | time 564[s] | perplexity 173.88\n",
            "| epoch 2 |  iter 361 / 1327 | time 570[s] | perplexity 198.30\n",
            "| epoch 2 |  iter 381 / 1327 | time 577[s] | perplexity 152.56\n",
            "| epoch 2 |  iter 401 / 1327 | time 583[s] | perplexity 167.91\n",
            "| epoch 2 |  iter 421 / 1327 | time 590[s] | perplexity 153.61\n",
            "| epoch 2 |  iter 441 / 1327 | time 596[s] | perplexity 161.94\n",
            "| epoch 2 |  iter 461 / 1327 | time 603[s] | perplexity 156.75\n",
            "| epoch 2 |  iter 481 / 1327 | time 610[s] | perplexity 155.28\n",
            "| epoch 2 |  iter 501 / 1327 | time 616[s] | perplexity 167.96\n",
            "| epoch 2 |  iter 521 / 1327 | time 623[s] | perplexity 174.11\n",
            "| epoch 2 |  iter 541 / 1327 | time 629[s] | perplexity 174.39\n",
            "| epoch 2 |  iter 561 / 1327 | time 636[s] | perplexity 157.06\n",
            "| epoch 2 |  iter 581 / 1327 | time 642[s] | perplexity 137.20\n",
            "| epoch 2 |  iter 601 / 1327 | time 649[s] | perplexity 189.19\n",
            "| epoch 2 |  iter 621 / 1327 | time 655[s] | perplexity 180.55\n",
            "| epoch 2 |  iter 641 / 1327 | time 662[s] | perplexity 163.91\n",
            "| epoch 2 |  iter 661 / 1327 | time 668[s] | perplexity 152.87\n",
            "| epoch 2 |  iter 681 / 1327 | time 675[s] | perplexity 129.35\n",
            "| epoch 2 |  iter 701 / 1327 | time 681[s] | perplexity 149.61\n",
            "| epoch 2 |  iter 721 / 1327 | time 688[s] | perplexity 159.12\n",
            "| epoch 2 |  iter 741 / 1327 | time 694[s] | perplexity 132.99\n",
            "| epoch 2 |  iter 761 / 1327 | time 701[s] | perplexity 131.96\n",
            "| epoch 2 |  iter 781 / 1327 | time 708[s] | perplexity 135.11\n",
            "| epoch 2 |  iter 801 / 1327 | time 714[s] | perplexity 146.53\n",
            "| epoch 2 |  iter 821 / 1327 | time 721[s] | perplexity 144.01\n",
            "| epoch 2 |  iter 841 / 1327 | time 727[s] | perplexity 143.50\n",
            "| epoch 2 |  iter 861 / 1327 | time 734[s] | perplexity 143.19\n",
            "| epoch 2 |  iter 881 / 1327 | time 740[s] | perplexity 128.88\n",
            "| epoch 2 |  iter 901 / 1327 | time 747[s] | perplexity 166.09\n",
            "| epoch 2 |  iter 921 / 1327 | time 754[s] | perplexity 147.54\n",
            "| epoch 2 |  iter 941 / 1327 | time 760[s] | perplexity 153.85\n",
            "| epoch 2 |  iter 961 / 1327 | time 767[s] | perplexity 162.79\n",
            "| epoch 2 |  iter 981 / 1327 | time 773[s] | perplexity 154.21\n",
            "| epoch 2 |  iter 1001 / 1327 | time 779[s] | perplexity 130.56\n",
            "| epoch 2 |  iter 1021 / 1327 | time 786[s] | perplexity 154.65\n",
            "| epoch 2 |  iter 1041 / 1327 | time 792[s] | perplexity 142.38\n",
            "| epoch 2 |  iter 1061 / 1327 | time 799[s] | perplexity 128.39\n",
            "| epoch 2 |  iter 1081 / 1327 | time 805[s] | perplexity 110.49\n",
            "| epoch 2 |  iter 1101 / 1327 | time 812[s] | perplexity 119.01\n",
            "| epoch 2 |  iter 1121 / 1327 | time 818[s] | perplexity 153.64\n",
            "| epoch 2 |  iter 1141 / 1327 | time 824[s] | perplexity 139.99\n",
            "| epoch 2 |  iter 1161 / 1327 | time 831[s] | perplexity 131.39\n",
            "| epoch 2 |  iter 1181 / 1327 | time 837[s] | perplexity 133.41\n",
            "| epoch 2 |  iter 1201 / 1327 | time 844[s] | perplexity 111.38\n",
            "| epoch 2 |  iter 1221 / 1327 | time 850[s] | perplexity 108.85\n",
            "| epoch 2 |  iter 1241 / 1327 | time 857[s] | perplexity 130.06\n",
            "| epoch 2 |  iter 1261 / 1327 | time 863[s] | perplexity 124.02\n",
            "| epoch 2 |  iter 1281 / 1327 | time 870[s] | perplexity 121.79\n",
            "| epoch 2 |  iter 1301 / 1327 | time 876[s] | perplexity 156.72\n",
            "| epoch 2 |  iter 1321 / 1327 | time 883[s] | perplexity 152.07\n",
            "| epoch 3 |  iter 1 / 1327 | time 885[s] | perplexity 160.76\n",
            "| epoch 3 |  iter 21 / 1327 | time 891[s] | perplexity 143.65\n",
            "| epoch 3 |  iter 41 / 1327 | time 898[s] | perplexity 135.01\n",
            "| epoch 3 |  iter 61 / 1327 | time 904[s] | perplexity 126.05\n",
            "| epoch 3 |  iter 81 / 1327 | time 911[s] | perplexity 117.07\n",
            "| epoch 3 |  iter 101 / 1327 | time 918[s] | perplexity 105.47\n",
            "| epoch 3 |  iter 121 / 1327 | time 924[s] | perplexity 115.72\n",
            "| epoch 3 |  iter 141 / 1327 | time 931[s] | perplexity 125.05\n",
            "| epoch 3 |  iter 161 / 1327 | time 937[s] | perplexity 140.44\n",
            "| epoch 3 |  iter 181 / 1327 | time 944[s] | perplexity 151.33\n",
            "| epoch 3 |  iter 201 / 1327 | time 951[s] | perplexity 139.94\n",
            "| epoch 3 |  iter 221 / 1327 | time 957[s] | perplexity 140.18\n",
            "| epoch 3 |  iter 241 / 1327 | time 964[s] | perplexity 133.89\n",
            "| epoch 3 |  iter 261 / 1327 | time 970[s] | perplexity 137.32\n",
            "| epoch 3 |  iter 281 / 1327 | time 977[s] | perplexity 141.08\n",
            "| epoch 3 |  iter 301 / 1327 | time 983[s] | perplexity 123.11\n",
            "| epoch 3 |  iter 321 / 1327 | time 990[s] | perplexity 101.99\n",
            "| epoch 3 |  iter 341 / 1327 | time 996[s] | perplexity 123.54\n",
            "| epoch 3 |  iter 361 / 1327 | time 1002[s] | perplexity 151.46\n",
            "| epoch 3 |  iter 381 / 1327 | time 1009[s] | perplexity 114.10\n",
            "| epoch 3 |  iter 401 / 1327 | time 1015[s] | perplexity 129.01\n",
            "| epoch 3 |  iter 421 / 1327 | time 1021[s] | perplexity 112.40\n",
            "| epoch 3 |  iter 441 / 1327 | time 1028[s] | perplexity 122.51\n",
            "| epoch 3 |  iter 461 / 1327 | time 1034[s] | perplexity 118.08\n",
            "| epoch 3 |  iter 481 / 1327 | time 1041[s] | perplexity 118.51\n",
            "| epoch 3 |  iter 501 / 1327 | time 1047[s] | perplexity 127.14\n",
            "| epoch 3 |  iter 521 / 1327 | time 1054[s] | perplexity 136.70\n",
            "| epoch 3 |  iter 541 / 1327 | time 1060[s] | perplexity 135.20\n",
            "| epoch 3 |  iter 561 / 1327 | time 1066[s] | perplexity 117.93\n",
            "| epoch 3 |  iter 581 / 1327 | time 1073[s] | perplexity 104.90\n",
            "| epoch 3 |  iter 601 / 1327 | time 1079[s] | perplexity 147.60\n",
            "| epoch 3 |  iter 621 / 1327 | time 1086[s] | perplexity 142.45\n",
            "| epoch 3 |  iter 641 / 1327 | time 1092[s] | perplexity 128.45\n",
            "| epoch 3 |  iter 661 / 1327 | time 1099[s] | perplexity 120.33\n",
            "| epoch 3 |  iter 681 / 1327 | time 1105[s] | perplexity 100.04\n",
            "| epoch 3 |  iter 701 / 1327 | time 1111[s] | perplexity 117.85\n",
            "| epoch 3 |  iter 721 / 1327 | time 1118[s] | perplexity 124.77\n",
            "| epoch 3 |  iter 741 / 1327 | time 1124[s] | perplexity 107.46\n",
            "| epoch 3 |  iter 761 / 1327 | time 1131[s] | perplexity 102.22\n",
            "| epoch 3 |  iter 781 / 1327 | time 1137[s] | perplexity 103.64\n",
            "| epoch 3 |  iter 801 / 1327 | time 1144[s] | perplexity 114.93\n",
            "| epoch 3 |  iter 821 / 1327 | time 1150[s] | perplexity 116.68\n",
            "| epoch 3 |  iter 841 / 1327 | time 1157[s] | perplexity 113.20\n",
            "| epoch 3 |  iter 861 / 1327 | time 1163[s] | perplexity 117.12\n",
            "| epoch 3 |  iter 881 / 1327 | time 1170[s] | perplexity 104.76\n",
            "| epoch 3 |  iter 901 / 1327 | time 1176[s] | perplexity 131.93\n",
            "| epoch 3 |  iter 921 / 1327 | time 1183[s] | perplexity 118.45\n",
            "| epoch 3 |  iter 941 / 1327 | time 1189[s] | perplexity 128.37\n",
            "| epoch 3 |  iter 961 / 1327 | time 1196[s] | perplexity 129.89\n",
            "| epoch 3 |  iter 981 / 1327 | time 1202[s] | perplexity 124.05\n",
            "| epoch 3 |  iter 1001 / 1327 | time 1209[s] | perplexity 108.89\n",
            "| epoch 3 |  iter 1021 / 1327 | time 1216[s] | perplexity 127.23\n",
            "| epoch 3 |  iter 1041 / 1327 | time 1222[s] | perplexity 118.18\n",
            "| epoch 3 |  iter 1061 / 1327 | time 1229[s] | perplexity 102.50\n",
            "| epoch 3 |  iter 1081 / 1327 | time 1235[s] | perplexity 88.48\n",
            "| epoch 3 |  iter 1101 / 1327 | time 1242[s] | perplexity 94.26\n",
            "| epoch 3 |  iter 1121 / 1327 | time 1248[s] | perplexity 120.96\n",
            "| epoch 3 |  iter 1141 / 1327 | time 1255[s] | perplexity 113.23\n",
            "| epoch 3 |  iter 1161 / 1327 | time 1261[s] | perplexity 105.09\n",
            "| epoch 3 |  iter 1181 / 1327 | time 1268[s] | perplexity 110.26\n",
            "| epoch 3 |  iter 1201 / 1327 | time 1275[s] | perplexity 92.93\n",
            "| epoch 3 |  iter 1221 / 1327 | time 1281[s] | perplexity 88.08\n",
            "| epoch 3 |  iter 1241 / 1327 | time 1288[s] | perplexity 105.37\n",
            "| epoch 3 |  iter 1261 / 1327 | time 1294[s] | perplexity 104.46\n",
            "| epoch 3 |  iter 1281 / 1327 | time 1301[s] | perplexity 99.53\n",
            "| epoch 3 |  iter 1301 / 1327 | time 1308[s] | perplexity 128.02\n",
            "| epoch 3 |  iter 1321 / 1327 | time 1314[s] | perplexity 126.13\n",
            "| epoch 4 |  iter 1 / 1327 | time 1316[s] | perplexity 132.68\n",
            "| epoch 4 |  iter 21 / 1327 | time 1323[s] | perplexity 120.54\n",
            "| epoch 4 |  iter 41 / 1327 | time 1330[s] | perplexity 105.61\n",
            "| epoch 4 |  iter 61 / 1327 | time 1336[s] | perplexity 106.77\n",
            "| epoch 4 |  iter 81 / 1327 | time 1343[s] | perplexity 95.98\n",
            "| epoch 4 |  iter 101 / 1327 | time 1350[s] | perplexity 85.96\n",
            "| epoch 4 |  iter 121 / 1327 | time 1356[s] | perplexity 94.65\n",
            "| epoch 4 |  iter 141 / 1327 | time 1363[s] | perplexity 102.17\n",
            "| epoch 4 |  iter 161 / 1327 | time 1369[s] | perplexity 117.16\n",
            "| epoch 4 |  iter 181 / 1327 | time 1376[s] | perplexity 128.60\n",
            "| epoch 4 |  iter 201 / 1327 | time 1383[s] | perplexity 120.20\n",
            "| epoch 4 |  iter 221 / 1327 | time 1389[s] | perplexity 120.74\n",
            "| epoch 4 |  iter 241 / 1327 | time 1396[s] | perplexity 114.97\n",
            "| epoch 4 |  iter 261 / 1327 | time 1403[s] | perplexity 112.29\n",
            "| epoch 4 |  iter 281 / 1327 | time 1409[s] | perplexity 120.28\n",
            "| epoch 4 |  iter 301 / 1327 | time 1416[s] | perplexity 102.37\n",
            "| epoch 4 |  iter 321 / 1327 | time 1422[s] | perplexity 84.98\n",
            "| epoch 4 |  iter 341 / 1327 | time 1429[s] | perplexity 99.24\n",
            "| epoch 4 |  iter 361 / 1327 | time 1435[s] | perplexity 126.59\n",
            "| epoch 4 |  iter 381 / 1327 | time 1442[s] | perplexity 97.03\n",
            "| epoch 4 |  iter 401 / 1327 | time 1449[s] | perplexity 109.28\n",
            "| epoch 4 |  iter 421 / 1327 | time 1455[s] | perplexity 92.61\n",
            "| epoch 4 |  iter 441 / 1327 | time 1462[s] | perplexity 102.93\n",
            "| epoch 4 |  iter 461 / 1327 | time 1469[s] | perplexity 99.40\n",
            "| epoch 4 |  iter 481 / 1327 | time 1475[s] | perplexity 101.19\n",
            "| epoch 4 |  iter 501 / 1327 | time 1482[s] | perplexity 106.86\n",
            "| epoch 4 |  iter 521 / 1327 | time 1488[s] | perplexity 115.64\n",
            "| epoch 4 |  iter 541 / 1327 | time 1495[s] | perplexity 112.40\n",
            "| epoch 4 |  iter 561 / 1327 | time 1502[s] | perplexity 102.16\n",
            "| epoch 4 |  iter 581 / 1327 | time 1508[s] | perplexity 88.28\n",
            "| epoch 4 |  iter 601 / 1327 | time 1515[s] | perplexity 125.87\n",
            "| epoch 4 |  iter 621 / 1327 | time 1521[s] | perplexity 121.01\n",
            "| epoch 4 |  iter 641 / 1327 | time 1528[s] | perplexity 110.07\n",
            "| epoch 4 |  iter 661 / 1327 | time 1535[s] | perplexity 102.55\n",
            "| epoch 4 |  iter 681 / 1327 | time 1541[s] | perplexity 84.25\n",
            "| epoch 4 |  iter 701 / 1327 | time 1548[s] | perplexity 101.39\n",
            "| epoch 4 |  iter 721 / 1327 | time 1554[s] | perplexity 107.01\n",
            "| epoch 4 |  iter 741 / 1327 | time 1561[s] | perplexity 94.58\n",
            "| epoch 4 |  iter 761 / 1327 | time 1567[s] | perplexity 87.67\n",
            "| epoch 4 |  iter 781 / 1327 | time 1574[s] | perplexity 87.76\n",
            "| epoch 4 |  iter 801 / 1327 | time 1581[s] | perplexity 97.50\n",
            "| epoch 4 |  iter 821 / 1327 | time 1587[s] | perplexity 102.34\n",
            "| epoch 4 |  iter 841 / 1327 | time 1594[s] | perplexity 97.73\n",
            "| epoch 4 |  iter 861 / 1327 | time 1600[s] | perplexity 101.46\n",
            "| epoch 4 |  iter 881 / 1327 | time 1607[s] | perplexity 90.40\n",
            "| epoch 4 |  iter 901 / 1327 | time 1613[s] | perplexity 114.70\n",
            "| epoch 4 |  iter 921 / 1327 | time 1620[s] | perplexity 102.73\n",
            "| epoch 4 |  iter 941 / 1327 | time 1627[s] | perplexity 113.72\n",
            "| epoch 4 |  iter 961 / 1327 | time 1633[s] | perplexity 109.96\n",
            "| epoch 4 |  iter 981 / 1327 | time 1640[s] | perplexity 107.19\n",
            "| epoch 4 |  iter 1001 / 1327 | time 1646[s] | perplexity 96.33\n",
            "| epoch 4 |  iter 1021 / 1327 | time 1653[s] | perplexity 111.14\n",
            "| epoch 4 |  iter 1041 / 1327 | time 1659[s] | perplexity 102.29\n",
            "| epoch 4 |  iter 1061 / 1327 | time 1666[s] | perplexity 88.92\n",
            "| epoch 4 |  iter 1081 / 1327 | time 1672[s] | perplexity 78.23\n",
            "| epoch 4 |  iter 1101 / 1327 | time 1679[s] | perplexity 79.64\n",
            "| epoch 4 |  iter 1121 / 1327 | time 1685[s] | perplexity 102.86\n",
            "| epoch 4 |  iter 1141 / 1327 | time 1692[s] | perplexity 99.06\n",
            "| epoch 4 |  iter 1161 / 1327 | time 1698[s] | perplexity 89.63\n",
            "| epoch 4 |  iter 1181 / 1327 | time 1705[s] | perplexity 96.29\n",
            "| epoch 4 |  iter 1201 / 1327 | time 1711[s] | perplexity 82.00\n",
            "| epoch 4 |  iter 1221 / 1327 | time 1717[s] | perplexity 75.19\n",
            "| epoch 4 |  iter 1241 / 1327 | time 1724[s] | perplexity 91.16\n",
            "| epoch 4 |  iter 1261 / 1327 | time 1730[s] | perplexity 93.55\n",
            "| epoch 4 |  iter 1281 / 1327 | time 1737[s] | perplexity 88.44\n",
            "| epoch 4 |  iter 1301 / 1327 | time 1743[s] | perplexity 111.15\n",
            "| epoch 4 |  iter 1321 / 1327 | time 1750[s] | perplexity 110.06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd3ykZbn4/881M5mZTCa9b7It25dFYFk60kFAFI+9HEEPHvCoKGJDPdaf5xz92ruicESOhaIIKlJl6WV3YXvv2Wx6nbRJJnP//nhKZlIn2Z3NJnu9X6+8MvO03M8OPNfc7brFGINSSikF4JnqAiillDp+aFBQSinl0qCglFLKpUFBKaWUS4OCUkoplwYFpZRSrrQGBRHZLyKbRGS9iKy1txWIyOMissv+nW9vFxH5kYjsFpGNIrIynWVTSik13LGoKVxsjDnVGLPKfn8b8KQxZhHwpP0e4Cpgkf1zI/DzY1A2pZRSCaai+eha4C779V3AWxK2/9ZYXgLyRKR8CsqnlFInLF+ar2+Ax0TEAL80xtwOlBpjau39dUCp/boCqE4495C9rTZhGyJyI1ZNgqysrNOXLl2axuIP2lEXIeT3MrsgdEz+nlJKpcu6deuajDHFI+1Ld1A43xhTIyIlwOMisj1xpzHG2AEjZXZguR1g1apVZu3atUevtGO45sfPUpId5M4PnHFM/p5SSqWLiBwYbV9am4+MMTX27wbgAeBMoN5pFrJ/N9iH1wCzE06vtLcdF7IDGXT2xqa6GEoplVZpCwoikiUi2c5r4ApgM/AQcL192PXAg/brh4Dr7FFIZwPtCc1MUy4c9NHR2z/VxVBKqbRKZ/NRKfCAiDh/5/fGmEdEZA1wr4jcABwA3mkf/zBwNbAb6AY+mMayTVh20EdnVGsKSqmZLW1BwRizFzhlhO3NwKUjbDfAR9NVniOVHfAR0eYjpdQMpzOaU5QdzKAzGkPXn1BKzWQaFFIUDvoYiBt6+gemuihKKZU2GhRSlB20Wtq0CUkpNZNpUEhROKBBQSk182lQSFFOMAOAiA5LVUrNYBoUUhTW5iOl1AlAg0KKnD6FnfURth7umOLSKKVUemhQSJHTp/CNv2/jfb9+idhAfIpLpJRSR58GhRRl230KAK3d/bxW3TaFpVFKqfTQoJAip6bgeHJbwyhHKqXU9KVBIUVej7ivs/xentxWP4WlUUqp9NCgMAlvPrWCXQ2d2q+glJpxNChMwvwia/W13pgGBaXUzKJBYQLCAR/ZQR+Zfqt/oadP8yAppWaWdC/HOaO88sVLEYS/b7LW/unV5HhKqRlGg8IEhOwaQjDDqmBpUFBKzTTafDQJmRleAE2jrZSacTQoTIIbFLRPQSk1w2hQmISgX2sKSqmZSYPCJDg1hd5+HZKqlJpZNChMwmBQ0JqCUmpm0aAwCUHtaFZKzVAaFCZBO5qVUjOVBoVJCPqtfzatKSilZhoNCpPg93rwiPYpKKVmHg0KkyAiZGZ4NSgopWYcDQqTFMzwavORUmrG0aAwScEMLz19Ok9BKTWzaFCYpEy/Nh8ppWYeDQqTlKnNR0qpGUiDwiRpR7NSaibSoDBJgQyP1hSUUjOOBoVJyszw6oxmpdSMo0FhkhI7mvsH4jyxtZ76jt4pLpVSSh0ZDQqT5HQ09w/EufYnz/Oh367ll0/vnepiKaXUEUl7UBARr4i8JiJ/s9/PF5GXRWS3iNwjIn57e8B+v9vePy/dZTsSQbv5qDESZWttBwCd0f4pLpVSSh2ZY1FT+ASwLeH9t4DvG2MWAq3ADfb2G4BWe/v37eOOW8EML72xON19MXebLrqjlJru0hoURKQSeCPwa/u9AJcA99uH3AW8xX59rf0ee/+l9vHHpcwML32xOB29g0FBRyMppaa7dNcUfgB8FnC+QhcCbcYY50l6CKiwX1cA1QD2/nb7+CQicqOIrBWRtY2Njeks+5gy7fTZzZ197jadt6CUmu7SFhRE5BqgwRiz7mhe1xhzuzFmlTFmVXFx8dG89IQ4C+00dUYByAn6dIiqUmra86Xx2ucBbxaRq4EgkAP8EMgTEZ9dG6gEauzja4DZwCER8QG5QHMay3dEnCU5m+2gUJQd0OYjpdS0l7aagjHm88aYSmPMPODdwD+NMe8DngLebh92PfCg/foh+z32/n8aY0y6ynekwgErntZ32EEhS4OCUmr6m4p5Cp8DbhWR3Vh9BnfY2+8ACu3ttwK3TUHZUpabmQHA4bYeAIqy/fRq85FSappLZ/ORyxizGlhtv94LnDnCMb3AO45FeY6GHCcotFuzmPNDfq0pKKWmPZ3RPEmJNYUsv5esgE+DglJq2tOgMEm5ISsotPf0Ewr4rMls/XHi8eO2G0QppcalQWGSwn4fztS6cMDnDlGNxnRWs1Jq+tKgMEkej5ATtGoLIb+XzAzrn1KbkJRS05kGhSPg9CtkBXyE/FafvQYFpdR0pkHhCLhBwe8l6Leaj3RWs1JqOtOgcAQSawpOn4LmP1JKTWcaFI7AYE1hMCho85FSajrToHAEchJrCnbWVG0+UkpNZxoUjsBg85HXTZCnNQWl1HSmQeEIaJ+CUmqm0aBwBBJHH2Xq6COl1AygQeEIjFRTiPTGNDAopaYtDQpHwAkKIb/P7VP4r4e38bafv8BxvBSEUkqNSoPCEVhSls3SsmxOmpVDwOdxcyFtre1gW21kagunlFKToEHhCBRnB3jklguYXRBCREisHPx90+GpK5hSSk2SBoU0yA74+PvG2qkuhlJKTZgGhTT413Pmsr+5m/qO3qkuilJKTYgGhTS4bFkJABsPtU9xSZRSamI0KBxFWX4vpTkBlpfn4vUIGw+1TXWRlFJqQjQoHEXrvnQ5T3/mYjL9XhaVhNkwTk3hYHM3p339MfY3dR2jEiql1Ng0KBxFwYzBHEinVOax8VDbmPMV/rbpMK3d/fz+lYPHqohKKTUmDQppcuqcPNq6+3l5X8uoxxRlBQBoikSPVbGUUmpMGhTS5NpTZ1GRl8lXHtxC/0B8xGP8Puufv6mr71gWTSmlRqVBIU1Cfh+fv3opO+ojvLCnecRjojErR1Jzp9YUlFLHBw0KaXROVSEAuxs6R9zf22/VIJo7taaglDo+aFBIo4IsP7mZGexpHC0oWDWFJq0pKKWOExoU0khEqCrOYu+oQcGqKcTihkhv/7EsmlJKjUiDQppVFYXZ29jFvWur2d2QnDnV6VMAqGnrOdZFU0qpYTQopFlVcRYNkSifvX8jP/nnbvY3dbHlsDWpzakpANS0alBQSk09DQpptqA4y3299kArn75vA5+8Zz0AvQk1hdp2TZ6nlJp6vqkuwExXVRwGIBzwcai1h0OtPYQD1j97b/8AJdkBGiJRWnSuglLqOKA1hTRbWBzmU5cv5jvvOMXd1hmN0RmNEe2PEw76yAn6dK6CUuq4oDWFNPN4hJsvXURsIE6W30tXn9Vk1NDRSzQ2QNDnpSgcoFlrCkqp40DaagoiEhSRV0Rkg4hsEZGv2dvni8jLIrJbRO4REb+9PWC/323vn5eusk0Fn9fDxy9dxDtOrwSgrqOX3v44wQwPBVl+ncCmlDoupLP5KApcYow5BTgVuFJEzga+BXzfGLMQaAVusI+/AWi1t3/fPm5GuenCBXz4ogUANHRE6e0fIODzUhj2a5+CUuq4kLagYCzOrK0M+8cAlwD329vvAt5iv77Wfo+9/1IRkXSVb6qU5gQBqO/opTc2QDDDQ2E4QHOX9ikopaZeSkFBRP4sIm8UkQkFERHxish6oAF4HNgDtBljYvYhh4AK+3UFUA1g728HCke45o0islZE1jY2Nk6kOMeFcMBHOOCjrqOXaH+cYIaXwiyrphCPj772glJKHQupPuR/BrwX2CUi3xSRJamcZIwZMMacClQCZwJLJ1fMpGveboxZZYxZVVxcfKSXmxIlOQGr+Sg24AaFuIG2Hk11oZSaWikFBWPME8aY9wErgf3AEyLygoh8UEQyUji/DXgKOAfIExFn1FMlUGO/rgFmA9j7c4GRc05Pc6XZQav5qD9OwOehIGwttqPDUpVSUy3l5iARKQQ+AHwIeA34IVaQeHyU44tFJM9+nQlcDmzDCg5vtw+7HnjQfv2Q/R57/z/NWGtZTmNluUF79JFVUyjK8gPQpCOQlFJTLKV5CiLyALAEuBt4kzGm1t51j4isHeW0cuAuEfFiBZ97jTF/E5GtwB9F5BtYweUO+/g7gLtFZDfQArx7Unc0DZRkW81HAAG7oxnQEUhKqSmX6uS1XxljHk7cICIBY0zUGLNqpBOMMRuB00bYvherf2Ho9l7gHSmWZ1orCgfos5foDPq8FNg1BR2BpJSaaqk2H31jhG0vHs2CnEiKsv3u60CGh/xQBiLQFNGgoJSaWmPWFESkDGuoaKaInAY48wZygFCayzZjFdnNRWDVFHxeD7PzQ+xp6prCUiml1PjNR2/A6lyuBL6XsD0CfCFNZZrxkoJChheAxaVhdtVHRjtFKaWOiTGDgjHmLqzO4rcZY/50jMo04yUHBasFb3FpNqt3NNIXi+P3afJapdTUGK/56F+NMf8HzBORW4fuN8Z8b4TT1DgKsvx4BOIGAj6rprCkLJtY3LCvqYslZdlTXEKl1IlqvK+kzrJhYSB7hB81CV6PuCOOnJrCohLrn3OHNiEppabQeM1Hv7R/f23oPifltZqcwqwATZ19bp9CVXEWXo9ov4JSakqlmhBvdeL6BiJyBrAmTWU6ITjDUp2aQjDDy+z8TPY26ggkpdTUSXXy2v8Aj4jIj7CGqF4FfDBtpToBOJ3NTp8CWH0NbT06q1kpNXVSCgrGmEdF5MNYeY6agNOMMXVpLdkM5wQFp6YAkJuZQaMmxVNKTaFUm4++BPwYuAD4KrBaRN6YxnLNeCPVFHIzM2i302cPxA0HmrUpSSl1bKU6IL4QONMY86Ld+fwG4Jb0FWvmO6uqgNPm5FGcPThnITczg7ZuKyj85182ceG3V9PerWssKKWOnVTXU7gFwFlcxxhzwBhzeToLNtOtnJPPAx85zx19BJAb8hPpjTEQN/zhlWoAGjt7p6qISqkTUKrNR28C1gOP2O9PFZGH0lmwE1FuprVe0eG2Hndbawo1had2NNBvZ11VSqkjkWrz0Vex0l23ARhj1gNVaSrTCcsJCn/fVOtuG2+NhT2NnXzwf9fwj83a76+UOnKpBoV+Y0z7kG361fQoc4LCY1sGH/Ct4wQFZ39Na8+YxymlVCpSDQpbROS9gFdEFonIj4EX0liuE5ITFLbWdjC/yMow0tI9dlCI9MYAqO+w+h4Ot/VQ06YBQik1OakGhZuBk4Ao8AegAx19dNTlhayg0NsfZ1FJmGCGxx2NNJqOXmu/ExRuuWc9t/zxtfQWVCk1Y6U6ea0b+KL9o9LEqSkAVOaHKAj5k/oUNh1qJy+UweyCwfWNOqNWTaGuo5eBuGHToXZ8HsEYg4iglFITMV7q7L8CZrT9xpg3H/USncCSg0ImeSF/Up/Ch/9vHafMzuVn7zvd3eY2H7X3sr+5i57+AQAaIlFKc4LHqORKqZlivJrCd45JKRRgJcXz+zz0xeJU5mdSkOV3+xT6YnEOt/eQ6fcmnROxm48aIlE21wyOBdjT0KlBQSk1YeOlzn7aeW2nyl6KVXPYYYzRzG1pkJuZQWMkyuyCEPlZfrbXRXjfr1/iunPmYQwcaO6ifyBOhtfqDuq0awqxuOHZXU2IgDGwu7GTcxcWTeWtKKWmoZT6FOw8R78A9gACzBeRm4wx/0hn4U5ETlCoyM+kIJRBU2eUpt1RBKt/oH/AUN3STVVxGBhsPgJ4ansDy8tzONjcze6Gzikpv1Jqekt19NF3gYuNMRcZYy4ELga+n75inbjyMjPIzcwgJ5hBXmhwHaNX9rW4r3fWR+jus4JBR28Mpz+5uauPU2bnsaAkzJ7G0YPCzvoIT+1oSM8NKKWmtVSDQsQYszvh/V5AlwhLg9kFIZbaazQ7S3YC9CWksfjs/Ru54vvPEI8bOqP9VOZnuvv+48IFVBVnsW+MxXp+sXoPn7lvQxpKr5Sa7lJdZGetiDwM3IvVp/AOYI2IvBXAGPPnNJXvhPONt6wgFrcGfPXFkieNl+UEiRtDQyRKR2+MTTXtRHpjVBWF6YvFeeeq2cwuCFGcHaC5q4/GSJQfPLGTL12zPCnxXmt3H02dfURjA0mpu5VSKtWaQhCoBy4ELgIagUzgTcA1aSnZCSor4HOHpp5ndxT/23nzAajIz2RpeQ5F4QAiViK8SG+MvFAGL33+Uj51xRIA8jL9RGNxnthWz+9ePsj66rakv9Fh90M0dOiCPkqpZOPWFETEC2w0xmgfwjG2fFYO+7/5RjZUt3Hn8/uoyMvki29cRv9AnJv/8BpPbW+gMxojO+hLmqjmzIzea/crHGzu5uyqQnd/h72QT217b9JEuKGisQFeO9jG2VWFbDnczsKSsNYslJrhxq0pGGMGgPccg7KoUSwqDePzCPMKQ5TmBKnMD3HxkhI2HGqnpauPcCAj6fh8NyhY/QoHWpL7F5zV3eo6xl6r4VfP7OXdt7/En9Yd4k0/fo571x46WreklDpOpdqn8LyI/AS4B3CfMMaYV9NSKpUk5Pdxz03nsNAehgrWIj2O7GDyx5ibaXVQ72uyg0Jzd9J+J19SXfvYifOc4PHDJ3cRN7CzTscWKDXTpRoUTrV/fz1hmwEuObrFUaM5fW5+0vuTK3Ld1zlDgoLTfHSwxQoG1S2DQSEaG6C33+rArmsfu0/BqYE413GCjFJq5ko1Id7F6S6Impjc0GCTUXYwufnICQrOKKYDCUGho2dwsltdx9g1BSeFhkODglIzX6rLcZaKyB0i8g/7/XIRuSG9RVPjmWN3EocDybE9P2HSG0Bbd7/bFNSR8KCvbR+7TyFxtnReKIOath567YR7SqmZKdUhqb8BHgVm2e93ouspTLl59kI8To3AEczwEvBZH22hPQHOaUJygkNR2E/9eEEh2k844GNpWTYfPNcaFru/WWsLSs1kqQaFImPMvdhLcBpjYoB+ZZxit16+mOyAj5Vz8obtc5qQVtp9ETvrrU5iZzjq4tJs6iPRYRPkEkV6YywqDfPILRdw6bISgDFnSiulpr9Ug0KXiBRir60gImcDQ9dsTiIis0XkKRHZKiJbROQT9vYCEXlcRHbZv/Pt7SIiPxKR3SKyUURWHsF9nRBOnZ3Hpq+9gZIRUmQ7TUhnzS8gNzODF/c0A4MT1y5YXMxA3LB2f8uwcx0dvTG3v8JZHnSv9isoNaOlGhRuBR4CqkTkeeC3WEt0jiUGfMoYsxw4G/ioiCwHbgOeNMYsAp603wNcBSyyf24Efj6RG1HJnFnRReEA5y4o5PndTRhj3OajK08qw+/1sHpn46jXiPT2u8NdswI+ZuUG3RrHaO5dU81T2zXZnlLTVapBYSvwALAGK93Fr7D6FUZljKl15jEYYyLANqACuBa4yz7sLuAt9utrgd8ay0tAnoiUT+BeVAKn+Sg/y8+5C4s43N7L/uZut/moLDfImfMLxnyAR3pjScNdl8/KZcvhjlGP74vF+epft/CLp/eMW76+WDyp01spdXxINSj8FmuBnf8GfgwsBu5O9Y+IyDzgNOBloNQYU2vvqgNK7dcVQHXCaYfsbUOvdaOIrBWRtY2No3/LPdE5zUcFIT/n2zmUXtzTTEdvP36fh2CGl4uWFLOroTNpHkMiq6YwONz1pFk57GnsdNN2D7V2fwvdfQMpdUb/bPVurvnRcxO9LaVUmqUaFFYYYz5kjHnK/vl34KRUThSRMPAn4BZjTNLXTGOMYYw1oEdijLndGLPKGLOquLh4IqeeUHLdmkIGcwtC+DxCdatVU8ixH/RvOKkMgH9srh12fl8sTm9/PKmmsKIiF2NgW+3ITUhOU1R9R5Su6MiBw7GjLkJ1azfWfwJKqeNFqkHhVbtzGQAROQtYO95JIpKBFRB+l5Beu95pFrJ/O+0XNcDshNMr7W1qEirzQ4T8XgqzAng8QlE4QFMkSkdPjNxM60E/uyDEKZW5/G3j8KDgTFwbWlMA2Hp45DEGq3c04LeXCR1voltdRy/GQFefDmJT6niSalA4HXhBRPaLyH7gReAMEdkkIhtHOkGstJ13ANuMMd9L2PUQcL39+nrgwYTt19mjkM4G2hOamdQEvWvVbB6/9UIy/VZW06JsP02dUdp7+snJHHzQv/F15Ww81M7BIfmRnIlriXmVynOD5Icy2FwzvF+hMxpjZ30nly23h66OFxTsORJDZ02Pp6Wrjx4NJEqlTaq5j66cxLXPA94PbBKR9fa2LwDfBO61Z0QfAN5p73sYuBrYDXQDH5zE31Q2v89DRd7gimxF4QBNnX30xeLMLhjc/vpFxcB2NhxqY05hiJ31EXweoStqPXgTawoiwrLyHLaPMAJpj70m9BXLy3h4Ux37xwgKA3FroSCAzt4Y5I566DAr/7/HmVcYYvVnNPOKUumQau6jAxO9sDHmOUBG2X3pCMcb4KMT/TsqNUXhADvqIkR6Y5yzYHBthTJ7jkOj/ZD+zP0byczw8PFLFgHDM7AuLs3mvrXVGGOS1nDYZQeFkytzmZUbdGsKjZEoX3xgEwVZfj55+WJKc4I0dUYZsGdhd/SO3fcwkv3N3fQPxMnwplrRVUqlKtWagprmisIBtx0/sQaRF8ogwyvuN/fath6isbj7sB4aFBaWhOnqG+Bwe2/SdXY1RMjwCnMLQlQVh3lmVyOPbqmjrr2Xx7bWA1ZA+bfz57tNR2A1O6UqsVN67f7WpOCmlDo69KvWCaIo7Md5plbkDz7MRYTicIDGiPXtvbmrj/aefvbYq7blDMnAurg0G4BdQ5qQdtd3UlUUxuf18KkrFpMf8vOR373KA6/VMLsgk3DA56bgTlzcZyJ9Ck7Kb4AnttWnfJ5SKnUaFE4QxdkB93XiN3xnX0Okl9buPrdZZ42d/mJoTWFRibXQz676zqTtuxo6WVhq7TttTj6/fP/pDMQN66vbOH9hMXMKQhyw5y8k1hQiE2g+SqxVvLyvOeXzlFKp06BwgigKDwaFyvyhQSFIYyTq9isArNvfisgIabmz/BSFA+xqGKwp9PQNUN3a7QYMgKriMGfMs5Lxnb+wiHlFIXcFuMSaQucEgoIzaS43M4O9jV3E4zrHQamjTYPCCcIJCsEMDwVZyestFGcHhgWFSDTGFctL8Y3QmbuoJMzOhJrCnsZOjIFFJdlJx91wfhXF2QHOW1jInIIsqlu7GYgb6tp7mZUbRGTs5qO9jZ3cdPdarrvzFdp7+t2awusqc+nuGxh3jWml1MRpUDhBFIWtQFCRl5k0agigJDtAS3cftfaazXMKQojAJy9fPOK1lpRls7M+4jY17bZHHi0qDScdd+WKMtZ88TLyQn7mFYboHzDUtvfQGIlSkhMk7PeNOfrovx/ezmNb63lmZyOvHmx1h8meOttKFe70eyiljh4NCieI/JAfr0eoyA8N21ecHUhKX/GFq5fxlWuWs7QsZ8RrLZ+VQ3ffgNtHsKshgtcjzCvMGvXvzym0/u6B5m5au/vID2WQHfSNOvqouqWbJ7fX8+4z5gCwt7HLTZ3xukorKDjBSCl19GhQOEF4PMKC4iyWlw9/0JfYndBbD3eQ5fdy5YoyPnDe/FGv5VzDCSK76juZVxjC7xv9P6e5dsA40NxNW3c/+SE/2cEMNlS3ceG3n6KmLXm96HvWVOMR4eOXLrT7EDrdADK3MERO0DfpmkJP34AuK6rUKDQonED+/JHzuHWEJiFnZNKWw+0jLtgz1MKSMD6PsLXWyoG0u6FzWH/CUOU5QTK8VlK+tu4+8kJ+wkEfuxo6OdDczct7k0cTvbK/hZMrcinPzWR+URb7mgZrClkBHwtKwuxpmNyCPx/53To+e/+I2VmUOuFpUDiBhAO+Eb/NO4Ggq2+A4oRRSqMJZnhZUBxmW22EaMxKlT20P2EoJynf4bYeuvoGyLObjxzbajtYd6CF9p5+BuKGzTXtnFJp5b+oKs5ib2OXW1MI+30sKgmzoz4yqSyr+5u72VRjBbT9TV18+r4NWnNQyqZBQVGWE2Sx/VCPxlJ7OC6flcOWw+3W0FADi0rHrimANQLK6Qew+hQGJ8Y9u6uJd/ziRf7zL5vtNRsG3L6DBcVh6jp6aey0RkdlBbycNieflq6+pMR7XdFYSsNU27r7qG7pJjYQ5/evHOT+dYdYvePors1x+zN7+O5jO47qNZU6FjQoKLwe4VfXrQKstZtTsXJuPvUdUe56YT8Ap9kjgsZSnD0YFPJC/qQ5ENvrIsQN/G3jYf607hAAp8y2awr2+tBbajoI+Dz4vB7OmFcADE6ya+/p5+z/eZL7Xz00ZhnicWtJ0ljcUNPWwz/tlece33p0Zkj3xeIMxA2/eHov966tHv8EpY4zGhQUYHUEb/36G/jkZSMPQx3qiuXWgnl/XFPNsvIcZhcMH9U0VFHYTzRmparIC2W4C/jMtx/65blBsvw+bn92L+GAj6oiq/Yyv9jav6mm3Q0kC4qzKMjy88q+VgBe3NNEpDfGzrqx15CORGM4lYlndzWxu6GTYIaHf26vZyBuaO2yMslOhjGGFV99lDf84Blauvqo74hOODW4UlNNg4Jyhfw+PJ7REtsmK80JsnKOVTtwAsR4ElNtWKOPrAf8tafOAuCNJ5dzx/WrWFaWwxXLS92yzLEDTntPP1l2UBARVs3Nd2sKT+9sAnAT+42mvXvwIf2/z+8D4OZLFtHa3c/66jau/tGz/PDJncPO+fgfXqOlq2/Ma3dGY/TF4klDZcdbV0Kp440GBTVpV59cDgwu6zmexFQbeaEMKvNDZGZ4ec+Zc3jbykref85czqoq5OFPvJ7vvetU99iQ3+eem5XQ5HTanHwOtnTT0dvPM+5SoGPPcm7rGXyw72ns4qRZOe59bK5pp7a9lxf3JI+EevVgKw9tOMxT2xsYS2vXYMCZlWt13u9tHDsobK5p5/N/3uhOBBxNpLefD921ZtjQXaWONg0KatKuO2ce9334HJbPGnmS21DJQcHPm06ZxXOfu5jSnCDffecp7lyGkcyxFwYKB+0ngE4AACAASURBVLzuNieH08t7W6hp68HrkXFrCm12TcGZ1P3+s+e6a0q8dtBqitp8uCOpCam12wokWw4PX3EukXPcxy9ZyG9vOBOPWKk6xvL7Vw7yh1eq2VY79rW3HO7giW0NrNnXMuZxQxlj3JxRSqVCg4KaNL9vsMM3FU7zUYZXyPJ78XqEwhSGwAJun0ViTWFWnvUwf26XVUs4uSKXhoSawq76CN9+dHvScNO2HisoLC3LISfo49pTK8j0e8kLZfBadRtgdRZvrxt8SDvNRptHWZva4QSFC5cUs7AkmzkFIfaMU1NwHvLrDrSOeZyTl6qte+wmrKF+8fReln/50XGbvpRyaFBQx4xTU8gL+YflXxrPnBGCQlmuVVN4Zb/1QD19bj5dfQPufIY7ntvHT5/aw/t+/TK/fXE/L+xuotke1vrtt7+Oe246x13Dujw3083iCrDBDhAwWLvYdrhjzCGvznF5ISvPVFVxeMxZ182dUXfFurWpBoWeiXVcv7DH6mv55TN7JnSeOnFpUFDHjFNTyMvMGOfI4ZyaQtg/GBRKsgN4BLbXWUNVV1RYzVhOv8K6A61U5GWyu6GTLz+4hff++mV+vtp6OC4py2ZZQsqP8tzBmdz5CbUGGKwBRKIxqlsHA8dQznH5dlBYXJrNnsZOdyb2UGvsYFaRl8mrQ4JCXXtv0roTzhyN9gkGhZJs677uemH/hM9VJyYNCuqYyQn68Hs97kNzIpyaQiihTyHD63GT+c0uCFFqPwAbOqK0dfexq6GT95w5m/VfvpyXv3ApReEADZEo4YBv2PrOTlAoCvs5bU4+WxP6D1q7+/DaI6E214ze9t/a3Y+Itd4DwAWLi+gfMDy3u2nE49cdaCHg83D9uXOpaevhvG/+k/XVbbR09fGWnz7PJ+9Z7x7r1BQSR0+losMeEtvbH2fTobGbv5QCDQrqGBIRirMD5IUmXlNwgsLQRX/K7Sak2fmZbrqOhkgvrx50mpQKEBFKc4Juh3juCDUVJyiU5QZZXp7D7oZOty+itaufFRW5ZAd8PLtr9JnPbd195AQz3AByxrwCsgM+/rlt5FFL22ojLCnL5i2nVnDtqbPo6O3nF6v38Nn7N1DX0cvOhCVPU20+enFPc1K/SkdPv7v4kZOrSqmxaFBQx9SXrlnOTRcumPB5ZTlBLltWytlVhUnbnYf57IIQpTlW81R9hzWs1OsRd1Y0wLJyKxXHSEHJ6Z8oy8lk+awcYnHjzjdo7e6jJDvABUuKeWJbw6j9Ci1dfUkLGGV4PVywpJindox8zo76CItLsynJCfLDd5/Ge8+cwyNb6nhiWwOLSsLuetmQWkfzgeYu3vOrl7joO6tZvcMKRJHeGHMLsyjPDSbVfpQajQYFdUxduaKM0+fmT/g8j0f49fWrOG9hUdL2wZpCiHDAR2aGlwfXH+Z/n9/PFctLCSX0QTgpv0cKCs68gnK7pgC4D1Fn/YfLl5XS1BnlDT94hp8+tXvYNdq6+4dd+5IlJTREosOGs7Z29dEYibo5pwD+9ey5eD3CJUtL+NQVSwArYR8M9imMVVN4ZtdgM9V9dqqQjt5+coI+lpfnsHWcYa+j6YvF0x5QGiK9/M8/tqWce0uljwYFNa0N1hSsFeU+cN48djd0UlWcxbfe/rqkY52O5bzM4X0aZQnNR3MKQmT5vWyt7cAYQ2t3P/lZfi5aUozPI+xq6OQ+O69Ra1cf962tto/rG9ZfctGSYkTgye3JuZWcpqHFCYkEZxeEePSWC/jZ+1aywE7tsb+5i4G4cUdNjdWn8OzORirzMzlzfgH77KGwHT395GRmsHxWDnsauyaVDfaB1w5xzY+fpba9h4G44dEtdTR1jj0fZKJuf3ovv3x6Ly/vndg8DHX0aVBQ05qTN2mh3W7+uSuXsu5Ll/PgR88nJ5j8rb2qKIuAz0N+1vCawpyCEO9cVcnldnqNZeVWFtjuvgH6YnHyQ37yQn7u/fA5nLug0M3h9OfXavjM/Rt5ZlfTiDWFwnCA02bnuYn3HDvtpqnFQ7LLLiwJE8zwMtteEnVvYxctXX3EDWQHfbT19HPtT58fVlPpH4jz4p5mXr+omKqiMPuarGDSGY25NYWBuGHHOLmhRnKwpZu4gVf2tfAvP3uem+5ex5cf3AxYmWkPjTEiazwbD7Xx62f38ic7keH6hFFfI4nGBnj/HS8PW39DHT0aFNS0dumyEh655fUsTFjkJxzwufMPEvm8Hm6/bhX//vqqEff9v7ef4j6kF5dls6exK2GYqfWwXzknn9Pn5lPf0Uv/QJzqFuuB+L/P7xuxpmCVsZSNh9ppiAx2AO+si5Ad8CUNhU0UzPBSkZfJ/uYutz9hcWk2A3HDhuq24ak4DrQSica4YFER84uz6OkfYE9jpx1MMjh9Xj4i8PTOwY7y7r5YSqOZnL//q2f3svFQO6+rzOWRzXVUt3Tzgyd28sYfPTfpJII/fGIX3/j7Nlq7+wn4POMGhY2H2nl2VxN3v3Rg3Gt/6t4NfOfRiaUvjw3E+epDW9ylZk9EGhTUtCYio64lPZILFxePmU7DMb8wi5auPndCW+LDviIvk7ixOrQPtVq5iFbvaKS7b8ANHokuXlJiHbN98IG8+XA7S8qyx5zEN78oi/1NXW5/gjOKCLDXnIi5zThPbm8gwyucv6iIBXbtaf1B6wGbk+mjJDvI6XPy+cfmOvcan7xnPdfd+fK4/xZO6pDNduryn7xnJR4RfvvifrbXRWjv6XcTE05Ud5/VnPXhCxfwplNm8drB1jEXTlprz+1YvaNx3P6H53c38coE04LsberiNy/s5+LvrJ7QeTOJBgWlRuA0SzmTyvITRhXNyrM6t2taezjU2s2qufnuN/7cEWoKy8qzKc8Nuv0KHb39bDzUzjkLCocdm2huYYj9zd3UtVuBJ7Gpqba9l0/ft4Erf/AM7d39PLG1nrOrCskOZlBVbAWP9YfsoGA3o125ooxttR0caO6ivqOXx7fWs7W2Y9xkfA0dg/0HZ8wrYE5hiNPn5rPuQCv77W/UQ5MFPr61ns014w+BbeqMctWKMm67aikr5+TT2t3PwZbRm6PWHWjB6xE6ozG+9/hOttipR4wxSRlp43FDU2d0wn0fzmivuIGXTtAmKg0KSo1gnhMU7PkOSTUFOxHf4fYeatp6OGlWDo/feiGfvmIxbzhpeBpxEWtE0bO7mojGBnhxTzMDccP5Q0ZSDVWZH6K9p58ddZ14BJaWJfc/PLK5jqbOPj72h1fZ29TF5XYK89KcAFl+b0JNwQoKTjbbZ3Y28udXa4gb6B8w4/YJNHZG3bkXzuivpWXZ7KiLUGPXlJ7akRwUvvjAJr7y0JYxr+tc20l/4gwf3jDKJDtjDOsOtPLGk8vJCfr45dN7+fD/rWMgbvjjmmou/e5qN4tsa3cfsbhxa1mpaktoTnvg1ZoJnTtTaFBQagRzCkJ4BJ7f3Yzf56HCrh0AzLKHwW6vjRDpjVFpD4f92CWL3LQSQ126rITuvgFe3tvC87ubCPmtJUXH4maB3ddMWU6QIjtNSFHYClBxYx3z7K4mwgEfVyy3HvoiQlVx2B2C6qxbUZmfSWaGlwPN3Ty8qdbdnpjeu7kzytf+uoUX9jTxnUd38JUHN9PcGeXSpSXkZma4gWdxWTZdfQPEDZxkj2xyJs3FBuI0dkZZd6CV2vbRU333xeK0dfe76U8WloTxeoQddSMPf93X1EVrdz/nLijkrzefz9evPYnqlh4e3VLHQ+sPEzeDo7qcJq9Ib2zMZqb2nv6k2oQzD2RxaXjSTWLTnQYFpUbg93mozA/RNxDn/IVFSR3XmX4vhVl+Xrbbq52aw1jOrirE6xHW7G/huV1NnDW/AL9v7P/9KvOtWdxbazuoyM90c0ZdvrwUn/3N/e4bzuKfn7qQdV+6zB1WC4NzMmCw+UhEqMzP5GBLN7sbOrlsmfWAd5L2RXr7ufpHz/K/z+/n3+9ay0+e2s3dLx0gbuD1i4rY8JUr3FFeSxKaspz1KHbWW9dp7urD6RZ4JKEPY6jmLuth7NQUAj4vVUVZo46QcuZ6nFyZy9zCLN531lzmFYb4zqM7eHmf1dTjDMVtTEih3tw5+oS/T96znit/8KwbvJzmo8uXl7K3qSvpOqmKxw03/+E1XtnXwq76yKRGfE0lDQpKjcJpQrp8hJXlZuVluiNlKlMICiG/j2Xl2fx9Uy17m7qGTcIbiXNdY6zO7YIsP2fOL+CqFeXMKQwxuyCT+UVZVBWHCfiSR1udXDk4kzsnIa3H7IIQrx5spad/gJVz8sjNzHDb4tfub6W+I8pX3rQcjwgZXnGXLi0eUgNalBAUnH8f91u63QchAg9vqh31/pwHbuKKfEvKstk+ykN0Z30Er0dYYPeZeD3C165dQXWrNWTW6xH3XhLX1RitX6EzGuO5XU00dUb52O9fA6yg4EwgBCZVW2jsjPLXDdZa47fcs5533f5iUuqRHXWRMTvTx7P1cEdaJ/lpUFBqFFV2ULh0WcmwfYnt+843+vGsnJPvNtW8flHxuMcXZvkJZlj/i1bkZ+Lzerj3pnO4YHExn7xsMZ+/atmo555cMRgUnGYisHJENdnfnOcXhakqznLLtGZ/Cz6P8K4zZvPwJ17PH288xz0v8cENVv6oWblBcoI+FpWEyQtluGnAnaG3lywpYe2BVn7/8kHe9csX6R9IHrbqPKyd5jCw/l0Ptfa46c8Tba+LMK8wRDBjMABeuLiYX123ipsvWciKWTluUEj8hr/lcEfSUFzHc7sa6RuIc9myUtYdaKW6pZu27n5yMzM4uSKPYIZnUvMhau3sts/tbmJrbQdt3f3ceu8G+gesmeFv+MEzPLxp9BrUWDbYS8Yu+c9H+NvGw5O6xng0KCg1in+/oIrb33/6iP0E/3nNcvehPdIw1JE46T2KswNJ6S1GIyJuX8bQwPOmU2a5zTYjWVo+GLQSM8I6KcgB5hdnUVVkrflgjGHtgVZOmpVDyO9jdkGIlXPyyLEDSkn28MWQTpubz4qKXESExSXZ7BrSnv+B8+ZhDHzxL5t4eV9L0noVMFpNwWr2um9t9bCmmx11kRGHH1+0xEoLUlUcTqgpDH4z/6+/b+OG36wZ9u36iW0N5AR93HLZIgBe3NtMW48VFPw+D+ctKOKxrfVu3qre/gHuXVM97mgtJ+V5TVsPxsBbV1bw3O4mPnPfBjbaI8Ie2zq5oLC3yQq8i0rC7oqBR1vagoKI3CkiDSKyOWFbgYg8LiK77N/59nYRkR+JyG4R2SgiK9NVLqVSVZGXyRWjrD+dm5nBi5+/lGc+c3HKCwattDuWz19YlPI5TjBI7OhOxdDmpKHXC/g8lOcEOXN+Pg2RKE9ua2BDdRunzx1cSU9EOGV2HjC8pgDWQkW3X7cKgEWlYXbWW80iTvPRWfMLWVwadvsX9jZ2Eo8bbvvTRr7xt61uGvLEZVqdvoqv/XUr//3wNnd7VzTGwZZulgwZgZVoflEWNW099PYP0BiJugkSO6MxYnGTFJQivf08uqWOS5eVsrw8h8IsPy/taaatu8/NovvmU2dR297rLoD0q2f28tk/beT5UVKhO+oSOtczvMJ/veVk/uOiBfxl/WGesDPmrt7RSGxg4hP+DrdZAeehj53PqgmsejgR6awp/Aa4csi224AnjTGLgCft9wBXAYvsnxuBn6exXEodFX6fx03XnYrK/Ew+fukibjh/fsrnOJ3YqXRmD3XzJQt50ymzkrbNtte6nl+Uhccj/MtplczKDfLp+zcQjcU5Y17yiKirVpRz5vyCpCYbR8jvc1OZLy7NpqM3RmMkSkOkl4IsP36fhw9fuICrVliBdW9TF4fbe/jjmmp+/dw+7n7pANlBX9K1ZxdkcttVSzmlMpcX9jS5be9O09R4QQGsfFENkShzC7IIJQwQWLO/hc/ct4Ha9h7++Eo1kd4YHzh3Hh6PcHZVoVVTSEhVctmyUoIZHh7aUENv/wC/eWE/kLwqH0Bte4/bzDQQN9R1RPF5BBFYUZFLpt/Ltadan8M/t9fj9QjtPf28enDwOptr2vnWI9vHrYUcbushP5Qx4oz9o8U3/iGTY4x5RkTmDdl8LXCR/fouYDXwOXv7b431X8BLIpInIuXGmNF7qZSaZkSEWy9fPKFzlpfnkB3wTbimALiZVhM5zUfz7Fndfp+HW69Ywm1/2sh158zlsiGd6u89aw7vPWvOuH9rkd0ctq0uQn1H1G1ueuvKSt66spJV33icvY2dbvPOW06dxV/WHybSm9x3ICJ8+MIF5AQz+MIDm9jX1EVVcZi1dodv4qiqoZygsK+xi6ZIlGWzcijqCLiT4X6+eg+HWnvYVtdBbVsv51QVujWhs6sK+PumWlq7+1hQbAWxrICP8xcW8+KeZv62sZbmrj5Cfi8bDg0+zONxw4fuWsv2ugg3X7KQXz6915qsmBfk3KoiTreD7OKSbHIzM2jv6eeNJ5fx8KZaXtjTxJnzrW/7P396D3/faA0T/shFC0e9x8NtPe7kyXQ51n0KpQkP+jrA+S+wAqhOOO6QvW0YEblRRNaKyNrGxtEXPFFqJnjPmXN45rMXj/hNfTJyghmsqMhJmk399tMr2fr1K/n6tSuGrUiXKudhva22g8ZI77DmJidJn9Op/dkrlwLWrO2ROOV7yc6a+tCGw6yoyEnqExnKCQp7m6wZ28XhgNuJnRP0cai1B7/Xw+aaDrKDPr765pPcc1fYHfO9/XF3jW2ABSVZVLf0sOlQGyG/lytPKmN9dbtbg/nrxsNsOWxl0/3BE7vo6R/g1YNtlOUE+dbbX8c7V80GrNTvTi3sjLn5LCgOJ6/iZ1cQvv/4zjHndtS29864oOCyawUTHpdljLndGLPKGLOquHj8ERxKTWdejySl2Dga/nbz67n+3HlJ28abMzGevJCfirxMth7uoCESHdY574xy2tvYSdhOBPjqly7nz/9x7ojXm1doLZr04t5m9jV1sfFQO9eeMuL3RFdWwEdpToBndzXS1TfAwpIws/KsYbtOjeDKFWU8+NHz+McnLkhqilpaloM99SNpZb75hVn0DcR5bncT84uyOHVOHk2dUQ7bncl3Pr+fJaXZfO3NJ1GeG3SbnpxFmxKdYfcBLCnLYcWsHDdFB1hNUEXhAP0Dhkc313HT3Wt57WDrsGvUtPW4a3+ky7EOCvUiUg5g/3bmxtcAsxOOq7S3KaWmiWXlOayvbqMxEqUkJ7mmML8oi+auPl6rbqOqOAsRoSDLT2F4eAc2WM1I51QV8tLeZv62wRp6ec0po4+2Svw7ThK8ZeU5fPma5dz5gTPcuQ3nLLCajIa2yWf6vW7OqMT0507yxD2NXSwoDnNKpRVc1uxroa27j42H2rjq5DLef848nv/cJZxr13DKcobf19tOr+SmC6s43R61Vdve6w7LrW3v5cLFxZTlBPn+E7t4dEt9UvLCNftb+N7jO4n0xmZcTeEh4Hr79fXAgwnbr7NHIZ0NtGt/glLTy/JZORxs6SYWN7x+UfLkPGeBo42H2t1mnvGcXVVIYyTK3S8d4NTZee4qe2OZXxQmbqyJc0vLrKVO5xdlcdIsqyZw3oLRJw06TWBJNYWEslYVZ7GiIpdZuUEeeK2GF/Y0YwxuDiuriciqDYxUUygKB/j8Vcvw+zycNMtqrtpc005sIE59Ry+z8oJcsLjInVW9zU5T8tSOBt73q5f50ZO7ACifrkFBRP4AvAgsEZFDInID8E3gchHZBVxmvwd4GNgL7AZ+BXwkXeVSSqXHcntuxMkVuZwzZC3t8xcWuQ/dqqLx52jAYL9CQyTKZSNMIByJM+FwbkGIrMDgOJp/Oa2Cx2+9kDmj9GGAlcMJkmsKpTkBdwJhVbGVm+ltp1fy7K5G7l93iHDA5zZNgZUwUAR35bxR/1aF9bc217TTEIkSN9bSshcutu4z4PO4QeHO5/Yl1bymbfORMeY9xphyY0yGMabSGHOHMabZGHOpMWaRMeYyY0yLfawxxnzUGLPAGHOyMWZtusqllEqPlXPyyfJ7ufmShcPmYXg8wuevtjqXl89Kbf2LOQUhNyX5pcuGpxoZifPNftmQUUo+r8dtQhrNmfML8AjMKRh8oIuIO1LLCThvP72SuIF/bm/gnAWFSZ3zi0uzeeYzF3Ph4rH7O3OCGVQVZ/HawTa3Y7k8L8hly0v43JVL+djFC2nq7KMh0svuhk7OmFfAV960HGDc+zhSaRuSqpQ6sZTkBNn01Tfg8Yw8Me/1i4p5+jMXMTvFtCBOyvGX9jYPSxs+mvnFIweFVJw2J58NX7mC7CHLuM4rzGJ7XYQq+9pzC7O48wOrqGuPcuGS4Q//sUZIJTprfgF/21jLm1utOQyzcjMJ+Lz8x0UL3JX11uxrpba9l4UlYT543nzef/ZcfJMcIZYqDQpKqaNmtIDgSGXVu0RfedNJ9A/EU54BXlWUxX++cRlvHjJpL1VDAwLAFSeV4vUKIf/g4/KSpanVXMZy1vxC/vBKtbtA0UhZbh/aYI23cVbdS3dAAA0KSqnjmN/nmdBwWRHhQyOswX0knAl4R5szce2RLXVk+b1unimA3FAGC4qz3LQYiavupZsmxFNKqSkwKy+TOQUhevvjXLS0ZFht6O2nz2YgbvD7PCk3SR0NWlNQSqkp8u23v47W7j531bxEb1tZwXce28ECe9TTsaJBQSmlpshZQ4buJirJCXLjBVVJWWSPBQ0KSil1nPqcnSPqWNI+BaWUUi4NCkoppVwaFJRSSrk0KCillHJpUFBKKeXSoKCUUsqlQUEppZRLg4JSSimXBgWllFIuDQpKKaVcGhSUUkq5NCgopZRyaVBQSinl0qCglFLKpUFBKaWUS4OCUkoplwYFpZRSLg0KSimlXBoUlFJKuTQoKKWUcmlQUEop5dKgoJRSyqVBQSmllEuDglJKKZcGBaWUUi4NCkoppVwaFJRSSrk0KCillHIdV0FBRK4UkR0isltEbpvq8iil1InmuAkKIuIFfgpcBSwH3iMiy6e2VEopdWI5boICcCaw2xiz1xjTB/wRuHaKy6SUUicU31QXIEEFUJ3w/hBw1tCDRORG4Eb7baeI7Jjk3ysCmiZ57nSh9zgz6D3ODMfTPc4dbcfxFBRSYoy5Hbj9SK8jImuNMauOQpGOW3qPM4Pe48wwXe7xeGo+qgFmJ7yvtLcppZQ6Ro6noLAGWCQi80XED7wbeGiKy6SUUieU46b5yBgTE5GPAY8CXuBOY8yWNP7JI26Cmgb0HmcGvceZYVrcoxhjproMSimljhPHU/ORUkqpKaZBQSmllOuEDAozNZ2GiOwXkU0isl5E1trbCkTkcRHZZf/On+pyToSI3CkiDSKyOWHbiPcklh/Zn+tGEVk5dSVP3Sj3+FURqbE/y/UicnXCvs/b97hDRN4wNaWeGBGZLSJPichWEdkiIp+wt8+Yz3KMe5xen6Ux5oT6werE3gNUAX5gA7B8qst1lO5tP1A0ZNv/A26zX98GfGuqyznBe7oAWAlsHu+egKuBfwACnA28PNXlP4J7/Crw6RGOXW7/NxsA5tv/LXun+h5SuMdyYKX9OhvYad/LjPksx7jHafVZnog1hRMtnca1wF3267uAt0xhWSbMGPMM0DJk82j3dC3wW2N5CcgTkfJjU9LJG+UeR3Mt8EdjTNQYsw/YjfXf9HHNGFNrjHnVfh0BtmFlMZgxn+UY9zia4/KzPBGDwkjpNMb64KYTAzwmIuvsdCAApcaYWvt1HVA6NUU7qka7p5n22X7Mbjq5M6HZb9rfo4jMA04DXmaGfpZD7hGm0Wd5IgaFmex8Y8xKrEyzHxWRCxJ3GqvOOqPGIM/Ee7L9HFgAnArUAt+d2uIcHSISBv4E3GKM6UjcN1M+yxHucVp9lidiUJix6TSMMTX27wbgAayqaL1T7bZ/N0xdCY+a0e5pxny2xph6Y8yAMSYO/IrBZoVpe48ikoH1sPydMebP9uYZ9VmOdI/T7bM8EYPCjEynISJZIpLtvAauADZj3dv19mHXAw9OTQmPqtHu6SHgOnvkytlAe0LTxLQypP38X7A+S7Du8d0iEhCR+cAi4JVjXb6JEhEB7gC2GWO+l7BrxnyWo93jtPssp7qneyp+sEY27MTq7f/iVJfnKN1TFdZIhg3AFue+gELgSWAX8ARQMNVlneB9/QGryt2P1eZ6w2j3hDVS5af257oJWDXV5T+Ce7zbvoeNWA+P8oTjv2jf4w7gqqkuf4r3eD5W09BGYL39c/VM+izHuMdp9VlqmgullFKuE7H5SCml1Cg0KCillHJpUFBKKeXSoKCUUsqlQUEppZRLg4Ka9kTkBfv3PBF571G+9hdG+lvpIiJvEZEvj3PMt0Vku5024QERyUvYNyzrpoj4ReQZETluVlpUxy8NCmraM8aca7+cB0woKKTwoEwKCgl/K10+C/xsnGMeB1YYY16HNd/m8wAishxrMuZJwJXAz0TEa6zEj08C70pbqdWMoUFBTXsi0mm//Cbwejtn/SdFxGt/q15jf6u+yT7+IhF5VkQeArba2/5iJxLc4iQTFJFvApn29X6X+LfsmbbfFpHNYq1h8a6Ea68Wkfvtb/O/s2e6IiLftHPtbxSR74xwH4uBqDGmyX7/oIhcZ7++ySmDMeYxY0zMPu0lrPQIMHbWzb8A7zsK/9xqhtPqpJpJbsPKW38NgP1wbzfGnCEiAeB5EXnMPnYl1rftffb7fzPGtIhIJrBGRP5kjLlNRD5mjDl1hL/1VqwEZ6cARfY5z9j7TsP6tn4YeB44T0S2YaU4WGqMMYlNPgnOA15NeH+jXeZ9wKew1hUY6t+Ae+zXFVhBwpGYdXMzcMYI5yuVRGsKaia7Ait/znqsFMaFWPllAF5JCAgAHxeRDVgP1dkJx43mfOAPxkp0Vg88zeBD9xVjzCFjJUBbj9Ws1Q70AneIyFuBLI8MjwAAActJREFU7hGuWQ40Om/s634ZeAr4lDEmac0FEfkiEAN+N05ZMcYMAH1OfiylRqM1BTWTCXCzMebRpI0iFwFdQ95fBpxjjOkWkdVA8Aj+bjTh9QDgM8bERORM4FLg7cDHgEuGnNcD5A7ZdjLQDMwacg8fAK4BLjWDuWrGy7oZwApMSo1KawpqJolgLYPoeBT4DzudMSKy2M4gO1Qu0GoHhKUkN9P0O+cP8SzwLrvfohhrSc1RM1zaOfZzjTEPA5/EanYaahuwMOGcM7HWxjgN+LSdSRMRuRKrQ/rNxpjEGseoWTdFpBBoMsb0j1ZGpUBrCmpm2QgM2M1AvwF+iNV086rd2dvIyMuRPgJ82G7330Fyu/ztwEYRedUYk9hR+wBwDlZWWgN81hhTZweVkWQDD4pIEKsGc+sIxzwDfNcuqx8r9/4HjTGHReRTwJ0icgnwE6xv/Y/bfdgvGWM+bIzZIiL3YnWex4CP2s1GABcDfx+lbEq5NEuqUscREfkh8FdjzBNH+bp/Bm4zxuw8mtdVM482Hyl1fPlvIHQ0LyjWYlJ/0YCgUqE1BaWUUi6tKSillHJpUFBKKeXSoKCUUsqlQUEppZRLg4JSSinX/w9jfdmKqlBq9wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "evaluating perplexity ...\n",
            "234 / 235\n",
            "test perplexity:  136.3136962392949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEabVEIbjnub",
        "colab_type": "text"
      },
      "source": [
        "最新の研究ではパープレキシティは60を下回っているらしい。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp_LwN80jvyg",
        "colab_type": "text"
      },
      "source": [
        "## RNNLMのさらなる改善\n",
        "+ LSTMレイヤの多層化\n",
        "+ Dropoutによる過学習の抑制\n",
        "+ 重み共有"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NlZTZ7zmOVH",
        "colab_type": "text"
      },
      "source": [
        "### LSTMレイヤの多層化\n",
        "+ LSTMレイヤを何層も重ねることで、より複雑なパターンを学習できるようにする。\n",
        "+ 重なる層の数は、それがハイパーパラメータとなる。データやタスクによって適宜決める必要がある。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_2Lg-8CnyEN",
        "colab_type": "text"
      },
      "source": [
        "### Dropoutによる過学習の抑制\n",
        "+ RNNはフィードフォワード型のネットワークよりも簡単に過学習をしてしまう。\n",
        "  + RNNにおいて過学習対策は研究が活発になされているらしい。\n",
        "\n",
        "+ 過学習を避けるための方法\n",
        " + 訓練データを増やす\n",
        " + モデルの複雑さを減らす\n",
        " + 正則化を行う\n",
        " + Dropoutのように訓練時にレイヤ内のニューロンのいくつかをランダムに無視して学習を行う \n",
        "\n",
        "\n",
        "+ Dropoutをどこに挟むべきか？\n",
        " + LSTMレイヤの時系列方向？変分Dropoutという手法があり、それならば有効だが、そのまま入れてもうまくいかない。\n",
        " + LSTMレイヤ自体の深さに関してDropoutを挟むのは有効。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_RZPhFdvGi_",
        "colab_type": "text"
      },
      "source": [
        "### 重み共有\n",
        "+ 例えば、Embeddingレイヤの重みとAffineレイヤの重みを結びつけるテクニック\n",
        " + 2つのレイヤで重みを共有することで、学習するパラメータを大きく減らすことができる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPs62aTONWE8",
        "colab_type": "text"
      },
      "source": [
        "### より良いRNNLMの実装"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRvUTZWyxg1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "from common.time_layers import *\n",
        "from common.np import *\n",
        "from common.base_model import BaseModel\n",
        "\n",
        "class BetterRnnlm(BaseModel):\n",
        "  def __init__(self, vocab_size=10000, wordvec_size=650,\n",
        "               hidden_size=650, dropout_ratio=0.5):\n",
        "    V, D, H = vocab_size, wordvec_size, hidden_size\n",
        "    rn = np.random.randn\n",
        "\n",
        "    embed_W = (rn(V, D) / 100).astype('f')\n",
        "    lstm_Wx1 = (rn(D, 4*H) / np.sqrt(D)).astype('f')\n",
        "    lstm_Wh1 = (rn(H, 4*H) / np.aqrt(H)).astype('f')\n",
        "    lstm_b1 = np.zeros(4*H).astype('f')\n",
        "    lstm_Wx2 = (rn(H, 4*H) / np.sqrt(H)).astype('f')\n",
        "    lstm_Wh2 = (rn(H, 4*H) / np.aqrt(H)).astype('f')\n",
        "    lstm_b2 = np.zeros(4*H).astype('f')\n",
        "    affine_b = np.zeros(V).astype('f')\n",
        "\n",
        "    # 3つの改善！\n",
        "    self.layers = [\n",
        "                   TimeEmbedding(embed_W),\n",
        "                   TimeDropout(dropout_ratio), # Dropout層を縦に追加している！\n",
        "                   TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\n",
        "                   TimeDropout(dropout_ratio),\n",
        "                   TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True), # LSTMレイヤを重ねている！\n",
        "                   TimeDropout(dropout_ratio),\n",
        "                   TimeAffine(embed_W.T, affine_b) # 重み共有！\n",
        "    ]\n",
        "\n",
        "    self.loss_layer = TimeSoftmaxWithLoss()\n",
        "    self.lstm_layers = [self.layers[2], self.layers[4]]\n",
        "    self.drop_layers = [self.layers[1], self.layers[3], self.layers[5]]\n",
        "    self.params, self.grads = [], []\n",
        "\n",
        "    for layer in self.layers:\n",
        "      self.params += layer.params\n",
        "      self.grads += layer.grads\n",
        "\n",
        "  def predict(self, xs, train_flg=False):\n",
        "    for layer in self.drop_layers:\n",
        "      layer.train_flg = train_flg\n",
        "\n",
        "    for layer in self.layers:\n",
        "      xs = layer.forward(xs)\n",
        "    return loss\n",
        "\n",
        "  def forward(self, xs, ts, train_flg=True):\n",
        "    score = self.predict(xs, train_flg)\n",
        "    loss = self.loss_layer.forward(score, ts)\n",
        "    return loss\n",
        "\n",
        "  def backward(self, dout=1):\n",
        "    dout = self.loss_layer.backward(dout)\n",
        "    for layer in reversed(self.layers):\n",
        "      dout = layer.backward(dout)\n",
        "    return dout\n",
        "\n",
        "  def reset_state(self):\n",
        "    for layer in self.lstm_layers:\n",
        "      layer.reset_state()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRDnFDDrR78y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e30d0b18-0322-440d-ca72-c2d5407c8fed"
      },
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "from common import config\n",
        "config.GPU = True\n",
        "\n",
        "from common.optimizer import SGD\n",
        "from common.trainer import RnnlmTrainer\n",
        "from common.util import eval_perplexity\n",
        "from dataset import ptb\n",
        "from ch06.better_rnnlm import BetterRnnlm\n",
        "\n",
        "# ハイパーパラメータの設定\n",
        "batch_size = 20\n",
        "wordvec_size = 650\n",
        "hidden_size = 650\n",
        "time_size = 35\n",
        "lr = 20.0\n",
        "max_epoch = 40\n",
        "max_grad = 0.25\n",
        "dropout = 0.5\n",
        "\n",
        "# 学習データの読み込み\n",
        "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
        "corpus_val, _, _ = ptb.load_data('val')\n",
        "corpus_test, _, _ = ptb.load_data('test')\n",
        "\n",
        "vocab_size = len(word_to_id)\n",
        "xs = corpus[:-1]\n",
        "ts = corpus[1:]\n",
        "\n",
        "model = BetterRnnlm(vocab_size, wordvec_size, hidden_size, dropout)\n",
        "optimizer = SGD(lr)\n",
        "trainer = RnnlmTrainer(model, optimizer)\n",
        "\n",
        "best_ppl = float('inf')\n",
        "for epoch in range(max_epoch):\n",
        "  trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size,\n",
        "              time_size=time_size, max_grad=max_grad)\n",
        "  model.reset_state()\n",
        "  ppl = eval_perplexity(model, corpus_val)\n",
        "  print('valid perplexity: ', ppl)\n",
        "\n",
        "  if best_ppl > ppl:\n",
        "    best_ppl = ppl\n",
        "    model.save_params()\n",
        "\n",
        "  else:\n",
        "    lr /= 4.0\n",
        "    optimizer.lr = lr \n",
        "\n",
        "  model.reset_state()\n",
        "  print('-'*50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading ptb.train.txt ... \n",
            "Done\n",
            "Downloading ptb.valid.txt ... \n",
            "Done\n",
            "Downloading ptb.test.txt ... \n",
            "Done\n",
            "| epoch 1 |  iter 1 / 1327 | time 3[s] | perplexity 9999.99\n",
            "| epoch 1 |  iter 21 / 1327 | time 63[s] | perplexity 3443.83\n",
            "| epoch 1 |  iter 41 / 1327 | time 125[s] | perplexity 1709.85\n",
            "| epoch 1 |  iter 61 / 1327 | time 185[s] | perplexity 1288.33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wzVy-vYVyf-",
        "colab_type": "text"
      },
      "source": [
        "GPUでも学習に5時間かかるらしい。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YnFrTpDVjXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}