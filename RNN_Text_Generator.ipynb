{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_Text_Generator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMAClz+sF/sXS4jwxQ1rkSc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KamonohashiPerry/MachineLearning/blob/master/RNN_Text_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65doECBdP8oR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, Activation, SimpleRNN\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "\n",
        "import codecs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL9hPNviQKVd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "231db8e6-7924-46bc-db06-5c39863135bc"
      },
      "source": [
        "\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 145118 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.18-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.18-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.18-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Dd4MxXbRhWi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "136ddb4c-e3ff-4d02-a608-c5d2f77aeddc"
      },
      "source": [
        "# drive mean root directory of  google drive\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "!ls drive/\"Colab Notebooks\"/NLP"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alice_in_wonderland.txt  Untitled0.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXsSB4syRwYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_FILE = \"drive/Colab Notebooks/NLP/alice_in_wonderland.txt\"\n",
        "with codecs.open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "  lines = [line.strip().lower() for line in f if len(line) != 0 ]\n",
        "  text = \" \".join(lines)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZsdQXTESkXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars = set(text)\n",
        "nb_chars = len(chars)\n",
        "char2index = dict((c, i) for i, c in enumerate(chars))\n",
        "index2char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTRCso2xTKUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEQLEN = 10\n",
        "STEP = 1\n",
        "\n",
        "input_chars = []\n",
        "label_chars = []\n",
        "for i in range(0, len(text) - SEQLEN, STEP ):\n",
        "  input_chars.append(text[i:i + SEQLEN])\n",
        "  label_chars.append(text[i + SEQLEN])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz1TOec0T2Qv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input_chars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUdBmkfiT3M0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# label_chars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI_qPhJNUWzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
        "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
        "\n",
        "for i, input_char in enumerate(input_chars):\n",
        "  for j, ch in enumerate(input_char):\n",
        "    X[i, j, char2index[ch]] = 1\n",
        "  y[i, char2index[label_chars[i]]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28onycvWVnv7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aebae851-4804-43e5-a4c0-0e106dbd8a6f"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(163816, 10, 63)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qtcg-j8QU9pj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ace0c78-ba87-4ef5-d2a2-5e80a9021b43"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(163816, 63)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuBV5ZarVjeo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "4758e3d8-f393-432e-a6bf-6075c851cd94"
      },
      "source": [
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 128\n",
        "NUM_ITERATIONS = 25\n",
        "NUM_EPOCHS_PER_ITERATION = 1\n",
        "NUM_PREDS_PER_EPOCH = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(HIDDEN_SIZE, return_sequences=False,\n",
        "                    input_shape=(SEQLEN, nb_chars),\n",
        "                    unroll=True))\n",
        "model.add(Dense(nb_chars))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e85rRnyXHbo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c95e0f86-da0b-47cd-defd-9d6584c3425e"
      },
      "source": [
        "for iteration in range(NUM_ITERATIONS):\n",
        "  print(\"=\" * 50)\n",
        "  print(\"Iteration #: %d\" % (iteration))\n",
        "  model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
        "\n",
        "  test_idx = np.random.randint(len(input_chars))\n",
        "  test_chars = input_chars[test_idx]\n",
        "  print(\"Generating from seed: %s\" % (test_chars))\n",
        "  print(test_chars, end=\"\")\n",
        "\n",
        "  for i in range(NUM_PREDS_PER_EPOCH):\n",
        "    Xtest = np.zeros((1, SEQLEN, nb_chars))\n",
        "    for j, ch in enumerate(test_chars):\n",
        "      Xtest[0, j, char2index[ch]] = 1\n",
        "    pred = model.predict(Xtest, verbose=0)[0]\n",
        "    ypred = index2char[np.argmax(pred)]\n",
        "    print(ypred, end=\"\")\n",
        "\n",
        "    test_chars = test_chars[1:] + ypred\n",
        "  print()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Iteration #: 0\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 28us/step - loss: 1.5067\n",
            "Generating from seed: of feet on\n",
            "of feet on the torter and the mouse to her alice to the project gutenberg-tm electronic works to ear project g\n",
            "==================================================\n",
            "Iteration #: 1\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 28us/step - loss: 1.4931\n",
            "Generating from seed:  would be \n",
            " would be of the dide her for the door as a little of the dide her for the door as a little of the dide her fo\n",
            "==================================================\n",
            "Iteration #: 2\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 29us/step - loss: 1.4809\n",
            "Generating from seed: te of mind\n",
            "te of mind a nother a tone of the mock turtle sormouse so she was so she was so she was so she was so she was \n",
            "==================================================\n",
            "Iteration #: 3\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 28us/step - loss: 1.4699\n",
            "Generating from seed: e queen wi\n",
            "e queen with a seres of the word as it was and here the project gutenberg-tm electronic work on the read a men\n",
            "==================================================\n",
            "Iteration #: 4\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 28us/step - loss: 1.4607\n",
            "Generating from seed: ot thrown \n",
            "ot thrown on the tort was and the tarts, and the mock turtle was a little the table to the table to the table \n",
            "==================================================\n",
            "Iteration #: 5\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 29us/step - loss: 1.4502\n",
            "Generating from seed:  the queen\n",
            " the queen had the king and a little that the king and a little that the king and a little that the king and a\n",
            "==================================================\n",
            "Iteration #: 6\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 28us/step - loss: 1.4416\n",
            "Generating from seed: lemn as sh\n",
            "lemn as she said to herself “what i should be and alice the project gutenberg-tm electronic works to copy in a\n",
            "==================================================\n",
            "Iteration #: 7\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 28us/step - loss: 1.4333\n",
            "Generating from seed: had been a\n",
            "had been about it was a little that alice the dormouse to her for the poor one or the poor one or the poor one\n",
            "==================================================\n",
            "Iteration #: 8\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 28us/step - loss: 1.4258\n",
            "Generating from seed: saw that, \n",
            "saw that, and the mock turtle said to herself and the mock turtle said to herself and the mock turtle said to \n",
            "==================================================\n",
            "Iteration #: 9\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 28us/step - loss: 1.4184\n",
            "Generating from seed: ere lookin\n",
            "ere looking at all the thing as it was an all the thing as it was an all the thing as it was an all the thing \n",
            "==================================================\n",
            "Iteration #: 10\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 28us/step - loss: 1.4115\n",
            "Generating from seed: hat there \n",
            "hat there was a little this the caterpillar the dide to see the consed the caterpillar the dide to see the con\n",
            "==================================================\n",
            "Iteration #: 11\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 29us/step - loss: 1.4045\n",
            "Generating from seed: y the wide\n",
            "y the wides the sorther the course the mock turtle said to herself _very_ the courte, and she said to herself \n",
            "==================================================\n",
            "Iteration #: 12\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 28us/step - loss: 1.3991\n",
            "Generating from seed: r. “you’re\n",
            "r. “you’re sloous of the strod catchere say it was a little this enen i think you say of the strod catchere sa\n",
            "==================================================\n",
            "Iteration #: 13\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 29us/step - loss: 1.3934\n",
            "Generating from seed: to leave t\n",
            "to leave the mock turtle seary and a long to herself up and a little the words and a long to herself up and a \n",
            "==================================================\n",
            "Iteration #: 14\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 28us/step - loss: 1.3884\n",
            "Generating from seed: use in cry\n",
            "use in cry the mock turtle seary was so parse with the courte, and she was so martion of the courte, and she w\n",
            "==================================================\n",
            "Iteration #: 15\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 28us/step - loss: 1.3832\n",
            "Generating from seed: the millen\n",
            "the millen the door said to the project gutenberg-tm electronic works project gutenberg-tm electronic works pr\n",
            "==================================================\n",
            "Iteration #: 16\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 28us/step - loss: 1.3792\n",
            "Generating from seed: alked on i\n",
            "alked on it as it was the dormouse that she was so they were not a little she said to herself “off with the do\n",
            "==================================================\n",
            "Iteration #: 17\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 28us/step - loss: 1.3738\n",
            "Generating from seed: ired of be\n",
            "ired of began the dormouse the court of the court of the court of the court of the court of the court of the c\n",
            "==================================================\n",
            "Iteration #: 18\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 28us/step - loss: 1.3694\n",
            "Generating from seed: he mock tu\n",
            "he mock turtle would have of the white rabbit how the mock turtle would have of the white rabbit how the mock \n",
            "==================================================\n",
            "Iteration #: 19\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 4s 27us/step - loss: 1.3650\n",
            "Generating from seed: son is,” s\n",
            "son is,” said alice, “i think you enget and a little sidee, and i don’t to be a sone of the sood not a little \n",
            "==================================================\n",
            "Iteration #: 20\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 29us/step - loss: 1.3613\n",
            "Generating from seed: ry hot, sh\n",
            "ry hot, she was a little that the should be the things in a sort of the sort of course, and she was a little t\n",
            "==================================================\n",
            "Iteration #: 21\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 28us/step - loss: 1.3585\n",
            "Generating from seed: ding outda\n",
            "ding outdant in a tone and the white rabbit here in the sort of the sood never her any poor read the sood neve\n",
            "==================================================\n",
            "Iteration #: 22\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 29us/step - loss: 1.3548\n",
            "Generating from seed: hought ali\n",
            "hought alice, “it was a down her feet her feet her feet her feet her feet her feet her feet her feet her feet \n",
            "==================================================\n",
            "Iteration #: 23\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 28us/step - loss: 1.3506\n",
            "Generating from seed:  went on, \n",
            " went on, “it was a melancry to seep on the project gutenberg-tm electronic works of the said alice.  “what a \n",
            "==================================================\n",
            "Iteration #: 24\n",
            "Epoch 1/1\n",
            "163816/163816 [==============================] - 5s 29us/step - loss: 1.3481\n",
            "Generating from seed: its share \n",
            "its share of the court on the sort of the court on the sort of the court on the sort of the court on the sort \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI5pcYLGZVxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}