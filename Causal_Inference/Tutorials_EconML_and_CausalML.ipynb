{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EconML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install econml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルたち\n",
    "+ Double Machine Learning\n",
    " + Linear final stage\n",
    " + Sparse linear final stage\n",
    " + Nonparametric last stage\n",
    "+ Orthogonal Random Forests\n",
    "+ Meta-Learners\n",
    " + XLearner\n",
    " + SLearner\n",
    " + TLearner\n",
    "+ Doubly Robust Learners\n",
    " + Linear final stage\n",
    " + Sparse linear final stage\n",
    " + Nonparametric final stage\n",
    "+ Orthogonal Instrumental Variables\n",
    " + Intent to Treat Doubly Robust Learner\n",
    "+ Deep Instrumental Variables\n",
    "\n",
    "※ソースコードあさったら、二段階最小二乗法もあった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CATE modelとは\n",
    "+ Conditional Average Treatment Effects Estimation\n",
    " + bbb\n",
    "   + ccc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.cate_interpreter import SingleTreeCateInterpreter\n",
    "\n",
    "intrp = SingleTreeCateInterpreter(include_model_uncertainty=True,\n",
    "                                                            max_depth=2,\n",
    "                                                            min_samples_leaf=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We interpret the CATE model's behavior based on the features used for heterogeneity\n",
    "intrp.interpret(est, X)\n",
    "# Plot the tree\n",
    "plt.figure(figsize=(25, 5))\n",
    "intrp.plot(feature_names=['A', 'B', 'C', 'D'], fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CausalML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install causalml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルたち\n",
    "+ Tree-based algorithms\n",
    " + Uplift tree/random forests on KL divergence, Euclidean Distance, and Chi-Square\n",
    " + Uplift tree/random forests on Contextual Treatment Selection\n",
    "+ Meta-learner algorithms\n",
    " + S-learner\n",
    " + T-learner\n",
    " + X-learner\n",
    " + R-learner（知らないやつ）\n",
    "+ Instrumental variables algorithms\n",
    " + 2-Stage Least Squares (2SLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalml.inference.meta import LRSRegressor\n",
    "from causalml.inference.meta import XGBTRegressor, MLPTRegressor\n",
    "from causalml.inference.meta import BaseXRegressor\n",
    "from causalml.inference.meta import BaseRRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from causalml.dataset import synthetic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X, treatment, _, _, e = synthetic_data(mode=1, n=1000, p=5, sigma=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Treatment Effect (Linear Regression): 0.74 (0.63, 0.85)\n"
     ]
    }
   ],
   "source": [
    "lr = LRSRegressor()\n",
    "te, lb, ub = lr.estimate_ate(X, treatment, y)\n",
    "print('Average Treatment Effect (Linear Regression): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:02:32] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:02:32] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Average Treatment Effect (XGBoost): 0.62 (0.54, 0.69)\n"
     ]
    }
   ],
   "source": [
    "xg = XGBTRegressor(random_state=42)\n",
    "te, lb, ub = xg.estimate_ate(X, treatment, y)\n",
    "print('Average Treatment Effect (XGBoost): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Treatment Effect (Neural Network (MLP)): 0.82 (0.73, 0.91)\n"
     ]
    }
   ],
   "source": [
    "nn = MLPTRegressor(hidden_layer_sizes=(10, 10),\n",
    "                 learning_rate_init=.1,\n",
    "                 early_stopping=True,\n",
    "                 random_state=42)\n",
    "te, lb, ub = nn.estimate_ate(X, treatment, y)\n",
    "print('Average Treatment Effect (Neural Network (MLP)): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xl = BaseXRegressor(learner=XGBRegressor(random_state=27))\n",
    "# te, lb, ub = xl.estimate_ate(X, e, treatment, y)\n",
    "# print('Average Treatment Effect (BaseXRegressor using XGBoost): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:03:08] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Average Treatment Effect (BaseRRegressor using XGBoost): 0.60 (0.59, 0.60)\n"
     ]
    }
   ],
   "source": [
    "rl = BaseRRegressor(learner=XGBRegressor(random_state=42))\n",
    "te, lb, ub =  rl.estimate_ate(X=X, p=e, treatment=treatment, y=y)\n",
    "print('Average Treatment Effect (BaseRRegressor using XGBoost): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "['Booster', 'Dataset', 'LGBMClassifier', 'LGBMModel', 'LGBMRanker', 'LGBMRegressor', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', 'absolute_import', 'basic', 'callback', 'compat', 'create_tree_digraph', 'cv', 'dir_path', 'early_stopping', 'engine', 'libpath', 'os', 'plot_importance', 'plot_metric', 'plot_split_value_histogram', 'plot_tree', 'plotting', 'print_evaluation', 'record_evaluation', 'reset_parameter', 'sklearn', 'train', 'version_file']"
      ],
      "text/plain": [
       "['Booster',\n",
       " 'Dataset',\n",
       " 'LGBMClassifier',\n",
       " 'LGBMModel',\n",
       " 'LGBMRanker',\n",
       " 'LGBMRegressor',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'absolute_import',\n",
       " 'basic',\n",
       " 'callback',\n",
       " 'compat',\n",
       " 'create_tree_digraph',\n",
       " 'cv',\n",
       " 'dir_path',\n",
       " 'early_stopping',\n",
       " 'engine',\n",
       " 'libpath',\n",
       " 'os',\n",
       " 'plot_importance',\n",
       " 'plot_metric',\n",
       " 'plot_split_value_histogram',\n",
       " 'plot_tree',\n",
       " 'plotting',\n",
       " 'print_evaluation',\n",
       " 'record_evaluation',\n",
       " 'reset_parameter',\n",
       " 'sklearn',\n",
       " 'train',\n",
       " 'version_file']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(lightgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from causalml.inference.meta import BaseSRegressor, BaseTRegressor, BaseXRegressor, BaseRRegressor\n",
    "# from causalml.dataset.regression import synthetic_data\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# import lightgbm\n",
    "\n",
    "# # Load synthetic data\n",
    "# y, X, treatment, tau, b, e = synthetic_data(mode=1, n=10000, p=25, sigma=0.5)\n",
    "# w_multi = np.array(['treatment_A' if x==1 else 'control' for x in treatment]) # customize treatment/control names\n",
    "\n",
    "# slearner = BaseSRegressor(lightgbm.LGBMRegressor(), control_name='control')\n",
    "# slearner.estimate_ate(X, w_multi, y)\n",
    "# slearner_tau = slearner.fit_predict(X, w_multi, y)\n",
    "\n",
    "# model_tau_feature = RandomForestRegressor()  # specify model for model_tau_feature\n",
    "\n",
    "# slearner.get_importance(X=X, tau=slearner_tau, model_tau_feature=model_tau_feature,\n",
    "#                         normalize=True, method='auto', features=feature_names)\n",
    "\n",
    "# # Using the feature_importances_ method in the base learner (LGBMRegressor() in this example)\n",
    "# slearner.plot_importance(X=X, tau=slearner_tau, normalize=True, method='auto')\n",
    "\n",
    "# # Using eli5's PermutationImportance\n",
    "# slearner.plot_importance(X=X, tau=slearner_tau, normalize=True, method='permutation')\n",
    "\n",
    "# # Using SHAP\n",
    "# shap_slearner = slearner.get_shap_values(X=X, tau=slearner_tau)\n",
    "\n",
    "# # Plot shap values without specifying shap_dict\n",
    "# slearner.plot_shap_values(X=X, tau=slearner_tau)\n",
    "\n",
    "# # Plot shap values WITH specifying shap_dict\n",
    "# slearner.plot_shap_values(shap_dict=shap_slearner)\n",
    "\n",
    "# # interaction_idx set to 'auto' (searches for feature with greatest approximate interaction)\n",
    "# slearner.plot_shap_dependence(treatment_group='treatment_A',\n",
    "#                               feature_idx=1,\n",
    "#                               X=X,\n",
    "#                               tau=slearner_tau,\n",
    "#                               interaction_idx='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
